[
  {
    "Document Index (generated)": 1,
    "Number of Records": 1,
    "Abstract": "Transfer learning considers related but distinct tasks defined on heterogenous domains and tries to transfer knowledge between these tasks to improve generalization performance. It is particularly useful when we do not have sufficient amount of labeled training data in some tasks, which may be very costly, laborious, or even infeasible to obtain. Instead, learning the tasks jointly enables us to effectively increase the amount of labeled training data. In this paper, we formulate a kernelized Bayesian transfer learning framework that is a principled combination of kernel-based dimensionality reduction models with task-specific projection matrices to find a shared subspace and a coupled classification model for all of the tasks in this subspace. Our two main contributions are: (i) two novel probabilistic models for binary and multiclass classification, and (ii) very efficient variational approximation procedures for these models. We illustrate the generalization performance of our algorithms on two different applications. In computer vision experiments, our method outperforms the state-of-the-art algorithms on nine out of 12 benchmark supervised domain adaptation experiments defined on two object recognition data sets. In cancer biology experiments, we use our algorithm to predict mutation status of important cancer genes from gene expression profiles using two distinct cancer populations, namely, patient-derived primary tumor data and in-vitro-derived cancer cell line data. We show that we can increase our generalization performance on primary tumors using cell lines as an auxiliary data source.",
    "Authors1": "Mehmet Gönen",
    "Authors2": "Adam A. Margolin",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Mehmet Gönen , Adam A. Margolin",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "cross-domain learning",
    "Keywords2": "domain adaptation",
    "Keywords3": "kernel methods",
    "Keywords4": "transfer learning",
    "Keywords5": "variational approximation",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "cross-domain learning;domain adaptation;kernel methods;transfer learning;variational approximation",
    "Title": "Kernelized Bayesian Transfer Learning",
    "Topics10": "",
    "Topics1": "APP: Biomedical / Bioinformatics",
    "Topics2": "NMLA: Bayesian Learning",
    "Topics3": "NMLA: Kernel Methods",
    "Topics4": "NMLA: Transfer, Adaptation, Multitask Learning",
    "Topics5": "VIS: Object Recognition",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "APP: Biomedical / Bioinformatics;NMLA: Bayesian Learning;NMLA: Kernel Methods;NMLA: Transfer, Adaptation, Multitask Learning;VIS: Object Recognition"
  },
  {
    "Document Index (generated)": 2,
    "Number of Records": 1,
    "Abstract": "Transfer learning uses relevant auxiliary data to help the learning task in a target domain where labeled data are usually insufficient to train an accurate model. Given appropriate auxiliary data, researchers have proposed many transfer learning models. How to find such auxiliary data, however, is of little research in the past. In this paper, we focus on this auxiliary data retrieval problem, and propose a transfer learning framework that effectively selects helpful auxiliary data from an open knowledge space (e.g. the World Wide Web). Because there is no need of manually selecting auxiliary data for different target domain tasks, we call our framework Source Free Transfer Learning (SFTL). For each target domain task, SFTL framework iteratively queries for the helpful auxiliary data based on the learned model and then updates the model using the retrieved auxiliary data. We highlight the automatic constructions of queries and the robustness of the SFTL framework. Our experiments on the 20 NewsGroup dataset and the Google search snippets dataset suggest that the new framework is capable to have the comparable performance to those state-of-the-art methods with dedicated selections of auxiliary data.",
    "Authors1": "Zhongqi Lu",
    "Authors2": "Yin Zhu",
    "Authors3": "Sinno Pan",
    "Authors4": "Evan Xiang",
    "Authors5": "Yujing Wang",
    "Authors6": "Qiang Yang",
    "Authors7": "",
    "Authors": "Zhongqi Lu, Yin Zhu, Sinno Pan, Evan Xiang, Yujing Wang , Qiang Yang",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "Novel Machine Learning Algorithms (NMLA)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW);Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "Transfer Learning",
    "Keywords2": "Auxiliary Data Retrieval",
    "Keywords3": "Text Classification",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Transfer Learning;Auxiliary Data Retrieval;Text Classification",
    "Title": "Source Free\" Transfer Learning for Text Classification",
    "Topics10": "",
    "Topics1": "AIW: Knowledge acquisition from the web",
    "Topics2": "AIW: Machine learning and the web",
    "Topics3": "NMLA: Transfer, Adaptation, Multitask Learning",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: Knowledge acquisition from the web;AIW: Machine learning and the web;NMLA: Transfer, Adaptation, Multitask Learning"
  },
  {
    "Document Index (generated)": 3,
    "Number of Records": 1,
    "Abstract": "The probabilistic serial (PS) rule is one of the most well-established and desirable rules for the random assignment problem. We present the egalitarian simultaneous reservation (ESR) social decision scheme — an extension of PS to the more general setting of randomized social choice. ESR also generalizes an egalitarian rule from the literature which is defined only for dichotomous preferences. We consider various desirable fairness, efficiency, and strategic properties of ESR and show that it compares favourably against other social decision schemes. Finally, we define a more general class of social decision schemes called Simultaneous Reservation (SR), that contains ESR as well as the serial dictatorship rules. We show that outcomes of SR characterize efficiency with respect to a natural refinement of stochastic dominance.",
    "Authors1": "Haris Aziz",
    "Authors2": "Paul Stursberg",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Haris Aziz , Paul Stursberg",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP)",
    "Keywords10": "",
    "Keywords1": "social choice theory",
    "Keywords2": "voting",
    "Keywords3": "fair division",
    "Keywords4": "social decision schemes",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "social choice theory;voting;fair division;social decision schemes",
    "Title": "A Generalization of Probabilistic Serial to Randomized Social Choice",
    "Topics10": "",
    "Topics1": "GTEP: Game Theory",
    "Topics2": "GTEP: Social Choice / Voting",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Game Theory;GTEP: Social Choice / Voting"
  },
  {
    "Document Index (generated)": 4,
    "Number of Records": 1,
    "Abstract": "As the rapid growth of online social media attracts a large number of Internet users, the large volume of content generated by these users also provides us with an opportunity to study the lexical variations of people of different age. In this paper, we present a latent variable model that jointly models the lexical content of tweets and Twitter users' age. Our model inherently assumes that a topic has not only a word distribution but also an age distribution. We propose a Gibbs-EM algorithm to perform inference on our model. Empirical evaluation shows that our model can generate meaningful age-specific topics such as \"school\" for teenagers and \"health\" for older people. Our model also performs age prediction better than a number of baseline methods.",
    "Authors1": "Liao Lizi",
    "Authors2": "Jing Jiang",
    "Authors3": "Ying Ding",
    "Authors4": "Heyan Huang",
    "Authors5": "Ee-Peng Lim",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Liao Lizi, Jing Jiang, Ying Ding, Heyan Huang , Ee-Peng Lim",
    "Groups1": "NLP and Text Mining (NLPTM)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "NLP and Text Mining (NLPTM)",
    "Keywords10": "",
    "Keywords1": "Generative model",
    "Keywords2": "Social Networks",
    "Keywords3": "Age Prediction",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Generative model;Social Networks;Age Prediction",
    "Title": "Lifetime Lexical Variation in Social Media",
    "Topics10": "",
    "Topics1": "AIW: Web personalization and user modeling",
    "Topics2": "NLPTM: Information Extraction",
    "Topics3": "NLPTM: Natural Language Processing (General/Other)",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: Web personalization and user modeling;NLPTM: Information Extraction;NLPTM: Natural Language Processing (General/Other)"
  },
  {
    "Document Index (generated)": 5,
    "Number of Records": 1,
    "Abstract": "In this paper, we study the low-rank tensor completion problem, where a high-order tensor with missing entries is given and the goal is to complete the tensor. We propose to minimize a new convex objective function, based on log sum of exponentials of nuclear norms, that promotes the low-rankness of unfolding matrices of the completed tensor. We show for the first time that the proximal operator to this objective function is readily computable through a hybrid singular value thresholding scheme. This leads to a new solution to high-order (low-rank) tensor completion via convex relaxation. We show that this convex relaxation and the resulting solution are much more effective than existing tensor completion methods\n(including those also based on minimizing ranks of unfolding matrices). The hybrid singular value thresholding scheme can be applied to any problem where the goal is\nto minimize the maximum rank of a set of low-rank matrices.",
    "Authors1": "Xiaoqin Zhang",
    "Authors2": "Zhengyuan Zhou",
    "Authors3": "Di Wang",
    "Authors4": "Yi Ma",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Xiaoqin Zhang, Zhengyuan Zhou, Di Wang , Yi Ma",
    "Groups1": "Knowledge Representation and Reasoning (KRR)",
    "Groups2": "Machine Learning Applications (MLA)",
    "Groups3": "Novel Machine Learning Algorithms (NMLA)",
    "Groups4": "Vision (VIS)",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Knowledge Representation and Reasoning (KRR);Machine Learning Applications (MLA);Novel Machine Learning Algorithms (NMLA);Vision (VIS)",
    "Keywords10": "",
    "Keywords1": "tensor completion",
    "Keywords2": "low-rank recovery",
    "Keywords3": "hybrid singular value thresholding",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "tensor completion;low-rank recovery;hybrid singular value thresholding",
    "Title": "Hybrid Singular Value Thresholding for Tensor Completion",
    "Topics10": "",
    "Topics1": "KRR: Knowledge Representation (General/Other)",
    "Topics2": "MLA: Machine Learning Applications (General/other)",
    "Topics3": "NMLA: Data Mining and Knowledge Discovery",
    "Topics4": "NMLA: Dimension Reduction/Feature Selection",
    "Topics5": "VIS: Statistical Methods and Learning",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "KRR: Knowledge Representation (General/Other);MLA: Machine Learning Applications (General/other);NMLA: Data Mining and Knowledge Discovery;NMLA: Dimension Reduction/Feature Selection;VIS: Statistical Methods and Learning"
  },
  {
    "Document Index (generated)": 6,
    "Number of Records": 1,
    "Abstract": "Hashing has recently attracted considerable attention for large scale similarity search. However, learning compact codes with good performance is still a challenge. In many cases, the real-world data lies on a low-dimensional manifold embedded in high-dimensional ambient space. To capture meaningful neighbors, a compact hashing representation should uncover the intrinsic geometric structure of the manifold, e.g., the neighborhood relationships between subregions. Most existing hashing methods only consider this issue during mapping data points into certain projected dimensions. When getting the binary codes, they either directly quantize the projected values with a threshold, or use an orthogonal matrix to refine the initial projection matrix, which both consider projection and quantization separately, and it will not well preserve the locality structure in the whole learning process. In this paper, we propose a novel hashing algorithm called Locality Preserving Hashing to effectively solve the above problems. Specifically, we learn a set of locality preserving projections with a joint optimization framework, which minimizes the average projection distance and quantization loss simultaneously. Experimental comparisons with other state-of-the-art methods on two large scale databases demonstrate the effectiveness and efficiency of our method.",
    "Authors1": "Kang Zhao",
    "Authors2": "Hongtao Lu",
    "Authors3": "Jincheng Mei",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Kang Zhao, Hongtao Lu , Jincheng Mei",
    "Groups1": "Vision (VIS)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Vision (VIS)",
    "Keywords10": "",
    "Keywords1": "Similarity Search",
    "Keywords2": "Approximate Nearest Neighbor Search",
    "Keywords3": "Binary Codes",
    "Keywords4": "Locality Preserving Hashing",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Similarity Search;Approximate Nearest Neighbor Search;Binary Codes;Locality Preserving Hashing",
    "Title": "Locality Preserving Hashing",
    "Topics10": "",
    "Topics1": "VIS: Image and Video Retrieval",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "VIS: Image and Video Retrieval"
  },
  {
    "Document Index (generated)": 7,
    "Number of Records": 1,
    "Abstract": "Selecting good conference keywords is important because they often determine the composition of review committees and hence which papers are reviewed by whom. But presently conference keywords are generated in an ad-hoc manner by a small set of conference organizers. This approach is plainly not ideal. There is no guarantee, for example, that the generated keyword set aligns with what the community is actually working on and submitting to the conference in a given year. This is especially true in fast moving fields such as AI. The problem is exacerbated by the tendency of organizers to draw heavily on preceding years' keyword lists when generating a new set. Rather than a select few ordaining a keyword set that that represents AI at large, it would be preferable to generate these keywords more directly from the data, with input from research community members. To this end, we solicited feedback from seven AAAI PC members regarding a previously existing keyword set and used these 'crowd-sourced constraints' to inform a clustering over the abstracts of all submissions to AAAI 2013. We show that the keywords discovered via this data-driven, human-in-the-loop method are at least as preferred (by AAAI PC members) as 2013's manually generated set, and that they include categories previously overlooked by organizers. Many of the discovered terms were used for this year's conference.",
    "Authors1": "Kelly Moran",
    "Authors2": "Byron Wallace",
    "Authors3": "Carla Brodley",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Kelly Moran, Byron Wallace , Carla Brodley",
    "Groups1": "Machine Learning Applications (MLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Machine Learning Applications (MLA)",
    "Keywords10": "",
    "Keywords1": "constraint-based clustering",
    "Keywords2": "machine learning",
    "Keywords3": "crowdsourcing",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "constraint-based clustering;machine learning;crowdsourcing",
    "Title": "Discovering Better AAAI Keywords via Clustering with Crowd-sourced Constraints",
    "Topics10": "",
    "Topics1": "MLA: Applications of Unsupervised Learning",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "MLA: Applications of Unsupervised Learning"
  },
  {
    "Document Index (generated)": 8,
    "Number of Records": 1,
    "Abstract": "We propose a voted dual averaging method for online\nclassification problems with explicit regularization.\nThis method employs the update rule of the regularized\ndual averaging (RDA) method proposed by Xiao, but\nonly on the subsequence of training examples where a\nclassification error is made. We derive a bound on the\nnumber of mistakes made by this method on the training\nset, as well as its generalization error rate.We also introduce\nthe concept of relative strength of regularization,\nand show how it affects the mistake bound and generalization\nperformance. We examine the method using\nℓ1-regularization on a large-scale natural language processing\ntask, and obtained state-of-the-art classification\nperformance with fairly sparse models.",
    "Authors1": "Tianbing Xu",
    "Authors2": "Jianfeng Gao",
    "Authors3": "Lin Xiao",
    "Authors4": "Amelia Regan",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Tianbing Xu, Jianfeng Gao, Lin Xiao , Amelia Regan",
    "Groups1": "Machine Learning Applications (MLA)",
    "Groups2": "NLP and Machine Learning (NLPML)",
    "Groups3": "Novel Machine Learning Algorithms (NMLA)",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Machine Learning Applications (MLA);NLP and Machine Learning (NLPML);Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "Online Classification",
    "Keywords2": "Voted Dual Averaging Method",
    "Keywords3": "Natural Language Processing",
    "Keywords4": "Parsing Reranking",
    "Keywords5": "Sparse Regularization",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Online Classification;Voted Dual Averaging Method;Natural Language Processing;Parsing Reranking;Sparse Regularization",
    "Title": "Online Classification Using a Voted RDA Method",
    "Topics10": "",
    "Topics1": "MLA: Machine Learning Applications (General/other)",
    "Topics2": "NLPML: Natural Language Processing (General/Other)",
    "Topics3": "NMLA: Big Data / Scalability",
    "Topics4": "NMLA: Classification",
    "Topics5": "NMLA: Online Learning",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "MLA: Machine Learning Applications (General/other);NLPML: Natural Language Processing (General/Other);NMLA: Big Data / Scalability;NMLA: Classification;NMLA: Online Learning"
  },
  {
    "Document Index (generated)": 9,
    "Number of Records": 1,
    "Abstract": "Fraudulent support phones\" refers to the misleading telephone numbers placed on Web pages or other media that claim to provide services with which they are not associated. Most fraudulent support phone information is found on search engine result pages (SERPs), and such information substantially degrades the search engine user experience. In this paper, we propose an approach to identify fraudulent support telephone numbers on the Web based on the co-occurrence relations between telephone numbers that appear on SERPs. We start from a small set of seed official support phone numbers and seed fraudulent numbers. Then, we construct a co-occurrence graph according to the co-occurrence relationships of the telephone numbers that appear on Web pages. Additionally, we take the page layout information into consideration on the assumption that telephone numbers that appear in nearby page blocks should be regarded as more closely related. Finally, we develop a propagation algorithm to diffuse the trust scores of seed official support phone numbers and the distrust scores of the seed fraudulent numbers on the co-occurrence graph to detect additional fraudulent numbers. Experimental results based on over 1.5 million SERPs produced by a popular Chinese commercial search engine indicate that our approach outperforms TrustRank, Anti-TrustRank and Good-Bad Rank algorithms by achieving an AUC value of over 0.90.",
    "Authors1": "Xin Li",
    "Authors2": "Yiqun Liu",
    "Authors3": "Min Zhang",
    "Authors4": "Shaoping Ma",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Xin Li, Yiqun Liu, Min Zhang , Shaoping Ma",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW)",
    "Keywords10": "",
    "Keywords1": "Fraudulent Support Telephone Number",
    "Keywords2": "Co-occurrence Graph",
    "Keywords3": "Propagation Algorithm",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Fraudulent Support Telephone Number;Co-occurrence Graph;Propagation Algorithm",
    "Title": "Fraudulent Support Telephone Number Identification Based on Co-occurrence Information on the Web",
    "Topics10": "",
    "Topics1": "AIW: Enhancing web search and information retrieval",
    "Topics2": "AIW: Recognizing web spam such as link farms and splogs",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: Enhancing web search and information retrieval;AIW: Recognizing web spam such as link farms and splogs"
  },
  {
    "Document Index (generated)": 10,
    "Number of Records": 1,
    "Abstract": "Hashing is a popular approximate nearest neighbor search approach in large-scale image retrieval. Supervised hashing, which incorporates similarity/dissimilarity information on entity pairs to improve the quality of hashing function learning, has recently received increasing attention. However, in the existing supervised hashing methods for images, an input image is usually encoded by a vector of hand-crafted visual features. Such hand-crafted feature vectors do not necessary preserve the accurate semantic similarities of images pairs, which may often degrade the performance of hashing function learning. In this paper, we propose a supervised hashing method for image search, in which we automatically learn a good image representation tailored to hashing as well as a set of hash functions. The proposed method has two stages. In the first stage, given the pairwise similarity matrix $S$ on pairs of training images, we propose a scalable coordinate descent method to decompose $S$ into a product of $HH^T$ where $H$ is a matrix with each of its row being the approximate hash code associated to a training image. In the second stage, we propose to simultaneously learn a good feature representation for the input images as well as a set of hash functions, via a deep convolutional network tailored to the learned hash codes in $H$ or the discrete class labels of the images. Extensive empirical evaluations on three benchmark datasets with different kinds of images show that the proposed method has superior performance gains over several state-of-the-art supervised and unsupervised hashing methods.",
    "Authors1": "Rongkai Xia",
    "Authors2": "Yan Pan",
    "Authors3": "Hanjiang Lai",
    "Authors4": "Cong Liu",
    "Authors5": "Shuicheng Yan",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Rongkai Xia, Yan Pan, Hanjiang Lai, Cong Liu , Shuicheng Yan",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "Vision (VIS)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA);Vision (VIS)",
    "Keywords10": "",
    "Keywords1": "supervised hashing",
    "Keywords2": "approximate near neighbor search",
    "Keywords3": "representation learning",
    "Keywords4": "convolutional neural networks",
    "Keywords5": "coordinate descent",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "supervised hashing;approximate near neighbor search;representation learning;convolutional neural networks;coordinate descent",
    "Title": "Supervised Hashing for Image Retrieval via Image Representation Learning",
    "Topics10": "",
    "Topics1": "NMLA: Neural Networks/Deep Learning",
    "Topics2": "VIS: Image and Video Retrieval",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Neural Networks/Deep Learning;VIS: Image and Video Retrieval"
  },
  {
    "Document Index (generated)": 11,
    "Number of Records": 1,
    "Abstract": "Partial MaxSAT (PMS) is a generalization to SAT and MaxSAT. Many real world problems can be encoded into PMS in a more natural and compact way than SAT and MaxSAT. In this paper, we propose new ideas for local search for PMS, which mainly rely on the distinction between hard and soft clauses. We then use these ideas to develop a local search PMS algorithm called Dist. Experimental results on PMS benchmarks from MaxSAT Evaluation 2013 show that Dist significantly outperforms state-of-the-art PMS algorithms, including both local search algorithms and complete ones, on random and crafted benchmarks. For the industrial benchmark, Dist dramatically outperforms previous local search algorithms and is comparable and complementary to complete algorithms.",
    "Authors1": "Shaowei Cai",
    "Authors2": "Chuan Luo",
    "Authors3": "Kaile Su",
    "Authors4": "John Thornton",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Shaowei Cai, Chuan Luo, Kaile Su , John Thornton",
    "Groups1": "Heuristic Search and Optimization (HSO)",
    "Groups2": "Search and Constraint Satisfaction (SCS)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Heuristic Search and Optimization (HSO);Search and Constraint Satisfaction (SCS)",
    "Keywords10": "",
    "Keywords1": "Partial MaxSAT",
    "Keywords2": "Local Search",
    "Keywords3": "Heuristics",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Partial MaxSAT;Local Search;Heuristics",
    "Title": "Tailoring Local Search for Partial MaxSAT",
    "Topics10": "",
    "Topics1": "HSO: Heuristic Search",
    "Topics2": "HSO: Optimization",
    "Topics3": "SCS: Constraint Optimization",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "HSO: Heuristic Search;HSO: Optimization;SCS: Constraint Optimization"
  },
  {
    "Document Index (generated)": 12,
    "Number of Records": 1,
    "Abstract": "We present a new Markov Chain Monte Carlo (MCMC) sampling algorithm for probabilistic programs. Our approach and tool, called R2, has the unique feature of employing program analysis in order to improve the efficiency of MCMC sampling. Given an input program P, R2 propagates observations in P backwards to obtain a semantically equivalent program P' in which every probabilistic assignment is immediately followed by an observe statement. Inference is performed by a suitably modified version of the Metropolis-Hastings algorithm that exploits the structure of the program P0. This has the overall effect of preventing rejections due to program executions that fail to satisfy observations in P. We formalize the semantics of probabilistic programs and rigorously prove the correctness of R2.We also empirically demonstrate the effectiveness of R2—--in particular, we show that R2 is able to produce results of similar quality as the Church and Stan probabilistic programming tools with much shorter execution time.",
    "Authors1": "Aditya Nori",
    "Authors2": "Chung-Kil Hur",
    "Authors3": "Sriram Rajamani",
    "Authors4": "Selva Samuel",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Aditya Nori, Chung-Kil Hur, Sriram Rajamani , Selva Samuel",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "Reasoning under Uncertainty (RU)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA);Reasoning under Uncertainty (RU)",
    "Keywords10": "",
    "Keywords1": "Probabilistic programming",
    "Keywords2": "Program analysis",
    "Keywords3": "Sampling",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Probabilistic programming;Program analysis;Sampling",
    "Title": "R2: An Efficient MCMC Sampler for Probabilistic Programs",
    "Topics10": "",
    "Topics1": "MLA: Machine Learning Applications (General/other)",
    "Topics2": "NMLA: Bayesian Learning",
    "Topics3": "RU: Bayesian Networks",
    "Topics4": "RU: Graphical Models (Other)",
    "Topics5": "RU: Probabilistic Inference",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "MLA: Machine Learning Applications (General/other);NMLA: Bayesian Learning;RU: Bayesian Networks;RU: Graphical Models (Other);RU: Probabilistic Inference"
  },
  {
    "Document Index (generated)": 13,
    "Number of Records": 1,
    "Abstract": "Mutual information (MI) based approaches are an important feature selection paradigm. Although the stated goal of MI-based feature selection is to identify a subset of features that share the highest mutual information with the class variable, most current MI-based techniques are greedy methods that make use of low dimensional MI quantities. The reason for using low dimensional approximation has been mostly attributed to the difficulty associated with estimating the high dimensional MI from limited samples. In this paper, we argue a different viewpoint that,  given a  very large amount of data, the high dimensional MI objective  is still problematic to be employed as a meaningful optimization criterion, due to its overfitting nature: the MI almost always increases as more features are added, thus leading to a trivial solution which includes all features. We  propose a novel approach to the MI-based feature selection problem, in which the overfitting phenomenon is controlled rigourously by means of a statistical test. We develop local and global optimization algorithms for this new feature selection model, and demonstrate its effectiveness in the applications of explaining variables and objects.",
    "Authors1": "Vinh Nguyen",
    "Authors2": "Jeffrey Chan",
    "Authors3": "James Bailey",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Vinh Nguyen, Jeffrey Chan , James Bailey",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "feature selection",
    "Keywords2": "mutual information",
    "Keywords3": "global optimization",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "feature selection;mutual information;global optimization",
    "Title": "Reconsidering Mutual Information Based Feature Selection: A Statistical Significance View",
    "Topics10": "",
    "Topics1": "NMLA: Data Mining and Knowledge Discovery",
    "Topics2": "NMLA: Dimension Reduction/Feature Selection",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Data Mining and Knowledge Discovery;NMLA: Dimension Reduction/Feature Selection"
  },
  {
    "Document Index (generated)": 14,
    "Number of Records": 1,
    "Abstract": "Influence maximization problem is to find a set of seed\nnodes in a social network such that their influence\nspread is maximized under certain propagation models.\nA few algorithms have been proposed for this problem.\nHowever, they have not considered the impact of\nnovelty decay in influence propagation, i.e., repeated\nexposures will have diminishing influence on users. In\nthis paper, we consider the problem of influence max-\nimization with novelty decay (IMND). We investigate\nthe effect of novelty decay on influence propagation in\nreal-life datasets and formulate the IMND problem. We\nfurther analyze its relevant properties and propose an\ninfluence estimation technique. We demonstrate perfor-\nmance of our algorithms over four social networks.",
    "Authors1": "Shanshan Feng",
    "Authors2": "Xuefeng Chen",
    "Authors3": "Gao Cong",
    "Authors4": "Yifeng Zeng",
    "Authors5": "Yeow Meng Chee",
    "Authors6": "Yanping Xiang",
    "Authors7": "",
    "Authors": "Shanshan Feng, Xuefeng Chen, Gao Cong, Yifeng Zeng, Yeow Meng Chee , Yanping Xiang",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW)",
    "Keywords10": "",
    "Keywords1": "social networks",
    "Keywords2": "influence maximization",
    "Keywords3": "novelty decay",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "social networks;influence maximization;novelty decay",
    "Title": "Influence Maximization with Novelty Decay in Social Networks",
    "Topics10": "",
    "Topics1": "AIW: Social networking and community identification",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: Social networking and community identification"
  },
  {
    "Document Index (generated)": 15,
    "Number of Records": 1,
    "Abstract": "While Markov decision processes (MDPs) are powerful tools for modeling sequential decision making problems under uncertainty, they are sensitive to the accuracy of their parameters. MDPs with uncertainty in their parameters are called Uncertain MDPs. In this paper, we introduce a general framework that allows off-the-shelf MDP algorithms to solve Uncertain MDPs by planning based on currently available information and replan if and when the problem changes. We demonstrate the generality of this approach by showing that it can use the VI, TVI, ILAO*, LRTDP, and UCT algorithms to solve Uncertain MDPs. We experimentally show that our approach is typically faster than replanning from scratch and we also provide a way to estimate the amount of speedup based on the amount of information is reused.",
    "Authors1": "Ping Hou",
    "Authors2": "William Yeoh",
    "Authors3": "Tran Cao Son",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Ping Hou, William Yeoh , Tran Cao Son",
    "Groups1": "Planning and Scheduling (PS)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Planning and Scheduling (PS)",
    "Keywords10": "",
    "Keywords1": "Markov Decision Processes (MDPs)",
    "Keywords2": "Replanning",
    "Keywords3": "Incremental Search",
    "Keywords4": "Uncertain MDPs",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Markov Decision Processes (MDPs);Replanning;Incremental Search;Uncertain MDPs",
    "Title": "Solving Uncertain MDPs by Reusing State Information and Plans",
    "Topics10": "",
    "Topics1": "PS: Probabilistic Planning",
    "Topics2": "PS: Replanning and Plan Repair",
    "Topics3": "PS: Planning (General/Other)",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "PS: Probabilistic Planning;PS: Replanning and Plan Repair;PS: Planning (General/Other)"
  },
  {
    "Document Index (generated)": 16,
    "Number of Records": 1,
    "Abstract": "We consider the task of grouping doctors with respect to communication patterns exhibited in outpatient visits. We propose a novel approach toward this end in which we model speech act transitions in conversations via a log-linear model incorporating physician specific components. We train this model over transcripts of outpatient visits annotated with speech act codes and then cluster physicians in (a transformation of) this parameter space. We find significant correlations between the induced groupings and patient survey response data comprising ratings of physician communication. Furthermore, the novel sequential component model we leverage to induce this clustering allows us to explore differences across these groups. This work demonstrates how statistical AI might be used to better understand (and ultimately improve) physician communication.",
    "Authors1": "Byron Wallace",
    "Authors2": "Issa Dahabreh",
    "Authors3": "Michael Barton Laws",
    "Authors4": "Ira Wilson",
    "Authors5": "Thomas Trikalinos",
    "Authors6": "Eugene Charniak",
    "Authors7": "",
    "Authors": "Byron Wallace, Issa Dahabreh, Michael Barton Laws, Ira Wilson, Thomas Trikalinos , Eugene Charniak",
    "Groups1": "Applications (APP)",
    "Groups2": "Machine Learning Applications (MLA)",
    "Groups3": "NLP and Machine Learning (NLPML)",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Applications (APP);Machine Learning Applications (MLA);NLP and Machine Learning (NLPML)",
    "Keywords10": "",
    "Keywords1": "Conversation modeling",
    "Keywords2": "Patient-doctor communication",
    "Keywords3": "Sequential component model",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Conversation modeling;Patient-doctor communication;Sequential component model",
    "Title": "Identifying Differences in Physician Communication Styles with a Log-Linear Transition Component Model",
    "Topics10": "",
    "Topics1": "APP: Biomedical / Bioinformatics",
    "Topics2": "MLA: Bio/Medicine",
    "Topics3": "MLA: Applications of Supervised Learning",
    "Topics4": "NLPML: Discourse and Dialogue",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "APP: Biomedical / Bioinformatics;MLA: Bio/Medicine;MLA: Applications of Supervised Learning;NLPML: Discourse and Dialogue"
  },
  {
    "Document Index (generated)": 17,
    "Number of Records": 1,
    "Abstract": "Kidney exchange, where candidates with organ failure trade incompatible but willing donors, is a life-saving alternative to the deceased donor waitlist, which has inadequate supply to meet demand.  While fielded kidney exchanges see huge benefit from altruistic kidney donors (who give an organ without a paired needy candidate), a significantly higher medical risk to the donor deters similar altruism with livers.  In this paper, we begin by proposing the idea of liver exchange, and show on demographically accurate data that vetted kidney exchange algorithms can be adapted to clear such an exchange at the nationwide level.  We then explore cross-organ donation where kidneys and livers can be bartered for each other.  We show theoretically that this multi-organ exchange provides linearly more transplants than running separate kidney and liver exchanges; this linear gain is a product of altruistic kidney donors creating chains that thread through the liver pool.  We support this result experimentally on demographically accurate multi-organ exchanges.  We conclude with thoughts regarding the fielding of a nationwide liver or joint liver-kidney exchange from a legal and computational point of view.",
    "Authors1": "John Dickerson",
    "Authors2": "Tuomas S",
    "Authors3": "holm",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "John Dickerson , Tuomas S,holm",
    "Groups1": "Applications (APP)",
    "Groups2": "Game Theory and Economic Paradigms (GTEP)",
    "Groups3": "Multiagent Systems (MAS)",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Applications (APP);Game Theory and Economic Paradigms (GTEP);Multiagent Systems (MAS)",
    "Keywords10": "",
    "Keywords1": "Kidney exchange",
    "Keywords2": "Sparse random graphs",
    "Keywords3": "Computational economics",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Kidney exchange;Sparse random graphs;Computational economics",
    "Title": "Multi-Organ Exchange: The Whole is Greater than the Sum of its Parts",
    "Topics10": "",
    "Topics1": "APP: Biomedical / Bioinformatics",
    "Topics2": "GTEP: Auctions and Market-Based Systems",
    "Topics3": "MAS: Mechanism Design",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "APP: Biomedical / Bioinformatics;GTEP: Auctions and Market-Based Systems;MAS: Mechanism Design"
  },
  {
    "Document Index (generated)": 18,
    "Number of Records": 1,
    "Abstract": "Data quality is a common source of concern for large-scale citizen science projects like eBird. In the case of eBird, a major cause of poor quality data is the misidentification of bird species by inexperienced contributors. A proactive approach for improving data quality is to identify commonly misidentified bird species and to teach inexperienced birders the differences between these species. In this paper, we develop a latent variable graphical model that can identify groups of bird species that are often confused for each other by eBird participants. Our model is a multi-species extension of the classic occupancy-detection model in the ecology literature. This multi-species extension is non-trivial, requiring a structure learning step as well as a computationally expensive parameter learning stage which we make efficient through a variational approximation. We show that by including these species misidentifications in the model, we can not only discover these misidentifications but predictions of both species occupancy and detection are also more accurate.",
    "Authors1": "Jun Yu",
    "Authors2": "Rebecca Hutchinson",
    "Authors3": "Weng-Keen Wong",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Jun Yu, Rebecca Hutchinson , Weng-Keen Wong",
    "Groups1": "Computational Sustainability and AI (CSAI)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Computational Sustainability and AI (CSAI)",
    "Keywords10": "",
    "Keywords1": "Probabilistic Graphical Model",
    "Keywords2": "Crowdsourcing",
    "Keywords3": "Citizen Science",
    "Keywords4": "Ecology",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Probabilistic Graphical Model;Crowdsourcing;Citizen Science;Ecology",
    "Title": "A Latent Variable Model for Discovering Bird Species Commonly Misidentified by Citizen Scientists",
    "Topics10": "",
    "Topics1": "CSAI: Modeling and prediction of dynamic and spatiotemporal phenomena and systems",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "CSAI: Modeling and prediction of dynamic and spatiotemporal phenomena and systems"
  },
  {
    "Document Index (generated)": 19,
    "Number of Records": 1,
    "Abstract": "Nowadays images on social networking websites (e.g., Flickr) are mostly accompanied with user-contributed tags, which help cast a new light on the conventional content-based image analysis tasks such as image classification and retrieval. In order to establish a scalable social image analysis system, two issues need to be considered: 1) Supervised learning is a futile task in modeling the enormous number of concepts in the world, whereas unsupervised approaches overcome this hurdle; 2) Algorithms are required to be both spatially and temporally efficient to handle large-scale datasets. In this paper, we propose a cross-view feature learning (CVFL) framework to handle the problem of social image analysis effectively and efficiently. Through explicitly modeling the relevance between image content and tags (which is empirically shown to be visually and semantically meaningful), CVFL yields more promising results than existing methods in the experiments. More importantly, being general and descriptive, CVFL and its variants can be readily applied to other large-scale multi-view tasks in unsupervised setting.",
    "Authors1": "Wenxuan Xie",
    "Authors2": "Yuxin Peng",
    "Authors3": "Jianguo Xiao",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Wenxuan Xie, Yuxin Peng , Jianguo Xiao",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW)",
    "Keywords10": "",
    "Keywords1": "Cross-View Learning",
    "Keywords2": "Feature Learning",
    "Keywords3": "Random Projection",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Cross-View Learning;Feature Learning;Random Projection",
    "Title": "Cross-View Feature Learning for Scalable Social Image Analysis",
    "Topics10": "",
    "Topics1": "AIW: AI for multimedia and multimodal web applications",
    "Topics2": "AIW: Enhancing web search and information retrieval",
    "Topics3": "AIW: Machine learning and the web",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: AI for multimedia and multimodal web applications;AIW: Enhancing web search and information retrieval;AIW: Machine learning and the web"
  },
  {
    "Document Index (generated)": 20,
    "Number of Records": 1,
    "Abstract": "We investigate weakly-supervised image parsing, i.e., assigning class labels to image regions by using image-level labels only. Existing studies pay main attention to the formulation of the weakly-supervised learning problem, i.e., how to propagate class labels from images to regions given an affinity graph of regions. Notably, however, the affinity graph of regions, which is generally constructed in relatively simpler settings in existing methods, is of crucial importance to the parsing performance due to the fact that the weakly-supervised parsing problem cannot be solved within a single image, and that the affinity graph enables label propagation among multiple images. In order to embed more semantics into the affinity graph, we propose novel criteria by exploiting the weak supervision information carefully, and develop two graphs: L1 semantic graph and k-NN semantic graph. Experimental results demonstrate that the proposed semantic graphs not only capture more semantic relevance, but also perform significantly better than conventional graphs in image parsing.",
    "Authors1": "Wenxuan Xie",
    "Authors2": "Yuxin Peng",
    "Authors3": "Jianguo Xiao",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Wenxuan Xie, Yuxin Peng , Jianguo Xiao",
    "Groups1": "Vision (VIS)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Vision (VIS)",
    "Keywords10": "",
    "Keywords1": "Weakly-Supervised Learning",
    "Keywords2": "Image Parsing",
    "Keywords3": "Graph Construction",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Weakly-Supervised Learning;Image Parsing;Graph Construction",
    "Title": "Semantic Graph Construction for Weakly-Supervised Image Parsing",
    "Topics10": "",
    "Topics1": "VIS: Categorization",
    "Topics2": "VIS: Object Recognition",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "VIS: Categorization;VIS: Object Recognition"
  },
  {
    "Document Index (generated)": 21,
    "Number of Records": 1,
    "Abstract": "Agency – the capacity to plan and act – and experience – the capacity to sense and feel – are two critical aspects that determine whether people will perceive non-human entities, such as autonomous agents, to have a mind. There is evidence that the absence of either can reduce cooperation. We present an experiment that tests the necessity of both for cooperation with agents. In this experiment we manipulated people’s perceptions about the cognitive and affective abilities of agents, when engaging in the ultimatum game. The results indicated that people offered more money to agents that were perceived to make decisions according to their intentions, rather than randomly. Additionally, the results showed that people offered more money to agents that expressed emotion, when compared to agents that did not. We discuss the implications of this agency-experience theoretical framework for the design of artificially intelligent decision makers.",
    "Authors1": "Celso de Melo",
    "Authors2": "Jonathan Gratch",
    "Authors3": "Peter Carnevale",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Celso de Melo, Jonathan Gratch , Peter Carnevale",
    "Groups1": "Cognitive Modeling (CM)",
    "Groups2": "Cognitive Systems (CS)",
    "Groups3": "Humans and AI (HAI)",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Cognitive Modeling (CM);Cognitive Systems (CS);Humans and AI (HAI)",
    "Keywords10": "",
    "Keywords1": "Mind perception",
    "Keywords2": "cognition",
    "Keywords3": "affect",
    "Keywords4": "Decision making",
    "Keywords5": "cooperation",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Mind perception;cognition;affect;Decision making;cooperation",
    "Title": "The Importance of Cognition and Affect for Artificially Intelligent Decision Makers",
    "Topics10": "",
    "Topics1": "CM: Simulating Humans",
    "Topics2": "CS: Problem solving and decision making",
    "Topics3": "HAI: Human-Computer Interaction",
    "Topics4": "HAI: Understanding People, Theories, Concepts and Methods",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "CM: Simulating Humans;CS: Problem solving and decision making;HAI: Human-Computer Interaction;HAI: Understanding People, Theories, Concepts and Methods"
  },
  {
    "Document Index (generated)": 22,
    "Number of Records": 1,
    "Abstract": "Recent work introduced Generalized First Order Decision Diagrams (GFODD) as a knowledge representation that is useful in mechanizing decision theoretic planning in relational domains. GFODDs generalize function-free first order logic and include numerical values and numerical generalizations of existential and universal quantification. Previous work presented heuristic inference algorithms for GFODDs. In this paper, we study the complexity of the evaluation problem, the satiability problem, and the equivalence problem for GFODDs under the assumption that the size of the intended model is given with the problem, a restriction that guarantees decidability. Our results provide a complete characterization. The same characterization applies to the corresponding restriction of problems in first order logic, giving an interesting new avenue for efficient inference when the number of objects is bounded. Our results show that for $\\Sigma_k$ formulas, and for corresponding GFODDs, evaluation and satisfiability are $\\Sigma_k^p$ complete, and equivalence is $\\Pi_{k+1}^p$ complete. For $\\Pi_k$ formulas evaluation is $\\Pi_k^p$ complete, satisfiability is one level higher and is $\\Sigma_{k+1}^p$ complete, and equivalence is $\\Pi_{k+1}^p$ complete.",
    "Authors1": "Benjamin Hescott",
    "Authors2": "Roni Khardon",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Benjamin Hescott , Roni Khardon",
    "Groups1": "Knowledge Representation and Reasoning (KRR)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Knowledge Representation and Reasoning (KRR)",
    "Keywords10": "",
    "Keywords1": "Decision Diagrams",
    "Keywords2": "Computational Complexity",
    "Keywords3": "First Order Logic",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Decision Diagrams;Computational Complexity;First Order Logic",
    "Title": "The Complexity of Reasoning with FODD and GFODD",
    "Topics10": "",
    "Topics1": "KRR: Automated Reasoning and Theorem Proving",
    "Topics2": "KRR: Computational Complexity of Reasoning",
    "Topics3": "KRR: Knowledge Representation Languages",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "KRR: Automated Reasoning and Theorem Proving;KRR: Computational Complexity of Reasoning;KRR: Knowledge Representation Languages"
  },
  {
    "Document Index (generated)": 23,
    "Number of Records": 1,
    "Abstract": "A large number of interdependent issues in complex contract poses a challenge for current negotiation approaches, which becomes even more apparent when negotiation problems scale up. To address this challenge, we present a structured anytime search process with agenda management mechanism using a hierarchical negotiation model, where agents search at various levels during the negotiation with the guidance from a mediator agent. This structured negotiation process increases computational efficiency, making negotiations scalable for large number of interdependent issues. To validate the contributions of our approach, 1) we developed anytime tree search negotiation process with an agenda management mechanism using a hierarchical problem structure and constraint-based preference model for real-world applications; 2) we defined a scenario matrix to capture various characteristics of negotiation scenarios and developed a scenario generator that produces testing cases according to this matrix; and 3) we performed an extensive set of experiments to study the performance of this structured negotiation protocol and the influence of different scenario parameters, and investigated the Pareto efficiency and social welfare optimality of the negotiation outcomes.",
    "Authors1": "Xiaoqin Zhang",
    "Authors2": "Mark Klein",
    "Authors3": "Ivan Marsa Maestre",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Xiaoqin Zhang, Mark Klein , Ivan Marsa Maestre",
    "Groups1": "Multiagent Systems (MAS)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Multiagent Systems (MAS)",
    "Keywords10": "",
    "Keywords1": "Large-scale Negotiation",
    "Keywords2": "Interdependent Issues",
    "Keywords3": "Complex Contracts",
    "Keywords4": "agenda management",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Large-scale Negotiation;Interdependent Issues;Complex Contracts;agenda management",
    "Title": "Scalable Complex Contract Negotiation With Structured Search and Agenda Management",
    "Topics10": "",
    "Topics1": "MAS: Distributed Problem Solving",
    "Topics2": "MAS: Mechanism Design",
    "Topics3": "MAS: Multiagent Systems (General/other)",
    "Topics4": "SCS: Distributed CSP/Optimization",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "MAS: Distributed Problem Solving;MAS: Mechanism Design;MAS: Multiagent Systems (General/other);SCS: Distributed CSP/Optimization"
  },
  {
    "Document Index (generated)": 24,
    "Number of Records": 1,
    "Abstract": "Classical approaches to visualization directly reduce a document's high-dimensional representation into visualizable two or three dimensions, using techniques such as multidimensional scaling.  More recent approaches consider an intermediate representation in topic space, between word space and visualization space, which preserves the semantics by topic modeling.  We call the latter semantic visualization problem, as it seeks to jointly model topic and visualization. While previous approaches aim to preserve the global consistency, they do not consider the local consistency in terms of the intrinsic geometric structure of the document manifold.  We therefore propose an unsupervised probabilistic model, called Semafore, which aims to preserve the manifold in the lower-dimensional spaces.  Comprehensive experiments on several real-life text datasets of news articles and web pages show that Semafore significantly outperforms the state-of-the-art baselines on objective evaluation metrics.",
    "Authors1": "Tuan Le",
    "Authors2": "Hady Lauw",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Tuan Le , Hady Lauw",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "document visualization",
    "Keywords2": "dimensionality reduction",
    "Keywords3": "topic model",
    "Keywords4": "manifold learning",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "document visualization;dimensionality reduction;topic model;manifold learning",
    "Title": "Manifold Learning for Jointly Modeling Topic and Visualization",
    "Topics10": "",
    "Topics1": "NMLA: Data Mining and Knowledge Discovery",
    "Topics2": "NMLA: Dimension Reduction/Feature Selection",
    "Topics3": "NMLA: Graphical Model Learning",
    "Topics4": "NMLA: Unsupervised Learning (Other)",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Data Mining and Knowledge Discovery;NMLA: Dimension Reduction/Feature Selection;NMLA: Graphical Model Learning;NMLA: Unsupervised Learning (Other)"
  },
  {
    "Document Index (generated)": 25,
    "Number of Records": 1,
    "Abstract": "We consider the problem of constructing a symbolic description of a continuous, low-level environment for use in planning. We show that  symbols that can represent the preconditions and effects of an agent's actions are both necessary and sufficient for high-level planning.  This enables reinforcement learning agents to acquire their own symbolic representations autonomously, and eliminates the symbol design problem when a representation must be constructed in advance. The resulting representation can be converted into PDDL, a canonical planning representation that enables very fast planning.",
    "Authors1": "George Konidaris",
    "Authors2": "Leslie Kaelbling",
    "Authors3": "Tomas Lozano-Perez",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "George Konidaris, Leslie Kaelbling , Tomas Lozano-Perez",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "Reinforcement learning",
    "Keywords2": "Planning",
    "Keywords3": "Representation",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Reinforcement learning;Planning;Representation",
    "Title": "Constructing Symbolic Representations for High-Level Planning",
    "Topics10": "",
    "Topics1": "NMLA: Reinforcement Learning",
    "Topics2": "PS: Learning Models for Planning and Diagnosis",
    "Topics3": "ROB: Cognitive Robotics",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Reinforcement Learning;PS: Learning Models for Planning and Diagnosis;ROB: Cognitive Robotics"
  },
  {
    "Document Index (generated)": 26,
    "Number of Records": 1,
    "Abstract": "As robots become more ubiquitous, it is increasingly important for untrained users to be able to interact with them intuitively. In this work, we investigate how people refer to objects in the world during relatively unstructured communication with robots. We collect a corpus of interactions from users describing objects, which we use to train language and gesture models that allow our robot to determine what objects are being indicated. We introduce a temporal extension to state-of-the-art hierarchical matching pursuit features to support gesture understanding, and demonstrate that combining multiple communication modalities more effectively captures user intent than relying on a single type of input. Finally, we present initial interactions with a robot that uses the learned models to follow commands while continuing to learn from user input.",
    "Authors1": "Cynthia Matuszek",
    "Authors2": "Liefeng Bo",
    "Authors3": "Luke Zettlemoyer",
    "Authors4": "Dieter Fox",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Cynthia Matuszek, Liefeng Bo, Luke Zettlemoyer , Dieter Fox",
    "Groups1": "Humans and AI (HAI)",
    "Groups2": "NLP and Machine Learning (NLPML)",
    "Groups3": "Robotics (ROB)",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Humans and AI (HAI);NLP and Machine Learning (NLPML);Robotics (ROB)",
    "Keywords10": "",
    "Keywords1": "Human-Robot Interaction",
    "Keywords2": "Robotics",
    "Keywords3": "Natural Language Processing",
    "Keywords4": "ML classifier features",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Human-Robot Interaction;Robotics;Natural Language Processing;ML classifier features",
    "Title": "Towards Understanding Unscripted Gesture and Language Input for Human-Robot Interactions",
    "Topics10": "",
    "Topics1": "APP: Other Applications",
    "Topics2": "HAI: Language Acquisition",
    "Topics3": "MLA: Machine Learning Applications (General/other)",
    "Topics4": "NLPML: Natural Language Processing (General/Other)",
    "Topics5": "NMLA: Time-Series/Data Streams",
    "Topics6": "ROB: Human-Robot Interaction",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "APP: Other Applications;HAI: Language Acquisition;MLA: Machine Learning Applications (General/other);NLPML: Natural Language Processing (General/Other);NMLA: Time-Series/Data Streams;ROB: Human-Robot Interaction"
  },
  {
    "Document Index (generated)": 27,
    "Number of Records": 1,
    "Abstract": "The frequency and intensity of natural disasters has significantly increased over the past decades and this trend is predicted to continue. Facing these unexpected disasters, urban emergency management has become the especially important issue for the whole governments around the world. In this paper, we present a novel intelligent system for urban emergency management during the large-scale disasters. The proposed system stores and manages the global positioning system (GPS) records from mobile devices used by approximately 1.6 million people throughout Japan from 1 August 2010 to 31 July 2011. By mining and analyzing population movements after the Great East Japan Earthquake, our system is able to automatically learn a probabilistic model to better understand and simulate human mobility during the emergency situations. Based on the learning model, population mobility in various urban areas impacted by the earthquake throughout Japan is able to be automatically simulated or predicted. On the basis of such kind of system, it is easy for us to find some new features or population mobility patterns after the recent and unprecedented composite disasters, which are likely to provide the valuable experiences and play a vital role for future disaster management worldwide.",
    "Authors1": "Xuan Song",
    "Authors2": "Quanshi Zhang",
    "Authors3": "Ryosuke Shibasaki",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Xuan Song, Quanshi Zhang , Ryosuke Shibasaki",
    "Groups1": "Computational Sustainability and AI (CSAI)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Computational Sustainability and AI (CSAI)",
    "Keywords10": "",
    "Keywords1": "Emergency Management",
    "Keywords2": "Disaster Informatics",
    "Keywords3": "Human Mobility",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Emergency Management;Disaster Informatics;Human Mobility",
    "Title": "Intelligent System for Urban Emergency Management During Large-scale Disaster",
    "Topics10": "",
    "Topics1": "CSAI: Modeling and prediction of dynamic and spatiotemporal phenomena and systems",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "CSAI: Modeling and prediction of dynamic and spatiotemporal phenomena and systems"
  },
  {
    "Document Index (generated)": 28,
    "Number of Records": 1,
    "Abstract": "The NP-hard number-partitioning problem is to separate a multiset\n  S of n positive integers into k subsets, such that the largest\n  sum of the integers assigned to any subset is minimized. The classic\n  application is scheduling a set of n jobs with different run times\n  onto k identical machines such that the makespan, the time to\n  complete the schedule, is minimized. We present a new algorithm,\n  cached iterative weakening (CIW), for solving this problem\n  optimally. It incorporates three ideas distinct from the previous\n  state of the art: it explores the search space using iterative\n  weakening instead of branch and bound; generates feasible subsets\n  once and caches them instead of at each node of the search tree; and\n  explores subsets in cardinality order instead of an arbitrary\n  order. The previous state of the art is represented by three different\n  algorithms depending on the values of n and k. We provide one\n  algorithm which outperforms all previous algorithms for k >=\n  4. Our run times are up to two orders of magnitude faster.",
    "Authors1": "Ethan Schreiber",
    "Authors2": "Richard Korf",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Ethan Schreiber , Richard Korf",
    "Groups1": "Heuristic Search and Optimization (HSO)",
    "Groups2": "Planning and Scheduling (PS)",
    "Groups3": "Search and Constraint Satisfaction (SCS)",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Heuristic Search and Optimization (HSO);Planning and Scheduling (PS);Search and Constraint Satisfaction (SCS)",
    "Keywords10": "",
    "Keywords1": "Heuristic Search",
    "Keywords2": "Optimization",
    "Keywords3": "Search",
    "Keywords4": "Scheduling",
    "Keywords5": "Constraint Optimization",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Heuristic Search;Optimization;Search;Scheduling;Constraint Optimization",
    "Title": "Cached Iterative Weakening for Optimal Multi-Way Number Partitioning",
    "Topics10": "",
    "Topics1": "HSO: Heuristic Search",
    "Topics2": "HSO: Optimization",
    "Topics3": "HSO: Search (General/Other)",
    "Topics4": "PS: Scheduling",
    "Topics5": "SCS: Constraint Satisfaction",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "HSO: Heuristic Search;HSO: Optimization;HSO: Search (General/Other);PS: Scheduling;SCS: Constraint Satisfaction"
  },
  {
    "Document Index (generated)": 29,
    "Number of Records": 1,
    "Abstract": "The explosive use of social media also makes it a popular platform for malicious users, known as social spammers, to overwhelm normal users with unwanted content. One effective way for social spammer detection is to build a classifier based on content and social network information. However, social spammers are sophisticated and adaptable to game the system with fast evolving content and network patterns. First, social spammers continually change their spamming content patterns to avoid being detected.  Second, reflexive reciprocity makes it easier for social spammers to establish social influence and pretend to be normal users by quickly accumulating a large number of ``human\" friends. It is challenging for existing anti-spamming systems based on batch-mode learning to quickly respond to newly emerging patterns for effective social spammer detection. In this paper, we present a general optimization framework to collectively use content and network information for social spammer detection, and provide the solution for efficient online processing. Experimental results on Twitter datasets confirm the  effectiveness and efficiency of the proposed framework.",
    "Authors1": "Xia Hu",
    "Authors2": "Jiliang Tang",
    "Authors3": "Huan Liu",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Xia Hu, Jiliang Tang , Huan Liu",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "Machine Learning Applications (MLA)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW);Machine Learning Applications (MLA)",
    "Keywords10": "",
    "Keywords1": "Social Media",
    "Keywords2": "Social Spammer",
    "Keywords3": "Online Learning",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Social Media;Social Spammer;Online Learning",
    "Title": "Online Social Spammer Detection",
    "Topics10": "",
    "Topics1": "AIW: Machine learning and the web",
    "Topics2": "AIW: Recognizing web spam such as link farms and splogs",
    "Topics3": "AIW: Web personalization and user modeling",
    "Topics4": "MLA: Machine Learning Applications (General/other)",
    "Topics5": "NMLA: Data Mining and Knowledge Discovery",
    "Topics6": "NMLA: Online Learning",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: Machine learning and the web;AIW: Recognizing web spam such as link farms and splogs;AIW: Web personalization and user modeling;MLA: Machine Learning Applications (General/other);NMLA: Data Mining and Knowledge Discovery;NMLA: Online Learning"
  },
  {
    "Document Index (generated)": 30,
    "Number of Records": 1,
    "Abstract": "An ability to predict the popularity dynamics of individual items within a complex evolving system has important implications in an array of areas. Here we propose a generative probabilistic framework using a reinforced Poisson process to model explicitly the process through which individual items gain their popularity. This model distinguishes itself from existing models via its capability of modeling the arrival process of popularity and its remarkable power at predicting the popularity of individual items. It possesses the flexibility of applying Bayesian treatment to further improve the predictive power using a conjugate prior. Extensive experiments on a longitudinal citation dataset demonstrate that this model consistently outperforms existing popularity prediction methods",
    "Authors1": "Huawei Shen",
    "Authors2": "Dashun Wang",
    "Authors3": "Chaoming Song",
    "Authors4": "Albert Laszlo Barabasi",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Huawei Shen, Dashun Wang, Chaoming Song , Albert Laszlo Barabasi",
    "Groups1": "Applications (APP)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Applications (APP)",
    "Keywords10": "",
    "Keywords1": "Social Dynamics",
    "Keywords2": "Poisson Process",
    "Keywords3": "Popularity Prediction",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Social Dynamics;Poisson Process;Popularity Prediction",
    "Title": "Modeling and Predicting Popularity Dynamics via Reinforced Poisson Process",
    "Topics10": "",
    "Topics1": "APP: Computational Social Science",
    "Topics2": "APP: Social Networks",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "APP: Computational Social Science;APP: Social Networks"
  },
  {
    "Document Index (generated)": 31,
    "Number of Records": 1,
    "Abstract": "The fair division of indivisible goods has long been an important topic in economics and, more recently, computer science.  We investigate the existence of envy-free allocations of indivisible goods, that is, allocations where each player values her own allocated set of goods at least as highly as any other player's allocated set of goods.  Under additive valuations, we show that even when the number of goods is larger than the number of agents by a linear fraction, envy-free allocations are unlikely to exist.  We then show that when the number of goods is larger by a logarithmic factor, such allocations exist with high probability.  We support these results experimentally and show that the asymptotic behavior of the theory holds even when the number of goods and agents is quite small.  We demonstrate that there is a sharp phase transition from nonexistence to existence of envy-free allocations, and that on average the computational problem is hardest at that transition.",
    "Authors1": "John Dickerson",
    "Authors2": "Jonathan Goldman",
    "Authors3": "Jeremy Karp",
    "Authors4": "Ariel Procaccia",
    "Authors5": "Tuomas S",
    "Authors6": "holm",
    "Authors7": "",
    "Authors": "John Dickerson, Jonathan Goldman, Jeremy Karp, Ariel Procaccia , Tuomas S,holm",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP)",
    "Keywords10": "",
    "Keywords1": "Fair division",
    "Keywords2": "Computational social choice",
    "Keywords3": "Envy-free allocation",
    "Keywords4": "Phase transition",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Fair division;Computational social choice;Envy-free allocation;Phase transition",
    "Title": "The Computational Rise and Fall of Fairness",
    "Topics10": "",
    "Topics1": "GTEP: Social Choice / Voting",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Social Choice / Voting"
  },
  {
    "Document Index (generated)": 32,
    "Number of Records": 1,
    "Abstract": "Utilizing multiple queues in Greedy Best-First Search (GBFS) has been proven to be a very effective approach to satisficing planning. Successful applications include extra queues based on Helpful Actions (or Preferred Operators), as well as using Multiple Heuristics. One weakness of all standard GBFS algorithms is their lack of exploration. All queues used in these methods work as priority queues sorted by heuristic values. Therefore, misleading heuristics, especially early in the search process, cause the search to become ineffective.\n\nType systems, as introduced for heuristic search by Lelis et al, are a recent development of ideas for exploration related to the classic stratified sampling approach. The current work introduces a search algorithm that utilizes type systems in a new way – for exploration within a GBFS multiqueue frame- work, in satisficing planning.\n\nA careful case study shows the benefits of such exploration for overcoming deficiencies of the heuristic. The proposed new baseline algorithm Type-GBFS solves almost 200 more problems than baseline GBFS over all International Planning Competition problems. Type-LAMA, a new planner which integrates Type-GBFS into LAMA-2011, substantially improves upon LAMA in terms of both coverage and speed.",
    "Authors1": "Fan Xie",
    "Authors2": "Martin Mueller",
    "Authors3": "Robert Holte",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Fan Xie, Martin Mueller , Robert Holte",
    "Groups1": "Heuristic Search and Optimization (HSO)",
    "Groups2": "Planning and Scheduling (PS)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Heuristic Search and Optimization (HSO);Planning and Scheduling (PS)",
    "Keywords10": "",
    "Keywords1": "Satisficing Planning",
    "Keywords2": "Heuristic Search",
    "Keywords3": "Greedy Best First Search",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Satisficing Planning;Heuristic Search;Greedy Best First Search",
    "Title": "Type-based Exploration  for Satisficing Planning with Multiple Search Queues",
    "Topics10": "",
    "Topics1": "HSO: Heuristic Search",
    "Topics2": "PS: Deterministic Planning",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "HSO: Heuristic Search;PS: Deterministic Planning"
  },
  {
    "Document Index (generated)": 33,
    "Number of Records": 1,
    "Abstract": "Subspace clustering is an important unsupervised learning problem with wide applications in computer vision and data analysis. However, the state-of-the-art methods for this problem suffer from high time complexity---quadratic or cubic in $n$ (the number of data instances). In this paper we exploit a data selection algorithm to speedup computation and the robust principal component analysis to strengthen robustness. Accordingly, we devise a scalable and robust subspace clustering method which costs time only linear in $n$. We prove theoretically that under certain mild assumptions our method solves the subspace clustering problem exactly even for grossly corrupted data. Our algorithm is based on very simple ideas, yet it is the only linear time algorithm with noiseless or noisy recovery guarantee. Finally, empirical results verify our theoretical analysis.",
    "Authors1": "Shusen Wang",
    "Authors2": "Bojun Tu",
    "Authors3": "Congfu Xu",
    "Authors4": "Zhihua Zhang",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Shusen Wang, Bojun Tu, Congfu Xu , Zhihua Zhang",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "subspace clustering",
    "Keywords2": "data selection",
    "Keywords3": "scalable algorithm",
    "Keywords4": "robust principal component analysis",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "subspace clustering;data selection;scalable algorithm;robust principal component analysis",
    "Title": "Exact Subspace Clustering in Linear Time",
    "Topics10": "",
    "Topics1": "NMLA: Clustering",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Clustering"
  },
  {
    "Document Index (generated)": 34,
    "Number of Records": 1,
    "Abstract": "Inverse reinforcement learning (IRL) aims to recover the reward function underlying a Markov Decision Process from behaviors of experts in support of decision-making. Most recent work on IRL assumes the same level of trustworthiness of all expert behaviors, and frames IRL as a process of seeking reward function that makes those behaviors appear (near)-optimal. However, it is common in reality that noisy expert behaviors disobeying the optimal policy exist, which may degrade the IRL performance significantly. To address this issue, in this paper, we develop a robust IRL framework that can accurately estimate the reward function in the presence of behavior noise. In particular, we focus on a special type of behavior noise referred to as sparse noise due to its wide popularity in real-world behavior data. To model such noise, we introduce a novel latent variable characterizing the reliability of each expert action and use Laplace distribution as its prior. We then device an EM algorithm with a novel variational inference procedure in the E-step, which can automatically identify and remove behavior noise in reward learning. Experiments on both synthetic data and real vehicle routing data with noticeable behavior noise show significant improvement of our method over previous approaches in learning accuracy, and also demonstrate its power in de-noising behavior data.",
    "Authors1": "Jiangchuan Zheng",
    "Authors2": "Siyuan Liu",
    "Authors3": "Lionel Ni",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Jiangchuan Zheng, Siyuan Liu , Lionel Ni",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "Inverse reinforcement learning",
    "Keywords2": "Robust model",
    "Keywords3": "Sparse behavior noise",
    "Keywords4": "Variational inference",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Inverse reinforcement learning;Robust model;Sparse behavior noise;Variational inference",
    "Title": "Robust Bayesian Inverse Reinforcement Learning with Sparse Behavior Noise",
    "Topics10": "",
    "Topics1": "NMLA: Reinforcement Learning",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Reinforcement Learning"
  },
  {
    "Document Index (generated)": 35,
    "Number of Records": 1,
    "Abstract": "Most work building on the Stackelberg security games model assumes that the attacker can perfectly observe the defender's randomized assignment of resources to targets. This assumption has been challenged by recent papers, which designed tailor-made algorithms that compute optimal defender strategies for security games with limited surveillance. We analytically demonstrate that in zero-sum security games, lazy defenders, who simply keep optimizing against perfectly informed attackers, are almost optimal against diligent attackers, who go to the effort of gathering a reasonable number of observations. This result implies that, in some realistic situations, limited surveillance may not need to be explicitly addressed.",
    "Authors1": "Avrim Blum",
    "Authors2": "Nika Haghtalab",
    "Authors3": "Ariel Procaccia",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Avrim Blum, Nika Haghtalab , Ariel Procaccia",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP)",
    "Keywords10": "",
    "Keywords1": "Security games",
    "Keywords2": "Approximation",
    "Keywords3": "Sampling",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Security games;Approximation;Sampling",
    "Title": "Lazy Defenders Are Almost Optimal Against Diligent Attackers",
    "Topics10": "",
    "Topics1": "GTEP: Game Theory",
    "Topics2": "GTEP: Imperfect Information",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Game Theory;GTEP: Imperfect Information"
  },
  {
    "Document Index (generated)": 36,
    "Number of Records": 1,
    "Abstract": "Cognitive robotics is often subject to the criticism that the proposals\ninvestigated in the literature are far removed from the kind of continuous\nuncertainty and noise seen in actual real-world robotics. This paper\nproposes a new language and an implemented system, called PREGO, based on\nthe situation calculus, that is able to reason effectively about degrees of\nbelief against noisy sensors and effectors in continuous domains. It\nembodies the representational richness of conventional logic-based action\nlanguages, such as context-sensitive successor state axioms, but is still\nshown to be efficient using a number of empirical evaluations. We believe\nthat PREGO is a simple yet powerful dialect to explore real-time reactivity\nand an interesting bridge between logic and probability for cognitive\nrobotics applications.",
    "Authors1": "Vaishak Belle",
    "Authors2": "Hector Levesque",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Vaishak Belle , Hector Levesque",
    "Groups1": "Knowledge Representation and Reasoning (KRR)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Knowledge Representation and Reasoning (KRR)",
    "Keywords10": "",
    "Keywords1": "knowledge representation",
    "Keywords2": "situation calculus",
    "Keywords3": "cognitive robotics",
    "Keywords4": "reasoning about beliefs",
    "Keywords5": "action and change",
    "Keywords6": "action languages",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "knowledge representation;situation calculus;cognitive robotics;reasoning about beliefs;action and change;action languages",
    "Title": "PREGO: An Action Language for Belief-Based Cognitive Robotics in Continuous Domains",
    "Topics10": "",
    "Topics1": "KRR: Action, Change, and Causality",
    "Topics2": "KRR: Knowledge Representation Languages",
    "Topics3": "KRR: Reasoning with Beliefs",
    "Topics4": "KRR: Knowledge Representation (General/Other)",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "KRR: Action, Change, and Causality;KRR: Knowledge Representation Languages;KRR: Reasoning with Beliefs;KRR: Knowledge Representation (General/Other)"
  },
  {
    "Document Index (generated)": 37,
    "Number of Records": 1,
    "Abstract": "Dropout and other feature noising schemes have shown promising results in controlling over-fitting by artificially corrupting the training data. Though extensive theoretical and empirical studies have been performed for generalized linear models, little work has been done for support vector machines (SVMs), one of the most successful approaches for supervised learning. This paper presents dropout training for linear SVMs. To deal with the intractable expectation of the non-smooth hinge loss under corrupting distributions, we develop an iteratively re-weighted least square (IRLS) algorithm by exploring data augmentation techniques. Our algorithm iteratively minimizes the expectation of a re-weighted least square problem, where the re-weights have closed-form solutions. The similar ideas are applied to develop a new IRLS algorithm for the expected logistic loss under corrupting distributions. Our algorithms offer insights on the connection and difference between the hinge loss and logistic loss in dropout training. Empirical results on several real datasets demonstrate the effectiveness of dropout training on significantly boosting the classification accuracy of linear SVMs.",
    "Authors1": "Ning Chen",
    "Authors2": "Jun Zhu",
    "Authors3": "Jianfei Chen",
    "Authors4": "Bo Zhang",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Ning Chen, Jun Zhu, Jianfei Chen , Bo Zhang",
    "Groups1": "Machine Learning Applications (MLA)",
    "Groups2": "Novel Machine Learning Algorithms (NMLA)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Machine Learning Applications (MLA);Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "Dropout traning",
    "Keywords2": "Support Vector Machines",
    "Keywords3": "Data Augmentation",
    "Keywords4": "Feature Noising",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Dropout traning;Support Vector Machines;Data Augmentation;Feature Noising",
    "Title": "Dropout Training for Support Vector Machines",
    "Topics10": "",
    "Topics1": "MLA: Applications of Supervised Learning",
    "Topics2": "NMLA: Classification",
    "Topics3": "NMLA: Supervised Learning (Other)",
    "Topics4": "NMLA: Machine Learning (General/other)",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "MLA: Applications of Supervised Learning;NMLA: Classification;NMLA: Supervised Learning (Other);NMLA: Machine Learning (General/other)"
  },
  {
    "Document Index (generated)": 38,
    "Number of Records": 1,
    "Abstract": "High profile large scale public events are attractive targets for terrorist attacks. The recent Boston Marathon bombings on April 15, 2013 have further emphasized the importance of protecting public events. The security challenge is exacerbated by the dynamic nature of such events: e.g., the impact of an attack at different locations changes over time as the Boston marathon participants and spectators move along the race track. In addition, the defender can relocate security resources among potential attack targets at any time and the attacker may act at any time during the event.\n\nThis paper focuses on developing efficient patrolling algorithms for such dynamic domains with continuous strategy spaces for both the defender and the attacker. We aim at computing optimal pure defender strategies, since an attacker does not have an opportunity to learn and respond to mixed strategies due to the relative infrequency of such events. We propose SCOUT-A, which makes assumptions on relocation cost, exploits payoff representation and computes optimal solutions efficiently. We also propose SCOUT-C to compute the exact optimal defender strategy for general cases despite the continuous strategy spaces. SCOUT-C computes the optimal defender strategy by constructing an equivalent game with discrete defender strategy space, then solving the constructed game. Experimental results show that both SCOUT-A and SCOUT-C significantly outperform other existing strategies.",
    "Authors1": "Yue Yin",
    "Authors2": "Bo An",
    "Authors3": "Manish Jain",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Yue Yin, Bo An , Manish Jain",
    "Groups1": "Applications (APP)",
    "Groups2": "Game Theory and Economic Paradigms (GTEP)",
    "Groups3": "Multiagent Systems (MAS)",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Applications (APP);Game Theory and Economic Paradigms (GTEP);Multiagent Systems (MAS)",
    "Keywords10": "",
    "Keywords1": "Security",
    "Keywords2": "Game Theory",
    "Keywords3": "Stackelberg Games",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Security;Game Theory;Stackelberg Games",
    "Title": "Game-theoretic Resource Allocation for Protecting Large Public Events",
    "Topics10": "",
    "Topics1": "APP: Security and Privacy",
    "Topics2": "GTEP: Game Theory",
    "Topics3": "MAS: Multiagent Systems (General/other)",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "APP: Security and Privacy;GTEP: Game Theory;MAS: Multiagent Systems (General/other)"
  },
  {
    "Document Index (generated)": 39,
    "Number of Records": 1,
    "Abstract": "The types of web data vary in terms of information quantity and quality. For example, some pages contain numerous texts, whereas some others contain few texts; some web videos are in high resolution, whereas some other web videos are in low resolution. As a consequence, the quality of extracted features from different web data may also vary greatly. Existing learning algorithms on web data classification usually ignore the variations of information quality or quantity. In this paper, the information quantity and quality of web data are described by quality-related factors such as text length and image quantity, and a new learning method is proposed to train classifiers based on quality-related factors. The method divides training data into subsets according to the clustering results of quality-related factors and then trains classifiers by using a multi-task learning strategy for each subset. Experimental results indicate that the quality-related factors are useful in web data classification, and the proposed method outperforms conventional algorithms that do not consider information quantity and quality.",
    "Authors1": "Ou Wu",
    "Authors2": "",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Ou Wu",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "Machine Learning Applications (MLA)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW);Machine Learning Applications (MLA)",
    "Keywords10": "",
    "Keywords1": "Information quality",
    "Keywords2": "Multi-task learning",
    "Keywords3": "Web data classification",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Information quality;Multi-task learning;Web data classification",
    "Title": "Quality-based Learning for Web Data Classification",
    "Topics10": "",
    "Topics1": "AIW: Machine learning and the web",
    "Topics2": "MLA: Applications of Supervised Learning",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: Machine learning and the web;MLA: Applications of Supervised Learning"
  },
  {
    "Document Index (generated)": 40,
    "Number of Records": 1,
    "Abstract": "Online mechanism design has been widely applied to various practical applications. However, designing a strategy-proof online mechanism is much more challenging than that in a static scenario due to short of knowledge of future information. In this paper, we investigate online auctions with time discounting values, in contrast to the flat values studied in most of existing work. We present a strategy-proof 2-competitive online auction mechanism despite of time discounting values. We also implement our design and compare it with off-line optimal solution. Our numerical results show that our design achieves good performance in terms of social welfare, revenue, average winning delay, and average valuation loss.",
    "Authors1": "Fan Wu",
    "Authors2": "Junming Liu",
    "Authors3": "Zhenzhe Zheng",
    "Authors4": "Guihai Chen",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Fan Wu, Junming Liu, Zhenzhe Zheng , Guihai Chen",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP)",
    "Keywords10": "",
    "Keywords1": "Online Auction",
    "Keywords2": "Mechanism Design",
    "Keywords3": "Game Theory",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Online Auction;Mechanism Design;Game Theory",
    "Title": "A Strategy-Proof Online Auction with Time Discounting Values",
    "Topics10": "",
    "Topics1": "GTEP: Auctions and Market-Based Systems",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Auctions and Market-Based Systems"
  },
  {
    "Document Index (generated)": 41,
    "Number of Records": 1,
    "Abstract": "The smoothness hypothesis is critical for graph-based semi-supervised learning. This paper defines local smoothness, based on which a new algorithm, Reliable Label Inference via Smoothness Hypothesis (ReLISH), is proposed. ReLISH has produced smoother labels than some existing methods for both labeled and unlabeled examples. Theoretical analyses demonstrate good stability and generalizability of ReLISH. Using real-world datasets, our empirical analyses reveal that ReLISH is promising for both transductive and inductive tasks, when compared with representative algorithms, including Harmonic Functions, Local and Global Consistency, Constraint Metric Learning, Linear Neighborhood Propagation, and Manifold Regularization.",
    "Authors1": "Chen Gong",
    "Authors2": "Dacheng Tao",
    "Authors3": "Keren Fu",
    "Authors4": "Jie Yang",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Chen Gong, Dacheng Tao, Keren Fu , Jie Yang",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "Semi-supervised learning",
    "Keywords2": "Local smoothness",
    "Keywords3": "Regularization",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Semi-supervised learning;Local smoothness;Regularization",
    "Title": "ReLISH: Reliable Label Inference via Smoothness Hypothesis",
    "Topics10": "",
    "Topics1": "NMLA: Classification",
    "Topics2": "NMLA: Semisupervised Learning",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Classification;NMLA: Semisupervised Learning"
  },
  {
    "Document Index (generated)": 42,
    "Number of Records": 1,
    "Abstract": "We present a novel approach to parallel materialisation (i.e., fixpoint computation) of datalog programs in centralised, main-memory, multi-core RDF systems. The approach comprises an algorithm that evenly distributes the workload to cores, and an RDF indexing data structure that supports efficient, 'mostly' lock-free parallel updates. Our empirical evaluation shows that our approach parallelises computation very well so, with 16 physical cores, materialisation can be up to 13.9 times faster than with just one core.",
    "Authors1": "Boris Motik",
    "Authors2": "Yavor Nenov",
    "Authors3": "Robert Piro",
    "Authors4": "Ian Horrocks",
    "Authors5": "Dan Olteanu",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Boris Motik, Yavor Nenov, Robert Piro, Ian Horrocks , Dan Olteanu",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "Knowledge Representation and Reasoning (KRR)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW);Knowledge Representation and Reasoning (KRR)",
    "Keywords10": "",
    "Keywords1": "datalog",
    "Keywords2": "materialization",
    "Keywords3": "fixpoint computation",
    "Keywords4": "parallelism",
    "Keywords5": "big data",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "datalog;materialization;fixpoint computation;parallelism;big data",
    "Title": "Parallel Materialisation of Datalog Programs in Centralised, Main-Memory RDF Systems",
    "Topics10": "",
    "Topics1": "AIW: Question answering on the web",
    "Topics2": "AIW: Representing, reasoning, and using provenance, trust, privacy, and security on the web",
    "Topics3": "KRR: Ontologies",
    "Topics4": "KRR: Automated Reasoning and Theorem Proving",
    "Topics5": "KRR: Logic Programming",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: Question answering on the web;AIW: Representing, reasoning, and using provenance, trust, privacy, and security on the web;KRR: Ontologies;KRR: Automated Reasoning and Theorem Proving;KRR: Logic Programming"
  },
  {
    "Document Index (generated)": 43,
    "Number of Records": 1,
    "Abstract": "We consider the problem of personalization of online services from the viewpoint of display ad targeting, where we seek to find the best ad categories to be shown to each user, resulting in improved user experience and increased advertiser's revenue. We propose to address this problem as a task of ranking the ad categories by each user's preferences, and introduce a novel label ranking approach capable of efficiently learning non-linear, highly accurate models in large-scale settings. Experiments on real-world advertising data set with more than 3.2 million users show that the proposed algorithm outperforms the existing solutions in terms of both rank loss and top-K retrieval performance, strongly suggesting the benefit of using the proposed model on large-scale ranking problems.",
    "Authors1": "Nemanja Djuric",
    "Authors2": "Mihajlo Grbovic",
    "Authors3": "Vladan Radosavljevic",
    "Authors4": "Narayan Bhamidipati",
    "Authors5": "Slobodan Vucetic",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Nemanja Djuric, Mihajlo Grbovic, Vladan Radosavljevic, Narayan Bhamidipati , Slobodan Vucetic",
    "Groups1": "Machine Learning Applications (MLA)",
    "Groups2": "Novel Machine Learning Algorithms (NMLA)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Machine Learning Applications (MLA);Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "Computational advertising",
    "Keywords2": "Label ranking",
    "Keywords3": "Online learning",
    "Keywords4": "Large-scale learning",
    "Keywords5": "Big data",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Computational advertising;Label ranking;Online learning;Large-scale learning;Big data",
    "Title": "Non-linear Label Ranking for Large-scale Prediction of Long-Term User Interests",
    "Topics10": "",
    "Topics1": "MLA: Applications of Supervised Learning",
    "Topics2": "NMLA: Big Data / Scalability",
    "Topics3": "NMLA: Preferences/Ranking Learning",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "MLA: Applications of Supervised Learning;NMLA: Big Data / Scalability;NMLA: Preferences/Ranking Learning"
  },
  {
    "Document Index (generated)": 44,
    "Number of Records": 1,
    "Abstract": "We examine how to use emerging far-infrared imager ensembles to detect certain\nobjects of interest (e.g., faces, hands, people and animals) in synchronized\nRGB video streams at very low power. We formulate the problem as one of selecting\nsubsets of sensing elements (among many thousand possibilities) from the\nensembles for  tests. The subset selection  problem is naturally {\\em adaptive} and {\\em online}: testing certain elements early can obviate the need for testing many others later, and selection policies must be updated at inference time. We pose the ensemble sensor selection problem as a structured extension of test-cost-sensitive classification, propose a principled suite of techniques to exploit ensemble structure to  speed up processing and show how to re-estimate policies fast. We estimate reductions in power consumption of roughly 50x relative to even highly optimized implementations of face detection, a canonical object-detection problem. We also illustrate the benefits of adaptivity and online estimation.",
    "Authors1": "Matthai Philipose",
    "Authors2": "",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Matthai Philipose",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "Planning and Scheduling (PS)",
    "Groups3": "Reasoning under Uncertainty (RU)",
    "Groups4": "Vision (VIS)",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA);Planning and Scheduling (PS);Reasoning under Uncertainty (RU);Vision (VIS)",
    "Keywords10": "",
    "Keywords1": "object detection",
    "Keywords2": "low power",
    "Keywords3": "value of information",
    "Keywords4": "adaptive submodular optimization",
    "Keywords5": "online optimization",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "object detection;low power;value of information;adaptive submodular optimization;online optimization",
    "Title": "Efficient Object Detection via Adaptive Online Selection of Sensor-Array Elements",
    "Topics10": "VIS: Categorization",
    "Topics1": "MLA: Machine Learning Applications (General/other)",
    "Topics2": "NMLA: Active Learning",
    "Topics3": "NMLA: Bayesian Learning",
    "Topics4": "PS: Probabilistic Planning",
    "Topics5": "PS: Temporal Planning",
    "Topics6": "RU: Bayesian Networks",
    "Topics7": "RU: Decision/Utility Theory",
    "Topics8": "RU: Probabilistic Inference",
    "Topics9": "RU: Sequential Decision Making",
    "Topics": "MLA: Machine Learning Applications (General/other);NMLA: Active Learning;NMLA: Bayesian Learning;PS: Probabilistic Planning;PS: Temporal Planning;RU: Bayesian Networks;RU: Decision/Utility Theory;RU: Probabilistic Inference;RU: Sequential Decision Making;VIS: Categorization;VIS: Object Detection;VIS: Statistical Methods and Learning;VIS: Videos"
  },
  {
    "Document Index (generated)": 45,
    "Number of Records": 1,
    "Abstract": "We introduce the simultaneous model for cake cutting (the fair allocation of a divisible good), in which agents simultaneously send messages containing a sketch of their preferences over the cake. We show that this model enables the computation of divisions that satisfy proportionality — a popular fairness notion — using a protocol that circumvents a standard lower bound via parallel information elicitation. Cake divisions satisfying another prominent fairness notion, envy-freeness, are impossible to compute in the simultaneous model, but such allocations admit arbitrarily good approximations.",
    "Authors1": "Eric Balkanski",
    "Authors2": "Simina Brânzei",
    "Authors3": "David Kurokawa",
    "Authors4": "Ariel Procaccia",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Eric Balkanski, Simina Brânzei, David Kurokawa , Ariel Procaccia",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP)",
    "Keywords10": "",
    "Keywords1": "Cake cutting",
    "Keywords2": "Fair division",
    "Keywords3": "Computational social choice",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Cake cutting;Fair division;Computational social choice",
    "Title": "Simultaneous Cake Cutting",
    "Topics10": "",
    "Topics1": "GTEP: Social Choice / Voting",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Social Choice / Voting"
  },
  {
    "Document Index (generated)": 46,
    "Number of Records": 1,
    "Abstract": "Selection bias is caused by preferential exclusion of units from the samples and represents a major obstacle to valid causal and statistical inferences; it cannot be removed by randomized experiments and can rarely be detected  in either experimental or observational studies.  Extending the results of (Bareinboim and Pearl 2012), we provide complete graphical and algorithmic conditions for recovering conditional probabilities from selection biased data.  We further provide graphical conditions for recoverability when unbiased data is available over a subset of the variables. Finally, we provide a graphical condition that generalizes the backdoor criterion and serves to recover causal effects when the data is collected under preferential selection.",
    "Authors1": "Elias Bareinboim",
    "Authors2": "Jin Tian",
    "Authors3": "Judea Pearl",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Elias Bareinboim, Jin Tian , Judea Pearl",
    "Groups1": "Knowledge Representation and Reasoning (KRR)",
    "Groups2": "Reasoning under Uncertainty (RU)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Knowledge Representation and Reasoning (KRR);Reasoning under Uncertainty (RU)",
    "Keywords10": "",
    "Keywords1": "Causal Inference",
    "Keywords2": "Causal Reasoning",
    "Keywords3": "Do-calculus",
    "Keywords4": "Causality",
    "Keywords5": "Selection Bias",
    "Keywords6": "Sampling Selection Bias",
    "Keywords7": "Case-control studies",
    "Keywords8": "Bias Removal",
    "Keywords9": "Backdoor criterion",
    "Keywords": "Causal Inference;Causal Reasoning;Do-calculus;Causality;Selection Bias;Sampling Selection Bias;Case-control studies;Bias Removal;Backdoor criterion",
    "Title": "Recovering from Selection Bias in Causal and Statistical Inference",
    "Topics10": "",
    "Topics1": "KRR: Action, Change, and Causality",
    "Topics2": "RU: Bayesian Networks",
    "Topics3": "RU: Uncertainty in AI (General/Other)",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "KRR: Action, Change, and Causality;RU: Bayesian Networks;RU: Uncertainty in AI (General/Other)"
  },
  {
    "Document Index (generated)": 47,
    "Number of Records": 1,
    "Abstract": "Currently, a large family of kernel methods for semi-supervised learning(SSL) problems builds the kernel by weighted average of predefined base kernels (i.e., those spanned by kernel eigenvectors). Optimization of the base kernel weights has been studied extensively in the literatures. However, little attention was devoted to designing high-quality base kernels. Note that the eigenvectors of the kernel matrix, which are computed irrespective of class labels, may not always reveal useful structures of the target. As a result, the generalization performance can be poor however hard the base kernel weighting is tuned. On the other hand, there are many SSL algorithms whose focus is not on kernel design but instead the estimation of the class labels directly. Motivated by the label propagation approach, in this paper we propose to construct novel kernel eigenvectors by injecting the class label information under the framework of eigenfunction extrapolation. A set of ``label-aware'' base kernels can be obtained with greatly improved quality, which leads to higher target alignment and henceforth better performance. Our approach is computationally efficient, and demonstrates encouraging performance in semi-supervised classification and regression tasks.",
    "Authors1": "Qiaojun Wang",
    "Authors2": "Kai Zhang",
    "Authors3": "Ivan Marsic",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Qiaojun Wang, Kai Zhang , Ivan Marsic",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "Semi-supervised Kernel Learning",
    "Keywords2": "Eigenfunction Extrapolation",
    "Keywords3": "Kernel Target Alignment",
    "Keywords4": "Ideal Kernel",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Semi-supervised Kernel Learning;Eigenfunction Extrapolation;Kernel Target Alignment;Ideal Kernel",
    "Title": "Semi-supervised Target Alignment via Label-Aware Base Kernels",
    "Topics10": "",
    "Topics1": "NMLA: Kernel Methods",
    "Topics2": "NMLA: Semisupervised Learning",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Kernel Methods;NMLA: Semisupervised Learning"
  },
  {
    "Document Index (generated)": 48,
    "Number of Records": 1,
    "Abstract": "Most work on active learning avoids the issue of model selection by training models of only one type (SVMs, boosted trees, etc.) using one pre-defined set of model hyperparameters.  We propose an algorithm that actively samples data to simultaneously train a set of candidate models (different model types and/or different hyperparameters) and also to select the best model from this set of candidates.  The algorithm actively samples points for training that are most likely to improve the accuracy of the more promising candidate models, and also samples points to use for model selection---all samples count against the same ﬁxed labeling budget. This exposes a natural trade-off between the focused active sampling that is most effective for training models, and the unbiased uniform sampling that is better for model selection.  We empirically demonstrate on six test problems that this algorithm is nearly as effective as an active learning oracle that knows the optimal model in advance.",
    "Authors1": "Alnur Ali",
    "Authors2": "Rich Caruana",
    "Authors3": "Ashish Kapoor",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Alnur Ali, Rich Caruana , Ashish Kapoor",
    "Groups1": "Humans and AI (HAI)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Humans and AI (HAI)",
    "Keywords10": "",
    "Keywords1": "active learning",
    "Keywords2": "model selection",
    "Keywords3": "machine learning",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "active learning;model selection;machine learning",
    "Title": "Active Learning with Model Selection via Nested Cross-Validation",
    "Topics10": "",
    "Topics1": "NMLA: Active Learning",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Active Learning"
  },
  {
    "Document Index (generated)": 49,
    "Number of Records": 1,
    "Abstract": "In this paper, we target at the problem of sketch recognition. We systematically study how to incorporate users' natural correction and editing into isolated and full sketch recognition. This is a natural and necessary interaction in real systems such as Visio where extremely similar shapes exist. First, a novel algorithm is proposed to mine the prior shape knowledge for three editing modes. Second, to differentiate visually similar shapes, a novel symbol recognition algorithm is introduced by leveraging the learnt shape knowledge. Then, a novel correction/editing detection algorithm is proposed to facilitate symbol recognition. Furthermore, both of the symbol recognizer and the correction/editing detector are systematically incorporated into the full sketch recognition. Finally, based on the proposed algorithms, a real-time sketch recognition system is built to recognize hand-drawn flowchart/diagram with flexible interactions. Extensive experiments on benchmark datasets show the effectiveness of the proposed algorithms.",
    "Authors1": "Jie Wu",
    "Authors2": "Changhu Wang",
    "Authors3": "Liqing Zhang",
    "Authors4": "Yong Rui",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Jie Wu, Changhu Wang, Liqing Zhang , Yong Rui",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "Humans and AI (HAI)",
    "Groups3": "Machine Learning Applications (MLA)",
    "Groups4": "Vision (VIS)",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW);Humans and AI (HAI);Machine Learning Applications (MLA);Vision (VIS)",
    "Keywords10": "",
    "Keywords1": "Sketch Recognition",
    "Keywords2": "Symbol Recognition",
    "Keywords3": "User Interface",
    "Keywords4": "Correction and Editing",
    "Keywords5": "Shape Knowledge",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Sketch Recognition;Symbol Recognition;User Interface;Correction and Editing;Shape Knowledge",
    "Title": "Sketch Recognition with Natural Correction and Editing",
    "Topics10": "",
    "Topics1": "AIW: Intelligent user interfaces for web systems",
    "Topics2": "HAI: Human-Computer Interaction",
    "Topics3": "HAI: Interaction Techniques and Devices",
    "Topics4": "MLA: Applications of Supervised Learning",
    "Topics5": "NMLA: Data Mining and Knowledge Discovery",
    "Topics6": "VIS: Object Recognition",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: Intelligent user interfaces for web systems;HAI: Human-Computer Interaction;HAI: Interaction Techniques and Devices;MLA: Applications of Supervised Learning;NMLA: Data Mining and Knowledge Discovery;VIS: Object Recognition"
  },
  {
    "Document Index (generated)": 50,
    "Number of Records": 1,
    "Abstract": "Label reduction is a technique for simplifying families of labeled transition systems by dropping distinctions between certain transition labels. While label reduction is critical to the efficient computation of merge-and-shrink heuristics, current theory only permits reducing labels in a limited number of cases. We generalize this theory so that labels can be reduced in every intermediate abstraction of a merge-and-shrink tree. This is particularly important for efficiently computing merge-and-shrink abstractions based on non-linear merge strategies. As a case study, we implement a non-linear merge strategy based on the original work on merge-and-shrink heuristics in model checking by Dräger et al.",
    "Authors1": "Silvan Sievers",
    "Authors2": "Martin Wehrle",
    "Authors3": "Malte Helmert",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Silvan Sievers, Martin Wehrle , Malte Helmert",
    "Groups1": "Heuristic Search and Optimization (HSO)",
    "Groups2": "Planning and Scheduling (PS)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Heuristic Search and Optimization (HSO);Planning and Scheduling (PS)",
    "Keywords10": "",
    "Keywords1": "classical planning",
    "Keywords2": "heuristic search",
    "Keywords3": "merge-and-shrink abstractions",
    "Keywords4": "label reduction",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "classical planning;heuristic search;merge-and-shrink abstractions;label reduction",
    "Title": "Generalized Label Reduction for Merge-and-Shrink Heuristics",
    "Topics10": "",
    "Topics1": "HSO: Heuristic Search",
    "Topics2": "HSO: Optimization",
    "Topics3": "HSO: Evaluation and Analysis (Search and Optimization)",
    "Topics4": "PS: Deterministic Planning",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "HSO: Heuristic Search;HSO: Optimization;HSO: Evaluation and Analysis (Search and Optimization);PS: Deterministic Planning"
  },
  {
    "Document Index (generated)": 51,
    "Number of Records": 1,
    "Abstract": "User-generated video collections are expanding rapidly in recent years, and systems for automatic analysis of these collections are in high demands. While extensive research efforts have been devoted to recognizing semantics like \"birthday party\" and \"skiing\", little attempts have been made to understand the emotions carried by the videos, e.g., \"joy\" and \"sadness\". In this paper, we propose a comprehensive computational framework for predicting emotions in user-generated videos. We first introduce a rigorously designed dataset collected from popular video-sharing websites with manual annotations, which can serve as a valuable benchmark for future research. A large set of features are extracted from this dataset, ranging from popular low-level visual descriptors, audio features, to high-level semantic attributes. Results of a comprehensive set of experiments indicate that combining multiple types of features---such as the joint use of the audio and visual clues---is important, and attribute features such as those containing sentiment-level semantics are very effective.",
    "Authors1": "Yu-Gang Jiang",
    "Authors2": "Baohan Xu",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Yu-Gang Jiang , Baohan Xu",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW)",
    "Keywords10": "",
    "Keywords1": "Emotion",
    "Keywords2": "User-generated videos",
    "Keywords3": "Multimodal features",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Emotion;User-generated videos;Multimodal features",
    "Title": "Predicting Emotions in User-Generated Videos",
    "Topics10": "",
    "Topics1": "AIW: AI for multimedia and multimodal web applications",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: AI for multimedia and multimodal web applications"
  },
  {
    "Document Index (generated)": 52,
    "Number of Records": 1,
    "Abstract": "This paper studies the problem of emotion classification in microblog texts. Given a microblog text which consists of several sentences, we classify its emotion as anger, disgust, fear, happiness, like, sadness or surprise if possible. Existing methods can be categorized as lexicon based methods or machine learning based methods. However, due to some intrinsic characteristics of the microblog texts, previous studies using these methods always get unsatisfactory results. This paper introduces a novel approach based on class sequential rules for emotion classification of microblog texts. The approach first obtains two potential emotion labels for each sentence in a microblog text by using an emotion lexicon and a machine learning approach respectively, and regards each microblog text as a data sequence. It then mines class sequential rules from the sequence set and finally derives new features from the mined rules for emotion classification of microblog texts. Experimental results on a Chinese benchmark dataset show the superior performance of the proposed approach.",
    "Authors1": "Shiyang Wen",
    "Authors2": "Xiaojun Wan",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Shiyang Wen , Xiaojun Wan",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW)",
    "Keywords10": "",
    "Keywords1": "Emotion Classification",
    "Keywords2": "Chinese Microblogs",
    "Keywords3": "Class Sequential Rules",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Emotion Classification;Chinese Microblogs;Class Sequential Rules",
    "Title": "Emotion Classification in Microblog Texts Using Class Sequential Rules",
    "Topics10": "",
    "Topics1": "AIW: Knowledge acquisition from the web",
    "Topics2": "AIW: Web-based opinion extraction and trend spotting",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: Knowledge acquisition from the web;AIW: Web-based opinion extraction and trend spotting"
  },
  {
    "Document Index (generated)": 53,
    "Number of Records": 1,
    "Abstract": "For datasets in Collaborative Filtering (CF) recommendations, even if the identifier is deleted and some trivial perturbation operations are applied to ratings before they are released, there are research results claiming that the adversary could discriminate the individual's identity with a little bit of information. In this paper, we propose $k$-coRating, a novel privacy-preserving model, to retain data privacy by replacing some null ratings with significantly predicted scores. They do not only mask the original ratings such that a $k$-anonymity-like data privacy is preserved, but also enhance the data utility (measured by prediction accuracy in this paper), which shows that the traditional assumption that accuracy and privacy are two goals in conflict is not necessarily correct. We show that the optimal $k$-coRated mapping is an NP-hard problem and design a naive but efficient algorithm to achieve $k$-coRating. All claims are verified by experimental results.",
    "Authors1": "Feng Zhang",
    "Authors2": "Victor E Lee",
    "Authors3": "Ruoming Jin",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Feng Zhang, Victor E Lee , Ruoming Jin",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "Applications (APP)",
    "Groups3": "Novel Machine Learning Algorithms (NMLA)",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW);Applications (APP);Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "Privacy-preserving Collaborative Filtering Recommender Systems",
    "Keywords2": "Data Privacy",
    "Keywords3": "Parallel Computing",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Privacy-preserving Collaborative Filtering Recommender Systems;Data Privacy;Parallel Computing",
    "Title": "k-CoRating: Filling up Data to Obtain Privacy and Utility",
    "Topics10": "",
    "Topics1": "AIW: Web-based recommendation systems",
    "Topics2": "APP: Security and Privacy",
    "Topics3": "NMLA: Recommender Systems",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: Web-based recommendation systems;APP: Security and Privacy;NMLA: Recommender Systems"
  },
  {
    "Document Index (generated)": 54,
    "Number of Records": 1,
    "Abstract": "Recursive neural models have achieved promising results in many natural language processing tasks. The main difference among these models lies in the composition function, i.e., how to obtain the vector representation for a phrase or sentence using the representations of words it contains. This paper introduces a novel Adaptive Multi-Compositionality (AdaMC) layer to recursive neural models. The basic idea is to use more than one composition functions and adaptively select them depending on the input vectors. We present a general framework to model each semantic composition as a distribution over these composition functions. The composition functions and parameters used for adaptive selection are learned jointly from data. We integrate AdaMC into existing recursive neural models and conduct extensive experiments on the Stanford Sentiment Treebank. The results illustrate that AdaMC significantly outperforms state-of-the-art sentiment classification methods. It helps push the best accuracy of sentence-level negative/positive classification from 85.4% up to 88.5%.",
    "Authors1": "Li Dong",
    "Authors2": "Furu Wei",
    "Authors3": "Ming Zhou",
    "Authors4": "Ke Xu",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Li Dong, Furu Wei, Ming Zhou , Ke Xu",
    "Groups1": "NLP and Machine Learning (NLPML)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "NLP and Machine Learning (NLPML)",
    "Keywords10": "",
    "Keywords1": "recursive neural network",
    "Keywords2": "sentiment analysis",
    "Keywords3": "semantic composition",
    "Keywords4": "recursive neural model",
    "Keywords5": "neural network",
    "Keywords6": "deep learning",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "recursive neural network;sentiment analysis;semantic composition;recursive neural model;neural network;deep learning",
    "Title": "Adaptive Multi-Compositionality for Recursive Neural Models with Applications to Sentiment Analysis",
    "Topics10": "",
    "Topics1": "NLPML: Natural Language Processing (General/Other)",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NLPML: Natural Language Processing (General/Other)"
  },
  {
    "Document Index (generated)": 55,
    "Number of Records": 1,
    "Abstract": "There are various algorithms for finding a Bayesian network structure\n(BNS) that is optimal with respect to a given scoring function. No\nsingle algorithm dominates the others in speed, and given a problem\ninstance, it is a priori unclear which algorithm will perform\nbest and how fast it will solve the problem. Estimating the running\ntimes directly is extremely difficult as they are complicated functions\nof the instance. The main contribution of this paper is characterization\nof the empirical hardness of an instance for a given algorithm based on\na novel collection of non-trivial, yet efficiently computable features.\nOur empirical results, based on the largest evaluation of\nstate-of-the-art BNS learning algorithms to date, demonstrate that we\ncan predict the runtimes to a reasonable degree of accuracy, and\neffectively select algorithms that perform well on a particular\ninstance. Moreover, we also show how the results can be utilized in\nbuilding a portfolio algorithm that combines several individual\nalgorithms in an almost optimal manner.",
    "Authors1": "Br",
    "Authors2": "on Malone",
    "Authors3": "Kustaa Kangas",
    "Authors4": "Matti Järvisalo",
    "Authors5": "Mikko Koivisto",
    "Authors6": "Petri Myllymäki",
    "Authors7": "",
    "Authors": "Br,on Malone, Kustaa Kangas, Matti Järvisalo, Mikko Koivisto , Petri Myllymäki",
    "Groups1": "Heuristic Search and Optimization (HSO)",
    "Groups2": "Novel Machine Learning Algorithms (NMLA)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Heuristic Search and Optimization (HSO);Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "Bayesian networks",
    "Keywords2": "structure learning",
    "Keywords3": "algorithm portfolios",
    "Keywords4": "empirical hardness models",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Bayesian networks;structure learning;algorithm portfolios;empirical hardness models",
    "Title": "Predicting the Hardness of Learning Bayesian Networks",
    "Topics10": "",
    "Topics1": "HSO: Metareasoning and Metaheuristics",
    "Topics2": "HSO: Evaluation and Analysis (Search and Optimization)",
    "Topics3": "NMLA: Graphical Model Learning",
    "Topics4": "NMLA: Evaluation and Analysis (Machine Learning)",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "HSO: Metareasoning and Metaheuristics;HSO: Evaluation and Analysis (Search and Optimization);NMLA: Graphical Model Learning;NMLA: Evaluation and Analysis (Machine Learning)"
  },
  {
    "Document Index (generated)": 56,
    "Number of Records": 1,
    "Abstract": "Online services such as web search and e-commerce applications typically rely on the collection of data about users, including details of their activities on the web.  Such personal data is used to enhance the quality of service via personalization of content and to maximize revenues via better targeting of advertisements and deeper engagement of users on sites.  To date, service providers have largely followed the approach of either requiring or requesting consent for opting-in to share their data.  Users may be willing to share private information in return for better quality of service or for incentives, or in return for assurances about the nature and extend of the logging of data. We introduce \\emph{stochastic privacy}, a new approach to privacy centering on a simple concept: A guarantee is provided to users about the upper-bound on the probability that their personal data will be used. Such a probability, which we refer to as \\emph{privacy risk}, can be assessed by users as a preference or communicated as a policy by a service provider.  Service providers can work to personalize and to optimize revenues in accordance with preferences about privacy risk.  We present procedures, proofs, and an overall system for maximizing the quality of services, while respecting bounds on allowable or communicated privacy risk. We demonstrate the methodology with a case study and evaluation of the procedures applied to web search personalization.  We show how we can achieve near-optimal utility of accessing information with provable guarantees on the probability of sharing data.",
    "Authors1": "Adish Singla",
    "Authors2": "Ece Kamar",
    "Authors3": "Ryen White",
    "Authors4": "Eric Horvitz",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Adish Singla, Ece Kamar, Ryen White , Eric Horvitz",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW)",
    "Keywords10": "",
    "Keywords1": "privacy tradeoff",
    "Keywords2": "value of information",
    "Keywords3": "online services",
    "Keywords4": "web search personalization",
    "Keywords5": "submodular optimization",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "privacy tradeoff;value of information;online services;web search personalization;submodular optimization",
    "Title": "Stochastic Privacy: Model, Methods, and Experiments",
    "Topics10": "",
    "Topics1": "AIW: Representing, reasoning, and using provenance, trust, privacy, and security on the web",
    "Topics2": "AIW: Web personalization and user modeling",
    "Topics3": "APP: Security and Privacy",
    "Topics4": "RU: Decision/Utility Theory",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: Representing, reasoning, and using provenance, trust, privacy, and security on the web;AIW: Web personalization and user modeling;APP: Security and Privacy;RU: Decision/Utility Theory"
  },
  {
    "Document Index (generated)": 57,
    "Number of Records": 1,
    "Abstract": "Generalized CP-nets (GCP-nets) allow a succinct representation of preferences over multi-attribute domains. As a consequence of their succinct representation, many GCP-net related tasks are computationally hard. Even finding the more preferable of two outcomes is PSPACE-complete. In this work, we employ the framework of parameterized complexity to achieve two goals: First, we want to gain a deeper understanding of the complexity of GCP-nets. Second, we search for efficient fixed-parameter tractable algorithms.",
    "Authors1": "Martin Kronegger",
    "Authors2": "Martin Lackner",
    "Authors3": "Andreas Pf",
    "Authors4": "ler",
    "Authors5": "Reinhard Pichler",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Martin Kronegger, Martin Lackner, Andreas Pf,ler , Reinhard Pichler",
    "Groups1": "Game Playing and Interactive Entertainment (GPIE)",
    "Groups2": "Knowledge Representation and Reasoning (KRR)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Playing and Interactive Entertainment (GPIE);Knowledge Representation and Reasoning (KRR)",
    "Keywords10": "",
    "Keywords1": "Computational social choice",
    "Keywords2": "CP-nets",
    "Keywords3": "Fixed-parameter tractable algorithms",
    "Keywords4": "(Parameterized) complexity",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Computational social choice;CP-nets;Fixed-parameter tractable algorithms;(Parameterized) complexity",
    "Title": "A Parameterized Complexity Analysis of Generalized CP-Nets",
    "Topics10": "",
    "Topics1": "GTEP: Social Choice / Voting",
    "Topics2": "KRR: Computational Complexity of Reasoning",
    "Topics3": "KRR: Preferences",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Social Choice / Voting;KRR: Computational Complexity of Reasoning;KRR: Preferences"
  },
  {
    "Document Index (generated)": 58,
    "Number of Records": 1,
    "Abstract": "Decomposition, i.e., independently analyzing possible subgames, has proven to be an essential principle for effective decision-making in perfect information games.  However, in imperfect information games, decomposition has proven to be problematic.  To date, all proposed techniques for decomposition in imperfect information games have abandoned theoretical guarantees.  This work presents the first technique for decomposing an imperfect information game into subgames that can be solved independently, while retaining optimality guarantees on the full-game solution.  We can use this technique to construct theoretically justified algorithms that make better use of information available at run-time, overcome memory or disk limitations at run-time, or make a time/space trade-off to overcome memory or disk limitations while solving a game.  In particular, we present an algorithm for subgame solving which guarantees performance in the whole game, in contrast to existing methods which may have unbounded error.  In addition, we present an offline game solving algorithm, CFR-D, which can produce a Nash equilibrium for a game that is larger than available storage.",
    "Authors1": "Neil Burch",
    "Authors2": "Michael Johanson",
    "Authors3": "Michael Bowling",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Neil Burch, Michael Johanson , Michael Bowling",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP)",
    "Keywords10": "",
    "Keywords1": "game theory",
    "Keywords2": "equilibrium theory",
    "Keywords3": "extensive-form games",
    "Keywords4": "imperfect information games",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "game theory;equilibrium theory;extensive-form games;imperfect information games",
    "Title": "Solving Imperfect Information Games Using Decomposition",
    "Topics10": "",
    "Topics1": "GTEP: Game Theory",
    "Topics2": "GTEP: Equilibrium",
    "Topics3": "GTEP: Imperfect Information",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Game Theory;GTEP: Equilibrium;GTEP: Imperfect Information"
  },
  {
    "Document Index (generated)": 59,
    "Number of Records": 1,
    "Abstract": "Image-based localization is an important problem in robotics and an integral part of visual mapping and navigation systems. An approach to robustly matching images to previously recorded ones must be able to cope with seasonal changes especially when it is supposed to work reliably over long periods of time.  In this paper, we present a novel approach to visual localization of mobile robots in outdoor environments, which is able to deal with substantial seasonal changes. We formulate image matching as a minimum cost flow problem in a data association graph to effectively exploit sequence information. This allows us to deal with non-matching image sequences that result from temporal occlusions or from visiting new places. We present extensive experimental evaluations under substantial seasonal changes. They suggest that our approach allows for an accurate matching across seasons and outperforms existing state-of-the-art methods such as FABMAP2 and SeqSLAM in such a context.",
    "Authors1": "Tayyab Naseer",
    "Authors2": "Luciano Spinello",
    "Authors3": "Wolfram Burgard",
    "Authors4": "Cyrill Stachniss",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Tayyab Naseer, Luciano Spinello, Wolfram Burgard , Cyrill Stachniss",
    "Groups1": "Robotics (ROB)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Robotics (ROB)",
    "Keywords10": "",
    "Keywords1": "robotics",
    "Keywords2": "visual localization",
    "Keywords3": "seasons",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "robotics;visual localization;seasons",
    "Title": "Robust Visual Robot Localization Across Seasons using Network Flows",
    "Topics10": "",
    "Topics1": "ROB: Localization, Mapping, and Navigation",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "ROB: Localization, Mapping, and Navigation"
  },
  {
    "Document Index (generated)": 60,
    "Number of Records": 1,
    "Abstract": "Infinite SVMs (iSVM) is a Dirichlet process (DP) mixture of large-margin classifiers. Though flexible in learning nonlinear classifiers and discovering latent clustering structures, iSVM has a difficult inference task and existing methods could hinder its applicability to large-scale problems. This paper presents a small-variance asymptotic analysis to derive a simple and efficient algorithm, which monotonically optimizes a max-margin DP-means (M2 DPM) problem, an extension of DP-means for both predictive learning and descriptive clustering. Our analysis is built on Gibbs infinite SVMs, an alternative DP mixture of large-margin machines,\nwhich admits a partially collapsed Gibbs sampler without truncation by exploring data augmentation techniques. Experimental results show that M2 DPM runs much faster than similar algorithms without sacrificing prediction accuracies.",
    "Authors1": "Yining Wang",
    "Authors2": "Jun Zhu",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Yining Wang , Jun Zhu",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "small-variance asymptotics",
    "Keywords2": "Bayesian nonparametric modeling",
    "Keywords3": "infinite SVM",
    "Keywords4": "collapsed Gibbs sampling",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "small-variance asymptotics;Bayesian nonparametric modeling;infinite SVM;collapsed Gibbs sampling",
    "Title": "Small-variance Asymptotics for Dirichlet Process Mixtures of SVMs",
    "Topics10": "",
    "Topics1": "NMLA: Bayesian Learning",
    "Topics2": "NMLA: Big Data / Scalability",
    "Topics3": "NMLA: Classification",
    "Topics4": "NMLA: Clustering",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Bayesian Learning;NMLA: Big Data / Scalability;NMLA: Classification;NMLA: Clustering"
  },
  {
    "Document Index (generated)": 61,
    "Number of Records": 1,
    "Abstract": "We consider a classic social choice problem in an online setting.  \nIn each round, a decision maker observes a single agent's preferences over\na set of $m$ candidates, and must choose whether to irrevocably add a candidate \nto a selection set of limited cardinality $k$.  Each agent's (positional) score \ndepends on the candidates in the set when he arrives, and the decision-maker's \ngoal is to maximize average (over all agents) score.\n\nWe prove that no algorithm (even randomized) can achieve an approximation\nfactor better than $O(\\log\\log m/ \\log m)$.  In contrast, if the agents \narrive in random order, we present a $(1 - 1/e - o(1))$-approximate\nalgorithm, matching a lower bound for the offline problem.\nWe show that improved performance is possible for natural input distributions\nor scoring rules.\n\nFinally, if the algorithm is permitted to revoke decisions at a fixed\ncost, we apply regret-minimization techniques to achieve approximation \n$1 - 1/e - o(1)$ even for arbitrary inputs.",
    "Authors1": "Joel Oren",
    "Authors2": "Brendan Lucier",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Joel Oren , Brendan Lucier",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP)",
    "Keywords10": "",
    "Keywords1": "Online algorithms",
    "Keywords2": "online learning",
    "Keywords3": "approximation algorithms",
    "Keywords4": "computational social choice",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Online algorithms;online learning;approximation algorithms;computational social choice",
    "Title": "Online (Budgeted) Social Choice",
    "Topics10": "",
    "Topics1": "GTEP: Game Theory",
    "Topics2": "GTEP: Social Choice / Voting",
    "Topics3": "GTEP: Adversarial Learning",
    "Topics4": "GTEP: Imperfect Information",
    "Topics5": "MAS: E-Commerce",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Game Theory;GTEP: Social Choice / Voting;GTEP: Adversarial Learning;GTEP: Imperfect Information;MAS: E-Commerce"
  },
  {
    "Document Index (generated)": 62,
    "Number of Records": 1,
    "Abstract": "Determinantal point process (DPP) is an important probabilistic model that has extensive applications in artificial intelligence. The exact sampling algorithm of DPP requires the full eigenvalue decomposition of the kernel matrix which has high time and space complexities. This prohibits the applications of DPP from large-scale datasets. Previous work has applied the Nystrom method to speedup the sampling algorithm of DPP, and error bounds have been established for the approximation. In this paper we  employ the matrix ridge approximation (MRA) to speedup the sampling algorithm of DPP, and we show that our approach MRA-DPP has stronger error bound than the Nystrom-DPP. In certain circumstance our MRA-DPP is provably exact, whereas the Nystrom-DPP is far from the ground truth. Finally, experiments on several real-world datasets show that our MRA-DPP is much more accurate than the other approximation approaches.",
    "Authors1": "Shusen Wang",
    "Authors2": "Chao Zhang",
    "Authors3": "Hui Qian",
    "Authors4": "Zhihua Zhang",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Shusen Wang, Chao Zhang, Hui Qian , Zhihua Zhang",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "kernel approximation",
    "Keywords2": "determinantal point process (DPP)",
    "Keywords3": "matrix ridge approximation (MRA)",
    "Keywords4": "the Nystrom method",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "kernel approximation;determinantal point process (DPP);matrix ridge approximation (MRA);the Nystrom method",
    "Title": "Using The Matrix Ridge Approximation to Speedup Determinantal Point Processes Sampling Algorithms",
    "Topics10": "",
    "Topics1": "NMLA: Big Data / Scalability",
    "Topics2": "NMLA: Kernel Methods",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Big Data / Scalability;NMLA: Kernel Methods"
  },
  {
    "Document Index (generated)": 63,
    "Number of Records": 1,
    "Abstract": "Although users' preference is semantically reflected in the free-form review texts, this wealth of information was not fully exploited for learning recommender models. Specifically, almost all existing recommendation algorithms only exploit rating scores in order to find users' preference, but ignore the review texts accompanied with rating information. In this paper, we propose a novel matrix factorization model (called TopicMF) which simultaneously considers the ratings and accompanied review texts. Experimental results on 20 real-world datasets show the superiority of our model over the state-of-the-art models, demonstrating its effectiveness for recommendation task.",
    "Authors1": "Yang Bao",
    "Authors2": "Hui Fang",
    "Authors3": "Jie Zhang",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Yang Bao, Hui Fang , Jie Zhang",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "Knowledge Representation and Reasoning (KRR)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW);Knowledge Representation and Reasoning (KRR)",
    "Keywords10": "",
    "Keywords1": "recommender system",
    "Keywords2": "ratings and free-form reviews",
    "Keywords3": "Non-negative matrix factorization",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "recommender system;ratings and free-form reviews;Non-negative matrix factorization",
    "Title": "TopicMF: Simultaneously Exploiting Ratings and Reviews for Recommendation",
    "Topics10": "",
    "Topics1": "AIW: Web-based recommendation systems",
    "Topics2": "KRR: Preferences",
    "Topics3": "NMLA: Recommender Systems",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: Web-based recommendation systems;KRR: Preferences;NMLA: Recommender Systems"
  },
  {
    "Document Index (generated)": 64,
    "Number of Records": 1,
    "Abstract": "Sustainable energy systems of the future will no longer be able to\nrely on the current paradigm that energy supply follows demand. Many\nof the renewable energy resources do not necessarily produce the\nenergy when it is needed, and therefore there is a need for new market\nstructures that motivate sustainable behaviors by participants.  The\nPower Trading Agent Competition ($\\powertac$) is a new annual\ncompetition that focuses on the design and operation of future retail\npower markets, specifically in smart grid environments with renewable\nenergy production, smart metering, and autonomous agents acting on\nbehalf of customers and retailers. It uses a rich, open-source\nsimulation platform that is based on real-world data and\nstate-of-the-art customer models. Its purpose is to help researchers\nunderstand the dynamics of customer and retailer decision-making, as\nwell as the robustness of proposed market designs. This paper\nintroduces OurAgent'13, the champion agent from the inaugural\ncompetition in 2013. OurAgent is an adaptive agent that learns and\nreacts to the environment in which it operates, by heavily relying on\nreinforcement-learning and prediction methods. This paper describes the\nconstituent components of our agent and examines the success of the\ncomplete agent through analysis of competition results and subsequent\ncontrolled experiments.",
    "Authors1": "Daniel Urieli",
    "Authors2": "Peter Stone",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Daniel Urieli , Peter Stone",
    "Groups1": "Applications (APP)",
    "Groups2": "Computational Sustainability and AI (CSAI)",
    "Groups3": "Game Theory and Economic Paradigms (GTEP)",
    "Groups4": "Machine Learning Applications (MLA)",
    "Groups5": "Multiagent Systems (MAS)",
    "Groups6": "Novel Machine Learning Algorithms (NMLA)",
    "Groups7": "Planning and Scheduling (PS)",
    "Groups8": "Reasoning under Uncertainty (RU)",
    "Groups": "Applications (APP);Computational Sustainability and AI (CSAI);Game Theory and Economic Paradigms (GTEP);Machine Learning Applications (MLA);Multiagent Systems (MAS);Novel Machine Learning Algorithms (NMLA);Planning and Scheduling (PS);Reasoning under Uncertainty (RU)",
    "Keywords10": "",
    "Keywords1": "Autonomous Electricity Trading Agents",
    "Keywords2": "Machine Learning",
    "Keywords3": "Reinforcement Learning",
    "Keywords4": "Online Learning",
    "Keywords5": "Smart Grid",
    "Keywords6": "Trading agents competition",
    "Keywords7": "Sustainable Energy",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Autonomous Electricity Trading Agents;Machine Learning;Reinforcement Learning;Online Learning;Smart Grid;Trading agents competition;Sustainable Energy",
    "Title": "OurAgent'13: A Champion Adaptive Power Trading Agent",
    "Topics10": "NMLA: Reinforcement Learning",
    "Topics1": "APP: Other Applications",
    "Topics2": "CSAI: Control and optimization of dynamic and spatiotemporal systems",
    "Topics3": "CSAI: Modeling and control of complex high-dimensional systems",
    "Topics4": "CSAI: Modeling the interactions of agents with different and often conflicting interests",
    "Topics5": "GTEP: Auctions and Market-Based Systems",
    "Topics6": "MLA: Environmental",
    "Topics7": "MLA: Applications of Supervised Learning",
    "Topics8": "MLA: Applications of Reinforcement Learning",
    "Topics9": "MAS: Multiagent Systems (General/other)",
    "Topics": "APP: Other Applications;CSAI: Control and optimization of dynamic and spatiotemporal systems;CSAI: Modeling and control of complex high-dimensional systems;CSAI: Modeling the interactions of agents with different and often conflicting interests;GTEP: Auctions and Market-Based Systems;MLA: Environmental;MLA: Applications of Supervised Learning;MLA: Applications of Reinforcement Learning;MAS: Multiagent Systems (General/other);NMLA: Reinforcement Learning;PS: Markov Models of Environments;RU: Sequential Decision Making"
  },
  {
    "Document Index (generated)": 65,
    "Number of Records": 1,
    "Abstract": "Influence maximization is a problem to find small sets of highly influential individuals in a social network to maximize the spread of influence under stochastic cascade models of propagation. Although the problem has been well-studied, it is still highly challenging to find solutions of high quality in large-scale networks of the day. While Monte-Carlo-simulation-based methods produce nearly optimal solutions with a theoretical guarantee, they are prohibitively slow for large graphs. As a result, many heuristic methods without any theoretical guarantee have been developed, but all of them substantially compromise solution quality. To address this issue, we propose a new method for the influence maximization problem. Unlike other recent heuristic methods, the proposed method is a Monte-Carlo-simulation-based method, and thus it consistently produces solutions of high quality with the theoretical guarantee. On the other hand, unlike other previous Monte-Carlo-simulation-based methods, it runs as fast as other state-of-the-art methods, and can be applied to large networks of the day. Through our extensive experiments, we demonstrate the scalability and the solution quality of the proposed method.",
    "Authors1": "Naoto Ohsaka",
    "Authors2": "Takuya Akiba",
    "Authors3": "Yuichi Yoshida",
    "Authors4": "Ken-Ichi Kawarabayashi",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Naoto Ohsaka, Takuya Akiba, Yuichi Yoshida , Ken-Ichi Kawarabayashi",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW)",
    "Keywords10": "",
    "Keywords1": "influence maximization",
    "Keywords2": "viral marketing",
    "Keywords3": "independent cascade model",
    "Keywords4": "social networks",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "influence maximization;viral marketing;independent cascade model;social networks",
    "Title": "Fast and Accurate Influence Maximization on Large Networks with Pruned Monte-Carlo Simulations",
    "Topics10": "",
    "Topics1": "AIW: Social networking and community identification",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: Social networking and community identification"
  },
  {
    "Document Index (generated)": 66,
    "Number of Records": 1,
    "Abstract": "Balanced knockout tournaments are one of the most common formats for sports competitions, and are also used in elections and decision-making. We consider the computational problem of finding the optimal draw for a particular player in such a tournament. The problem has generated considerable research within AI in recent years. We prove that checking whether there exists a draw in which a player wins is NP-complete, thereby settling an outstanding open problem. Our main result has a number of interesting implications on related counting and approximation problems. We present a memoization-based algorithm for the problem that is faster than previous approaches. Moreover, we highlight two natural cases that can be solved in polynomial time. All of our results also hold for the more general problem of counting the number of draws in which a given player is the winner.",
    "Authors1": "Haris Aziz",
    "Authors2": "Serge Gaspers",
    "Authors3": "Simon Mackenzie",
    "Authors4": "Nicholas Mattei",
    "Authors5": "Paul Stursberg",
    "Authors6": "Toby Walsh",
    "Authors7": "",
    "Authors": "Haris Aziz, Serge Gaspers, Simon Mackenzie, Nicholas Mattei, Paul Stursberg , Toby Walsh",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP)",
    "Keywords10": "",
    "Keywords1": "knockout tournaments",
    "Keywords2": "tournament fixing problem",
    "Keywords3": "manipulation",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "knockout tournaments;tournament fixing problem;manipulation",
    "Title": "Fixing a Balanced Knockout Tournament",
    "Topics10": "",
    "Topics1": "GTEP: Game Theory",
    "Topics2": "GTEP: Social Choice / Voting",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Game Theory;GTEP: Social Choice / Voting"
  },
  {
    "Document Index (generated)": 67,
    "Number of Records": 1,
    "Abstract": "Recently several inconsistency-tolerant semantics have been introduced for querying \ninconsistent description logic knowledge bases. Most of these semantics rely on the notion of a repair, defined as an inclusion-maximal subset of the facts (ABox) which is consistent with the ontology (TBox). In this paper, we investigate variants of two popular inconsistency-tolerant semantics obtained by replacing the classical notion of repair by different types of preferred repairs. For each of the resulting semantics, we analyze the complexity of conjunctive query answering over knowledge bases expressed in the lighweight logic DL-Lite. Unsurprisingly, query answering is intractable in all cases, but we nonetheless identify one notion of preferred repair, based upon assigning facts to priority levels, whose data complexity is ``only\" coNP-complete. This leads us to propose an approach combining incomplete tractable methods with calls to a SAT solver. An experimental evaluation of the approach shows good scalability on realistic cases.",
    "Authors1": "Camille Bourgaux",
    "Authors2": "Meghyn Bienvenu",
    "Authors3": "François Goasdoué",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Camille Bourgaux, Meghyn Bienvenu , François Goasdoué",
    "Groups1": "Knowledge Representation and Reasoning (KRR)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Knowledge Representation and Reasoning (KRR)",
    "Keywords10": "",
    "Keywords1": "inconsistency-tolerant query answering",
    "Keywords2": "complexity of query answering",
    "Keywords3": "DL-Lite",
    "Keywords4": "conjunctive queries",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "inconsistency-tolerant query answering;complexity of query answering;DL-Lite;conjunctive queries",
    "Title": "Querying Inconsistent Description Logic Knowledge Bases under Preferred Repair Semantics",
    "Topics10": "",
    "Topics1": "KRR: Ontologies",
    "Topics2": "KRR: Computational Complexity of Reasoning",
    "Topics3": "KRR: Description Logics",
    "Topics4": "KRR: Preferences",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "KRR: Ontologies;KRR: Computational Complexity of Reasoning;KRR: Description Logics;KRR: Preferences"
  },
  {
    "Document Index (generated)": 68,
    "Number of Records": 1,
    "Abstract": "Incomplete preferences are likely to arise in real-world preference aggregation and voting systems.\nThis paper deals with determining whether an incomplete preference profile is single-peaked.\nThis is essential information since many intractable voting problems become tractable for single-peaked profiles.\nWe prove that for incomplete profiles the problem of determining single-peakedness is NP-complete.\nDespite this computational hardness result, we find four polynomial-time algorithms for reasonably restricted settings.",
    "Authors1": "Martin Lackner",
    "Authors2": "",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Martin Lackner",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP)",
    "Keywords10": "",
    "Keywords1": "Computational social choice",
    "Keywords2": "Preferences",
    "Keywords3": "Incomplete information",
    "Keywords4": "Structure",
    "Keywords5": "Single-peaked",
    "Keywords6": "Algorithms",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Computational social choice;Preferences;Incomplete information;Structure;Single-peaked;Algorithms",
    "Title": "Incomplete Preferences in Single-Peaked Electorates",
    "Topics10": "",
    "Topics1": "GTEP: Social Choice / Voting",
    "Topics2": "GTEP: Imperfect Information",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Social Choice / Voting;GTEP: Imperfect Information"
  },
  {
    "Document Index (generated)": 69,
    "Number of Records": 1,
    "Abstract": "Diabetes complications often afflict diabetes patients seriously: over 68% of diabetes-related mortality is caused by diabetes complications. In this paper, we study the problem of automatically diagnosing diabetes complications from patients’ lab test results. The objective problem has two main challenges: 1) feature sparseness: a patient only takes 1:26% lab tests on average, and 65:5% types of lab tests are taken by less than 10 patients; 2) knowledge skewness: it lacks comprehensive detailed domain knowledge of association between diabetes complications and lab tests. To address these challenges, we propose a novel probabilistic model called Sparse Factor Graph Model (SparseFGM). SparseFGM projects sparse features onto a lower-dimensional latent space, which alleviates the problem of sparseness. SparseFGM is also able to capture the associations between complications and lab tests, which help handle the knowledge skewness. We evaluate the proposed model on a large collections of real medical records. SparseFGM outperforms (+20% by F1) baselines significantly and gives detailed associations between diabetes complications and lab tests.",
    "Authors1": "Yang Yang",
    "Authors2": "Walter Luyten",
    "Authors3": "Lu Liu",
    "Authors4": "Marie-Francine Moens",
    "Authors5": "Juanzi Li",
    "Authors6": "Jie Tang",
    "Authors7": "",
    "Authors": "Yang Yang, Walter Luyten, Lu Liu, Marie-Francine Moens, Juanzi Li , Jie Tang",
    "Groups1": "Applications (APP)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Applications (APP)",
    "Keywords10": "",
    "Keywords1": "forecast diabetes complications",
    "Keywords2": "feature sparseness",
    "Keywords3": "sparse factor graph",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "forecast diabetes complications;feature sparseness;sparse factor graph",
    "Title": "Forecasting Potential Diabetes Complications",
    "Topics10": "",
    "Topics1": "APP: Biomedical / Bioinformatics",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "APP: Biomedical / Bioinformatics"
  },
  {
    "Document Index (generated)": 70,
    "Number of Records": 1,
    "Abstract": "We deal with embedding a large scale knowledge graph composed of entities and relations into a continuous vector space. TransE is a promising method proposed recently which is very efficient while achieving the state-of-the-art predictive performance. We discuss about some mapping properties of relations which should be considered in embedding, such as symmetric, one-to-many, many-to-one, and many-to-many. We point out that TransE does not do well in dealing with these properties. Some complex models are capable to preserve these mapping properties but sacrificing the efficiency. To make a good trade-off between model capacity and efficiency, in this paper we propose a method where a relation is modeled as a hyperplane together with a translation operation on it. In this way, we can well preserve the above mapping properties of relations with almost the same model complexity of TransE. Meanwhile, as a practical knowledge graph is often far from completed, how to construct negative examples to reduce false negative labels in training is very important. Utilizing the one-to-many/many-to-one mapping property of a relation, we propose a simple trick to reduce the possibility of false negative labeling. We conduct extensive experiments on the tasks of link prediction, triplet classification and fact extraction on benchmark data sets from WordNet and Freebase. They show impressive improvements on predictive accuracy and also the capability to scale up.",
    "Authors1": "Zhen Wang",
    "Authors2": "Jianwen Zhang",
    "Authors3": "Jianlin Feng",
    "Authors4": "Zheng Chen",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Zhen Wang, Jianwen Zhang, Jianlin Feng , Zheng Chen",
    "Groups1": "Knowledge Representation and Reasoning (KRR)",
    "Groups2": "Machine Learning Applications (MLA)",
    "Groups3": "NLP and Knowledge Representation (NLPKR)",
    "Groups4": "Novel Machine Learning Algorithms (NMLA)",
    "Groups5": "Reasoning under Uncertainty (RU)",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Knowledge Representation and Reasoning (KRR);Machine Learning Applications (MLA);NLP and Knowledge Representation (NLPKR);Novel Machine Learning Algorithms (NMLA);Reasoning under Uncertainty (RU)",
    "Keywords10": "",
    "Keywords1": "Knowledge Embedding",
    "Keywords2": "Knowledge Graph",
    "Keywords3": "Knowledge Reasoning",
    "Keywords4": "Knowledge Completion",
    "Keywords5": "Fact Extraction",
    "Keywords6": "Representation Learning",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Knowledge Embedding;Knowledge Graph;Knowledge Reasoning;Knowledge Completion;Fact Extraction;Representation Learning",
    "Title": "Knowledge Graph Embedding by Translating on Hyperplanes",
    "Topics10": "",
    "Topics1": "KRR: Knowledge Representation (General/Other)",
    "Topics2": "MLA: Machine Learning Applications (General/other)",
    "Topics3": "NLPKR: Semantics and Summarization",
    "Topics4": "NLPTM: Information Extraction",
    "Topics5": "NMLA: Relational/Graph-Based Learning",
    "Topics6": "RU: Uncertainty Representations",
    "Topics7": "RU: Uncertainty in AI (General/Other)",
    "Topics8": "",
    "Topics9": "",
    "Topics": "KRR: Knowledge Representation (General/Other);MLA: Machine Learning Applications (General/other);NLPKR: Semantics and Summarization;NLPTM: Information Extraction;NMLA: Relational/Graph-Based Learning;RU: Uncertainty Representations;RU: Uncertainty in AI (General/Other)"
  },
  {
    "Document Index (generated)": 71,
    "Number of Records": 1,
    "Abstract": "Scoring systems are an extremely important class of election systems. A length-m (so-called) scoring vector applies only to m-candidate elections. To handle general elections, one must use a family of vectors, one per length.\n\nThe most elegant approach to making sure such families are \"family-like\" is the recently introduced notion of (polynomial-time uniform) pure scoring rules (Betzler and Dorn 2010), where each scoring vector is obtained from its precursor by adding one new coefficient.\n\nWe obtain the first dichotomy theorem for pure scoring rules for a control problem. In particular, for constructive control by adding voters (CCAV), which is arguably the most important control type, we show that CCAV is solvable in polynomial time for k-approval with k<=3, k-veto with k<=2, every pure scoring rule in which only the two top-rated candidates gain nonzero scores, and a particular rule that is a \"hybrid\" of 1-approval and 1-veto. For all other pure scoring rules, CCAV is NP-complete.\n\nWe also investigate the descriptive richness of different models for defining pure scoring rules, proving how more rule-generation time gives more rules, proving that rationals give more rules than do the natural numbers, and proving that some restrictions previously thought to be \"w.l.o.g.\" in fact do lose generality.",
    "Authors1": "Edith Hemaspa",
    "Authors2": "ra",
    "Authors3": "Lane A. Hemaspa",
    "Authors4": "ra",
    "Authors5": "Henning Schnoor",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Edith Hemaspa,ra, Lane A. Hemaspa,ra , Henning Schnoor",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP)",
    "Keywords10": "",
    "Keywords1": "voting systems",
    "Keywords2": "computational social choice",
    "Keywords3": "complexity",
    "Keywords4": "scoring rules",
    "Keywords5": "control of elections",
    "Keywords6": "dichotomy theorems",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "voting systems;computational social choice;complexity;scoring rules;control of elections;dichotomy theorems",
    "Title": "A Control Dichotomy for Pure Scoring Rules",
    "Topics10": "",
    "Topics1": "GTEP: Social Choice / Voting",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Social Choice / Voting"
  },
  {
    "Document Index (generated)": 72,
    "Number of Records": 1,
    "Abstract": "We present a new reasoner for RCC-8 constraint networks, called gp-rcc8, that is based on the patchwork property of path-consistent tractable RCC-8 networks and graph partitioning. We compare gp-rcc8 with state of the art reasoners that are based on constraint propagation and backtracking search as well as one that is based on graph partitioning and SAT solving. Our evaluation considers very large real-world RCC-8 networks and medium-sized synthetic ones, and shows that gp-rcc8\noutperforms the other reasoners for these networks, while it is less efficient for smaller networks.",
    "Authors1": "Charalampos Nikolaou",
    "Authors2": "Manolis Koubarakis",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Charalampos Nikolaou , Manolis Koubarakis",
    "Groups1": "Knowledge Representation and Reasoning (KRR)",
    "Groups2": "Search and Constraint Satisfaction (SCS)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Knowledge Representation and Reasoning (KRR);Search and Constraint Satisfaction (SCS)",
    "Keywords10": "",
    "Keywords1": "qualitative spatial reasoning",
    "Keywords2": "consistency checking",
    "Keywords3": "graph partitioning",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "qualitative spatial reasoning;consistency checking;graph partitioning",
    "Title": "Fast consistency checking of very large real-world RCC-8 constraint  networks using graph partitioning",
    "Topics10": "",
    "Topics1": "KRR: Geometric, Spatial, and Temporal Reasoning",
    "Topics2": "KRR: Qualitative Reasoning",
    "Topics3": "SCS: Constraint Satisfaction",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "KRR: Geometric, Spatial, and Temporal Reasoning;KRR: Qualitative Reasoning;SCS: Constraint Satisfaction"
  },
  {
    "Document Index (generated)": 73,
    "Number of Records": 1,
    "Abstract": "Multi-task learning seeks to improve the generalization performance by sharing common information among multiple related tasks. A key assumption in most MTL algorithms is that all tasks are related, which, however, may not hold in many real-world applications. Existing techniques, which attempt to address this issue, aim to identify groups of related tasks using group sparsity. In this paper, we propose a probabilistic tree sparsity (PTS) model to utilize the tree structure to obtain the sparse solution instead of the group structure. Specifically, each model coefficient in the learning model is decomposed into a product of multiple component coefficients each of which corresponds to a node in the tree. Based on the decomposition, Gaussian and Cauchy distributions are placed on the component coefficients as priors to restrict the model complexity. We devise an efficient expectation maximization algorithm to learn the model parameters. Experiments conducted on both synthetic and real-world problems show the effectiveness of our model compared with state-of-the-art baselines.",
    "Authors1": "Lei Han",
    "Authors2": "Yu Zhang",
    "Authors3": "Guojie Song",
    "Authors4": "Kunqing Xie",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Lei Han, Yu Zhang, Guojie Song , Kunqing Xie",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "Multi-Task Learning",
    "Keywords2": "Sparsity",
    "Keywords3": "Probabilistic Modeling",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Multi-Task Learning;Sparsity;Probabilistic Modeling",
    "Title": "Encoding Tree Sparsity in Multi-Task Learning: A Probabilistic Framework",
    "Topics10": "",
    "Topics1": "NMLA: Transfer, Adaptation, Multitask Learning",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Transfer, Adaptation, Multitask Learning"
  },
  {
    "Document Index (generated)": 74,
    "Number of Records": 1,
    "Abstract": "Generalized Fused Lasso (GFL) penalizes variables with L1 norms both on variables and their pairwise differences. GFL is useful when applied to data where prior information expressed with a graph is available in the domain. However, the existing algorithms for GFL take high computational cost and do not scale to large size problems. In this paper, we propose a fast and scalable algorithm for GFL. Based on the fact that the fusion penalty is the Lov´asz extension of a cut function, we show that the key building block is equivalent to recursively solving graph cut problems. We then solve GFL efficiently via a parametric flow algorithm. Runtime comparison demonstrate a significant speed-up over existing algorithms for GFL. Benefited from the scalability of our algorithm, we propose to formulate the diagnosis of Alzheimer’s Disease as GFL. Experiments demonstrate that GFL seems to be a natural way to formulate such a problem. Not only is the diagnosis performance promising, but the selected critical voxels are well structured, consistent across tasks and in accordance with clinical prior knowledge.",
    "Authors1": "Bo Xin",
    "Authors2": "Yoshinubo Kawahara",
    "Authors3": "Yizhou Wang",
    "Authors4": "Wen Gao",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Bo Xin, Yoshinubo Kawahara, Yizhou Wang , Wen Gao",
    "Groups1": "Machine Learning Applications (MLA)",
    "Groups2": "Novel Machine Learning Algorithms (NMLA)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Machine Learning Applications (MLA);Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "Generalized Fused Lasso",
    "Keywords2": "Alzhemier's Disease",
    "Keywords3": "Parametric graph cut",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Generalized Fused Lasso;Alzhemier's Disease;Parametric graph cut",
    "Title": "Efficient Generalized Fused Lasso with Application to the Diagnosis of Alzheimer’s Disease",
    "Topics10": "",
    "Topics1": "MLA: Bio/Medicine",
    "Topics2": "NMLA: Dimension Reduction/Feature Selection",
    "Topics3": "NMLA: Relational/Graph-Based Learning",
    "Topics4": "NMLA: Structured Prediction",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "MLA: Bio/Medicine;NMLA: Dimension Reduction/Feature Selection;NMLA: Relational/Graph-Based Learning;NMLA: Structured Prediction"
  },
  {
    "Document Index (generated)": 75,
    "Number of Records": 1,
    "Abstract": "Mining emotions hidden in images has attracted significant interest, in particular with the rapid development of social networks. The emotional impact is very important for understanding the intrinsic meanings of images. Despite many studies have been done, most existing methods focus on image content, but ignore the emotions of the user who has published the image. To understand the emotional impact from images, one interesting question is: How does social effect correlate with the emotion expressed in an image? Specifically, can we leverage friends interactions (e.g., discussions) related to an image to help discover the emotions? In this paper, we formally formalize the problem and propose a novel emotion learning method by jointly modeling images posted by social users and comments added by friends. One advantage of the model is that it can distinguish those comments that are closely related to the emotion expression for an image from other irrelevant ones. Experiments on an open Flickr dataset show that the proposed model can significantly improve (+37.4% by F1) the accuracy for inferring emotions from images. More interestingly, we found that half of the improvements are due to interactions between 1% of the closest friends.",
    "Authors1": "Yang Yang",
    "Authors2": "Jia Jia",
    "Authors3": "Shumei Zhang",
    "Authors4": "Boya Wu",
    "Authors5": "Jie Tang",
    "Authors6": "Juanzi Li",
    "Authors7": "",
    "Authors": "Yang Yang, Jia Jia, Shumei Zhang, Boya Wu, Jie Tang , Juanzi Li",
    "Groups1": "Applications (APP)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Applications (APP)",
    "Keywords10": "",
    "Keywords1": "emotion inference",
    "Keywords2": "images and comments",
    "Keywords3": "generative model",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "emotion inference;images and comments;generative model",
    "Title": "How Do Your Friends on Social Media Disclose Your Emotions?",
    "Topics10": "",
    "Topics1": "APP: Social Networks",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "APP: Social Networks"
  },
  {
    "Document Index (generated)": 76,
    "Number of Records": 1,
    "Abstract": "We propose a new framework for single-channel source separation that lies\nbetween the fully supervised and unsupervised setting. Instead of supervision,\nwe provide input features for each source signal and use convex methods to\nestimate the correlations between these features and the unobserved signal\ndecomposition. Contextually supervised source separation is a natural fit for\ndomains with large amounts of data but no explicit supervision; our motivating\napplication is energy disaggregation of hourly smart meter data (the separation\nof whole-home power signals into different energy uses). Here contextual\nsupervision allows us to provide itemized energy usage for thousands homes, a task\npreviously impossible due to the need for specialized data collection hardware.\nOn smaller datasets which include labels, we demonstrate that contextual\nsupervision improves significantly over a reasonable baseline and existing\nunsupervised methods for source separation. Finally, we analyze the case of\n$\\ell_2$ loss theoretically and show that recovery of the signal components\ndepends only on cross-correlation between features for different signals, not on\ncorrelations between features for the same signal.",
    "Authors1": "Matt Wytock",
    "Authors2": "Zico Kolter",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Matt Wytock , Zico Kolter",
    "Groups1": "Computational Sustainability and AI (CSAI)",
    "Groups2": "Machine Learning Applications (MLA)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Computational Sustainability and AI (CSAI);Machine Learning Applications (MLA)",
    "Keywords10": "",
    "Keywords1": "energy disaggregation",
    "Keywords2": "convex optimization",
    "Keywords3": "source separation",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "energy disaggregation;convex optimization;source separation",
    "Title": "Contextually Supervised Source Separation with Application to Energy Disaggregation",
    "Topics10": "",
    "Topics1": "CSAI: Modeling and prediction of dynamic and spatiotemporal phenomena and systems",
    "Topics2": "MLA: Environmental",
    "Topics3": "MLA: Applications of Unsupervised Learning",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "CSAI: Modeling and prediction of dynamic and spatiotemporal phenomena and systems;MLA: Environmental;MLA: Applications of Unsupervised Learning"
  },
  {
    "Document Index (generated)": 77,
    "Number of Records": 1,
    "Abstract": "Halpern and Pearl 2001 introduced a definition of\nactual causality; Eiter and Lukasiewicz 2001 showed that\ncomputing whether X=x is a cause of Y=y is NP-complete in binary\nmodels (where all variables can take on only two values) and\nSigma_2^P-complete in general models.  In the final version of their\npaper, Halpern and Pearl (2005) slightly modified the definition of\nactual cause, in order to deal with problems pointed by Hopkins and\nPearl in 2003.  As we show, this modification has a\nnontrivial impact on the complexity of computing actual cause.\nTo characterize the complexity, a new family D_k, k= 1, 2, 3, ...\nis introduced, which generalizes the class D^P introduced by\nPapadimitriou and Yannakakis (1984)  (D^P is just D_1.)\nWe show that the complexity of computing causality is D_2-complete\nunder the new definition.  Chockler and Halpern 2004 extended the\ndefinition of causality by introducing notions of responsibility\nand blame. They characterized the complexity of determining the\ndegree of responsibility and blame using the original definition of\ncausality.  Again, we show that changing the definition of causality\naffects the complexity, and completely characterize the complexity of\ndetermining the degree of responsibility and blame with the new definition.",
    "Authors1": "Hana Chockler",
    "Authors2": "Gadi Aleks",
    "Authors3": "rowicz",
    "Authors4": "Joseph Y. Halpern",
    "Authors5": "Alex",
    "Authors6": "er Ivrii",
    "Authors7": "",
    "Authors": "Hana Chockler, Gadi Aleks,rowicz, Joseph Y. Halpern , Alex,er Ivrii",
    "Groups1": "Knowledge Representation and Reasoning (KRR)",
    "Groups2": "Reasoning under Uncertainty (RU)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Knowledge Representation and Reasoning (KRR);Reasoning under Uncertainty (RU)",
    "Keywords10": "",
    "Keywords1": "Knowledge Representation and Reasoning",
    "Keywords2": "Causal Models",
    "Keywords3": "Structural Causality",
    "Keywords4": "Complexity",
    "Keywords5": "Strong Cause",
    "Keywords6": "Actual Cause",
    "Keywords7": "Polynomial Hierarchy",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Knowledge Representation and Reasoning;Causal Models;Structural Causality;Complexity;Strong Cause;Actual Cause;Polynomial Hierarchy",
    "Title": "The Computational Complexity of Structure-Based Causality",
    "Topics10": "",
    "Topics1": "KRR: Action, Change, and Causality",
    "Topics2": "KRR: Computational Complexity of Reasoning",
    "Topics3": "KRR: Qualitative Reasoning",
    "Topics4": "KRR: Reasoning with Beliefs",
    "Topics5": "RU: Uncertainty Representations",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "KRR: Action, Change, and Causality;KRR: Computational Complexity of Reasoning;KRR: Qualitative Reasoning;KRR: Reasoning with Beliefs;RU: Uncertainty Representations"
  },
  {
    "Document Index (generated)": 78,
    "Number of Records": 1,
    "Abstract": "We present a novel extension of normal form games that we call biased games. In these games, a player's utility is influenced by the distance between his mixed strategy and a given base strategy. We argue that biased games capture important aspects of the interaction between software agents. Our main result is that biased games satisfying certain mild conditions always admit an equilibrium. We also tackle the computation of equilibria in biased games.",
    "Authors1": "Ioannis Caragiannis",
    "Authors2": "David Kurokawa",
    "Authors3": "Ariel Procaccia",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Ioannis Caragiannis, David Kurokawa , Ariel Procaccia",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP)",
    "Keywords10": "",
    "Keywords1": "Equilibrium existence",
    "Keywords2": "Equilibrium computation",
    "Keywords3": "Solutions concepts",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Equilibrium existence;Equilibrium computation;Solutions concepts",
    "Title": "Biased Games",
    "Topics10": "",
    "Topics1": "GTEP: Game Theory",
    "Topics2": "GTEP: Equilibrium",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Game Theory;GTEP: Equilibrium"
  },
  {
    "Document Index (generated)": 79,
    "Number of Records": 1,
    "Abstract": "Extracting the 3D geometry plays an important part in scene understanding. Recently, structured prediction-based, robust visual descriptors are proposed for extracting the indoor scene layout from a passive agent’s perspective, i.e., single image. This robustness is mainly due to modeling the physical interaction of the underlying room geometry with the objects and the humans present in the room. In this work we add the physical constraints coming from acoustic echoes, generated by an audio source, to this visual model. Our audio-visual 3D geometry descriptor improves over the state of the art in passive perception models as shown by experiments.",
    "Authors1": "Muhammad Wajahat Hussain",
    "Authors2": "Javier Civera",
    "Authors3": "Luis Montano",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Muhammad Wajahat Hussain, Javier Civera , Luis Montano",
    "Groups1": "Knowledge Representation and Reasoning (KRR)",
    "Groups2": "Machine Learning Applications (MLA)",
    "Groups3": "Vision (VIS)",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Knowledge Representation and Reasoning (KRR);Machine Learning Applications (MLA);Vision (VIS)",
    "Keywords10": "",
    "Keywords1": "Scene layout",
    "Keywords2": "Scene understanding",
    "Keywords3": "Acoustic echoes",
    "Keywords4": "Room geometry",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Scene layout;Scene understanding;Acoustic echoes;Room geometry",
    "Title": "Grounding Acoustic Echoes In Single View Geometry Estimation",
    "Topics10": "",
    "Topics1": "KRR: Geometric, Spatial, and Temporal Reasoning",
    "Topics2": "MLA: Applications of Supervised Learning",
    "Topics3": "MLA: Machine Learning Applications (General/other)",
    "Topics4": "VIS: Perception",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "KRR: Geometric, Spatial, and Temporal Reasoning;MLA: Applications of Supervised Learning;MLA: Machine Learning Applications (General/other);VIS: Perception"
  },
  {
    "Document Index (generated)": 80,
    "Number of Records": 1,
    "Abstract": "While stable matching problems are widely studied, little work has investigated schemes for effectively eliciting agent preferences using either preference (e.g., comparison) queries or interviews (to form such comparisons); and no work has addressed how to combine both. We develop a new model for representing and assessing agent preferences that accommodates both forms of information and (heuristically) minimizes the number of queries and interviews required to determine a stable matching. Our Refine-then-Interview (RtI) scheme uses coarse preference queries to refine knowledge of agent preferences and relies on interviews only to assess comparisons of relatively \"close\" options. Empirical results show RtI to compare favorably to a recent pure interview minimization algorithm, and that the number of interviews is generally independent of the size of the market.",
    "Authors1": "Joanna Drummond",
    "Authors2": "Craig Boutilier",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Joanna Drummond , Craig Boutilier",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "Multiagent Systems (MAS)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP);Multiagent Systems (MAS)",
    "Keywords10": "",
    "Keywords1": "Stable Matching",
    "Keywords2": "Preference Elicitation",
    "Keywords3": "Computational Social Choice",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Stable Matching;Preference Elicitation;Computational Social Choice",
    "Title": "Preference Elicitation and Interview Minimization in Stable Matchings",
    "Topics10": "",
    "Topics1": "APP: Computational Social Science",
    "Topics2": "GTEP: Social Choice / Voting",
    "Topics3": "KRR: Preferences",
    "Topics4": "RU: Decision/Utility Theory",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "APP: Computational Social Science;GTEP: Social Choice / Voting;KRR: Preferences;RU: Decision/Utility Theory"
  },
  {
    "Document Index (generated)": 81,
    "Number of Records": 1,
    "Abstract": "Compared to conventional cars, electric vehicles still suffer from a considerably shorter cruising range. Combined with the sparsity of battery loading stations, the complete transition to E-mobility still seems a long way to go. In this paper, we consider the problem of placing as few loading stations as possible such that on any shortest path there are enough to guarantee sufficient energy supply. This means, that EV owners no longer have to plan their trips ahead incorporating loading station positions, and are no longer forced to accept long detours to reach their destinations. We show how to model this problem and introduce heuristics which provide close-to-optimal solutions even in large road networks.",
    "Authors1": "Stefan Funke",
    "Authors2": "André Nusser",
    "Authors3": "Sabine Stor",
    "Authors4": "t",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Stefan Funke, André Nusser , Sabine Stor,t",
    "Groups1": "Computational Sustainability and AI (CSAI)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Computational Sustainability and AI (CSAI)",
    "Keywords10": "",
    "Keywords1": "energy efficiency",
    "Keywords2": "electric vehicles",
    "Keywords3": "facility location",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "energy efficiency;electric vehicles;facility location",
    "Title": "Placement of Loading Stations for Electric Vehicles: No Detours Necessary!",
    "Topics10": "",
    "Topics1": "CSAI: Control and optimization of dynamic and spatiotemporal systems",
    "Topics2": "CSAI: Network modeling, prediction, and optimization.",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "CSAI: Control and optimization of dynamic and spatiotemporal systems;CSAI: Network modeling, prediction, and optimization."
  },
  {
    "Document Index (generated)": 82,
    "Number of Records": 1,
    "Abstract": "Keyphrases for a document concisely describe the document using a small set of \nphrases. Keyphrases have been previously\nshown to improve several document processing and retrieval tasks. In this work, we study keyphrase extraction from research papers by leveraging citation networks. \nWe propose CiteTextRank for extracting keyphrases,\na graph-based algorithm that incorporates evidence from \nboth a document's content as well as the contexts\nin which the document is referenced within the citation network. Our model obtains significant \nimprovements over the state-of-the-art models for this task. Specifically, on several datasets of research papers, \nCiteTextRank improves precision at rank $1$ by as much as 16-60\\%",
    "Authors1": "Sujatha Das Gollapalli",
    "Authors2": "Cornelia Caragea",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Sujatha Das Gollapalli , Cornelia Caragea",
    "Groups1": "NLP and Text Mining (NLPTM)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "NLP and Text Mining (NLPTM)",
    "Keywords10": "",
    "Keywords1": "CiteTextRank",
    "Keywords2": "Citation Network",
    "Keywords3": "PageRank",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "CiteTextRank;Citation Network;PageRank",
    "Title": "Extracting Keyphrases from Research Papers using Citation Networks",
    "Topics10": "",
    "Topics1": "NLPTM: Information Extraction",
    "Topics2": "NLPTM: Natural Language Processing (General/Other)",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NLPTM: Information Extraction;NLPTM: Natural Language Processing (General/Other)"
  },
  {
    "Document Index (generated)": 83,
    "Number of Records": 1,
    "Abstract": "Efficient and effective learning of social infectivity is a critical challenge in modeling diffusion phenomenons in social networks and other applications.\nExisting methods require substantial amount of event cascades to guarantee the learning accuracy, while only time-invariant infectivity is considered.\nOur paper overcomes those two drawbacks by constructing a more compact model and parameterizing the infectivity using time-varying features, thus dramatically reduces the data requirement, and enable the learning of time-varying infectivity which also takes into account the underlying network topology.\nWe replace the pairwise infectivity in the multidimensional Hawkes processes with linear combinations of those time-varying features, and optimize the associated coefficients with lasso regularization on coefficients. To efficiently solve the resulting optimization problem, we employ the technique of alternating direction method of multipliers, and under that framework update each coefficient independently, by optimizing a surrogate function which upper-bounds the original objective function. On both synthetic and real world data, the proposed method performs better than alternatives in terms of both recovering the hidden diffusion network and predicting the occurrence time of social events.",
    "Authors1": "Liangda Li",
    "Authors2": "Hongyuan Zha",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Liangda Li , Hongyuan Zha",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "Applications (APP)",
    "Groups3": "Machine Learning Applications (MLA)",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW);Applications (APP);Machine Learning Applications (MLA)",
    "Keywords10": "",
    "Keywords1": "Social infectivity",
    "Keywords2": "diffusion network",
    "Keywords3": "Hawkes process",
    "Keywords4": "time-varying feature",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Social infectivity;diffusion network;Hawkes process;time-varying feature",
    "Title": "Learning Parametric Models for Social Infectivity in Multi-dimensional Hawkes Processes",
    "Topics10": "",
    "Topics1": "AIW: Machine learning and the web",
    "Topics2": "AIW: Social networking and community identification",
    "Topics3": "APP: Social Networks",
    "Topics4": "MLA: Networks",
    "Topics5": "NMLA: Time-Series/Data Streams",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: Machine learning and the web;AIW: Social networking and community identification;APP: Social Networks;MLA: Networks;NMLA: Time-Series/Data Streams"
  },
  {
    "Document Index (generated)": 84,
    "Number of Records": 1,
    "Abstract": "Recently with the explosive growth of visual content on the Internet, large-scale image search has attracted intensive attention. It has been shown that mapping high-dimensional image descriptors to compact binary codes can lead to considerable efficiency gains in both storage and similarity computation of images. However, most existing methods still suffer from expensive training devoted to large-scale binary code learning. To address this issue, we propose a sub-selection based matrix manipulation algorithm which can significantly reduce the computational cost of code learning. As case studies, we apply the sub-selection algorithm to two popular quantization techniques PCA Quantization (PCAQ) and Iterative Quantization (ITQ). Crucially, we can justify the resulting sub-selective quantization by proving its theoretic properties. Extensive experiments are carried out on three image benchmarks with up to one million samples, corroborating the efficacy of the sub-selective quantization method in terms of image retrieval.",
    "Authors1": "Yeqing Li",
    "Authors2": "Chen Chen",
    "Authors3": "Wei Liu",
    "Authors4": "Junzhou Huang",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Yeqing Li, Chen Chen, Wei Liu , Junzhou Huang",
    "Groups1": "Machine Learning Applications (MLA)",
    "Groups2": "Vision (VIS)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Machine Learning Applications (MLA);Vision (VIS)",
    "Keywords10": "",
    "Keywords1": "subselection",
    "Keywords2": "image retrieval",
    "Keywords3": "binary embedding",
    "Keywords4": "image hashing",
    "Keywords5": "similarity search",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "subselection;image retrieval;binary embedding;image hashing;similarity search",
    "Title": "Sub-Selective Quantization for Large-Scale Image Search",
    "Topics10": "",
    "Topics1": "VIS: Image and Video Retrieval",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "VIS: Image and Video Retrieval"
  },
  {
    "Document Index (generated)": 85,
    "Number of Records": 1,
    "Abstract": "Accurately measuring the aerosol optical depth (AOD) is essential for our understanding of the climate. Currently, AOD can be measured by (i) satellite instruments, which operate on a global scale but have limited accuracies; and (ii) ground-based instruments, which are more accurate but not widely available. Recent approaches focus on integrating measurements from these two sources to complement each other. In this paper,  we further improve the prediction accuracy by using the observation that the AOD varies slowly in the spatial domain. Using a probabilistic approach, we impose this smoothness constraint by a Gaussian random field on the Earth's surface, which can be considered as a two-dimensional manifold. The proposed integration approach is computationally simple, and experimental results on both synthetic and real-world data sets show that it significantly outperforms the state-of-the-art.",
    "Authors1": "Shuai Zheng",
    "Authors2": "James Kwok",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Shuai Zheng , James Kwok",
    "Groups1": "Machine Learning Applications (MLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Machine Learning Applications (MLA)",
    "Keywords10": "",
    "Keywords1": "aerosol optical depth",
    "Keywords2": "manifold",
    "Keywords3": "Gaussian random field",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "aerosol optical depth;manifold;Gaussian random field",
    "Title": "Accurate Integration of Aerosol Predictions by Smoothing on a Manifold",
    "Topics10": "",
    "Topics1": "MLA: Environmental",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "MLA: Environmental"
  },
  {
    "Document Index (generated)": 86,
    "Number of Records": 1,
    "Abstract": "Trust has been used to replace or complement rating-based similarity in recommender systems, to improve the accuracy of rating prediction. However, people trusting each other may not always share similar preferences. In this paper, we try to fill in this gap by decomposing the original single-aspect trust information into four general trust aspects, i.e. benevolence, integrity, competence, and predictability, and further employing the support vector regression technique to incorporate them into the probabilistic matrix factorization model for rating prediction in recommender systems. Experimental results on four datasets demonstrate the superiority of our method over the state-of-the-art approaches.",
    "Authors1": "Hui Fang",
    "Authors2": "Yang Bao",
    "Authors3": "Jie Zhang",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Hui Fang, Yang Bao , Jie Zhang",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW)",
    "Keywords10": "",
    "Keywords1": "multi-facet trust",
    "Keywords2": "trust theory",
    "Keywords3": "probabilistic matrix factorization",
    "Keywords4": "rating prediction",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "multi-facet trust;trust theory;probabilistic matrix factorization;rating prediction",
    "Title": "Leveraging Decomposed Trust in Probabilistic Matrix Factorization for Effective Recommendation",
    "Topics10": "",
    "Topics1": "AIW: Representing, reasoning, and using provenance, trust, privacy, and security on the web",
    "Topics2": "AIW: Web-based recommendation systems",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: Representing, reasoning, and using provenance, trust, privacy, and security on the web;AIW: Web-based recommendation systems"
  },
  {
    "Document Index (generated)": 87,
    "Number of Records": 1,
    "Abstract": "Multi-instance learning deals with tasks where each example is a bag of instances, and the bag labels of training data are known whereas instance labels are unknown. Most previous studies on multi-instance learning assumed that the training and testing data are from the same distribution; however, this assumption is often violated in real tasks. In this paper, we present possibly the first study on multi-instance learning with distribution change. We propose the MICS approach by considering both bag-level distribution change and instance-level distribution change. Experiments show that MICS is almost always significantly better than many state-of-the-art multi-instance learning approaches when distribution change occurs, and even when there is no distribution change, it is still highly competitive.",
    "Authors1": "Wei-Jia Zhang",
    "Authors2": "Zhi-Hua Zhou",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Wei-Jia Zhang , Zhi-Hua Zhou",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "multi-instance learning",
    "Keywords2": "covariate shift",
    "Keywords3": "distribution change",
    "Keywords4": "importance sampling",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "multi-instance learning;covariate shift;distribution change;importance sampling",
    "Title": "Multi-Instance Learning with Distribution Change",
    "Topics10": "",
    "Topics1": "NMLA: Classification",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Classification"
  },
  {
    "Document Index (generated)": 88,
    "Number of Records": 1,
    "Abstract": "In multi-robot task allocation problems with in-schedule dependencies, tasks with high costs have a large influence on the overall time for a robot team to complete all tasks. \nWe reduce this influence by calculating a novel task cost dispersion value which measures robots' collective preference for each task. \nBy modifying the winner determination phase of sequential single-item auctions, our approach inspects the bids for every task to identify tasks which robots collectively consider to be high cost and we ensure these tasks are allocated before other tasks.\nWe show empirically this method reduces the overall time taken to complete all tasks.",
    "Authors1": "Bradford Heap",
    "Authors2": "Maurice Pagnucco",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Bradford Heap , Maurice Pagnucco",
    "Groups1": "Multiagent Systems (MAS)",
    "Groups2": "Robotics (ROB)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Multiagent Systems (MAS);Robotics (ROB)",
    "Keywords10": "",
    "Keywords1": "Multi-Robot Task Allocation",
    "Keywords2": "Distributed Auctions",
    "Keywords3": "Multi-Agent Systems",
    "Keywords4": "Multi-Robot Systems",
    "Keywords5": "Autonomous Systems",
    "Keywords6": "Autonomous Robotics",
    "Keywords7": "Market-Based Systems",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Multi-Robot Task Allocation;Distributed Auctions;Multi-Agent Systems;Multi-Robot Systems;Autonomous Systems;Autonomous Robotics;Market-Based Systems",
    "Title": "Minimising Undesired Task Costs in Multi-robot Task Allocation Problems with In-Schedule Dependencies",
    "Topics10": "",
    "Topics1": "GTEP: Auctions and Market-Based Systems",
    "Topics2": "MAS: Coordination and Collaboration",
    "Topics3": "MAS: Distributed Problem Solving",
    "Topics4": "ROB: Multi-Robot Systems",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Auctions and Market-Based Systems;MAS: Coordination and Collaboration;MAS: Distributed Problem Solving;ROB: Multi-Robot Systems"
  },
  {
    "Document Index (generated)": 89,
    "Number of Records": 1,
    "Abstract": "Recent literature has demonstrated the difficulty of classifying between composers who write in extremely similar styles (homogeneous style). Additionally, machine learning studies in this field have been exclusively of technical import with little musicological interpretability or significance. We present a supervised machine learning system which addresses the difficulty of differentiating between stylistically homogeneous composers using foundational elements of music, their complexity and interaction. Our work expands on previous style classification studies by developing more complex features as well as introducing a new class of musical features which focus on local irregularities within musical scores. We demonstrate the discriminative power of the system as applied to Haydn and Mozart's string quartets. Our results yield interpretable musicological conclusions about Haydn's and Mozart's stylistic differences while distinguishing between the composers with higher accuracy than previous studies in this domain.",
    "Authors1": "William Herl",
    "Authors2": "s",
    "Authors3": "Ricky Der",
    "Authors4": "Yoel Greenberg",
    "Authors5": "Simon Levin",
    "Authors6": "",
    "Authors7": "",
    "Authors": "William Herl,s, Ricky Der, Yoel Greenberg , Simon Levin",
    "Groups1": "Machine Learning Applications (MLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Machine Learning Applications (MLA)",
    "Keywords10": "",
    "Keywords1": "supervised machine learning",
    "Keywords2": "music",
    "Keywords3": "information retrieval",
    "Keywords4": "style classification",
    "Keywords5": "classical music",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "supervised machine learning;music;information retrieval;style classification;classical music",
    "Title": "A Machine Learning Approach to Musically Meaningful Homogeneous Style Classification",
    "Topics10": "",
    "Topics1": "MLA: Humanities",
    "Topics2": "MLA: Applications of Supervised Learning",
    "Topics3": "MLA: Machine Learning Applications (General/other)",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "MLA: Humanities;MLA: Applications of Supervised Learning;MLA: Machine Learning Applications (General/other)"
  },
  {
    "Document Index (generated)": 90,
    "Number of Records": 1,
    "Abstract": "Recently deep learning has been successfully adopted in many applications such as speech recognition, image classification, and natural language processing. In this work, we explore the possibility of employing deep learning in graph clustering. In particular, we propose a simple method, which first learns a nonlinear embedding of the original graph by stacked autoencoder, and then runs a $k$-means algorithm on the embedding to obtain the clustering result. We show that this simple method has a solid theoretical foundation, due to the equivalence between autoencoder and spectral clustering in terms of what they actually optimize. Then, we demonstrate that the proposed method is more efficient and flexible than spectral clustering. First, the computational complexity of autoencoder is much lower than spectral clustering: the former can be linear to the number of nodes in a sparse graph while the latter is super quadratic due to its dependency on an eigenvalue decomposition. Second, when additional constraints like sparsity is imposed, we can simply employ the \\emph{sparse} autoencoder developed in the literature of deep learning; however, it is non-straightforward to implement a sparse spectral method. We have conducted comprehensive experiments to test the performance of the proposed method. The results on various graph datasets show that it can significantly outperform the conventional spectral clustering method. This clearly indicates the effectiveness of deep learning in graph clustering, and enriches our understanding on the power of deep learning in general.",
    "Authors1": "Fei Tian",
    "Authors2": "Bin Gao",
    "Authors3": "Enhong Chen",
    "Authors4": "Tie-Yan Liu",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Fei Tian, Bin Gao, Enhong Chen , Tie-Yan Liu",
    "Groups1": "Machine Learning Applications (MLA)",
    "Groups2": "Novel Machine Learning Algorithms (NMLA)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Machine Learning Applications (MLA);Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "deep representations",
    "Keywords2": "clustering on graph",
    "Keywords3": "neural networks",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "deep representations;clustering on graph;neural networks",
    "Title": "Learning Deep Representations for Graph Clustering",
    "Topics10": "",
    "Topics1": "MLA: Applications of Unsupervised Learning",
    "Topics2": "NMLA: Clustering",
    "Topics3": "NMLA: Neural Networks/Deep Learning",
    "Topics4": "NMLA: Relational/Graph-Based Learning",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "MLA: Applications of Unsupervised Learning;NMLA: Clustering;NMLA: Neural Networks/Deep Learning;NMLA: Relational/Graph-Based Learning"
  },
  {
    "Document Index (generated)": 91,
    "Number of Records": 1,
    "Abstract": "In multi-instance multi-label learning (MIML), one object is represented by multiple instances and simultaneously associated with multiple labels. Existing MIML approaches have been found useful in many applications; however, most of them can only handle moderate-sized data. To efficiently handle large data sets, we propose the MIMLfast approach, which first constructs a low-dimensional subspace shared by all labels, and then trains label specific linear models to optimize approximated ranking loss via stochastic gradient descent. Although the MIML problem is complicated, MIMLfast is able to achieve excellent performance by exploiting label relations with shared space and discovering sub-concepts for complicated labels. Experiments show that the performance of MIMLfast is highly competitive to state-of-the-art techniques, whereas its time cost is much less; particularly, on a data set with 30K bags and 270K instances, where none of existing approaches can return results in 24 hours, MIMLfast takes only 12 minutes. Moreover, our approach is able to identify the most representative instance for each label, and thus providing a chance to understand the relation between input patterns and output semantics.",
    "Authors1": "Sheng-Jun Huang",
    "Authors2": "Wei Gao",
    "Authors3": "Zhi-Hua Zhou",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Sheng-Jun Huang, Wei Gao , Zhi-Hua Zhou",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "Multi-instance multi-label learning",
    "Keywords2": "Key instance",
    "Keywords3": "Fast",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Multi-instance multi-label learning;Key instance;Fast",
    "Title": "Fast Multi-Instance Multi-Label Learning",
    "Topics10": "",
    "Topics1": "NMLA: Classification",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Classification"
  },
  {
    "Document Index (generated)": 92,
    "Number of Records": 1,
    "Abstract": "Active surveillance is a desirable way to prevent the\nspread of infectious diseases in that it aims to timely\ndiscover individual incidences through an active searching\nfor patients. However, in practice active surveillance\nis difficult to implement especially when monitoring\nspace is large but the available resources are limited.\nTherefore, it is extremely important for public health\nauthorities to know how to distribute their very sparse\nresources to high-priority regions so as to maximize the\noutcomes of active surveillance. In this paper, we raise\nthe problem of active surveillance planning and provide\nan effective method to address it via modeling and mining\nspatiotemporal patterns of infection risk from heterogeneous\ndata sources. Taking malaria as an example,\nwe perform an empirical study on real-world data\nto validate our method and provide our new findings.",
    "Authors1": "Bo Yang",
    "Authors2": "Hua Guo",
    "Authors3": "Yi Yang",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Bo Yang, Hua Guo , Yi Yang",
    "Groups1": "Computational Sustainability and AI (CSAI)",
    "Groups2": "Novel Machine Learning Algorithms (NMLA)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Computational Sustainability and AI (CSAI);Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "active surveillance planning",
    "Keywords2": "spatiotemporal data mining",
    "Keywords3": "heterogeneous data mining",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "active surveillance planning;spatiotemporal data mining;heterogeneous data mining",
    "Title": "Modeling and mining spatiotemporal patterns of infection risk from heterogeneous data for active surveillance planning",
    "Topics10": "",
    "Topics1": "CSAI: Modeling and prediction of dynamic and spatiotemporal phenomena and systems",
    "Topics2": "CSAI: Control and optimization of dynamic and spatiotemporal systems",
    "Topics3": "NMLA: Data Mining and Knowledge Discovery",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "CSAI: Modeling and prediction of dynamic and spatiotemporal phenomena and systems;CSAI: Control and optimization of dynamic and spatiotemporal systems;NMLA: Data Mining and Knowledge Discovery"
  },
  {
    "Document Index (generated)": 93,
    "Number of Records": 1,
    "Abstract": "Planning-based methods to guide switched hybrid systems from an initial state into a desired goal region opens an interesting field for control. The idea of the Domain Predictive Control (DPC) approach is to generate input signals affecting both the numerical states and the modes of the system by stringing together atomic actions to a logically consistent plan. However, the existing DPC approach is restricted in the sense that a discrete and pre-defined input signal is required for each action. In this paper, we extend the approach to deal with symbolic states. This allows for the propagation of reachable regions of the state space emerging from actions with inputs that can be arbitrarily chosen within specified input bounds. The symbolic extension enables the applicability of DPC to systems with bounded inputs sets and increases its robustness due to the implicitly reduced search space. Moreover, precise numeric goal states instead of goal regions become reachable.",
    "Authors1": "Johannes Löhr",
    "Authors2": "Martin Wehrle",
    "Authors3": "Maria Fox",
    "Authors4": "Bernhard Nebel",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Johannes Löhr, Martin Wehrle, Maria Fox , Bernhard Nebel",
    "Groups1": "Planning and Scheduling (PS)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Planning and Scheduling (PS)",
    "Keywords10": "",
    "Keywords1": "planning",
    "Keywords2": "control",
    "Keywords3": "hybrid domains",
    "Keywords4": "switched linear dynamic systems",
    "Keywords5": "domain predictive control",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "planning;control;hybrid domains;switched linear dynamic systems;domain predictive control",
    "Title": "Symbolic Domain Predictive Control",
    "Topics10": "",
    "Topics1": "PS: Deterministic Planning",
    "Topics2": "PS: Mixed Discrete/Continuous Planning",
    "Topics3": "PS: Planning (General/Other)",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "PS: Deterministic Planning;PS: Mixed Discrete/Continuous Planning;PS: Planning (General/Other)"
  },
  {
    "Document Index (generated)": 94,
    "Number of Records": 1,
    "Abstract": "Peer Designed Agents (PDAs), computer agents developed by non-experts, is an emerging technology, widely advocated in recent literature for the purpose of replacing people in simulations and investigating human behavior.  Its main premise is that strategies programmed into these agents reliably reflect, to some extent, the behavior used by the programmer in real life.  In this paper we show that PDA development has an important side effect that has not been addressed to date --- the process that merely attempts to capture one's strategy is also likely to affect the developer's strategy.  The phenomenon is demonstrated experimentally using several performance measures.  This result has many implications concerning the appropriate design of PDA-based simulations, and the validness of using PDAs for studying individual decision making. \nFurthermore, we obtain that PDA development actually improved the developer's strategy according to all performance measures.  Therefore, PDA development can be suggested as a means for improving people's problem solving skills.",
    "Authors1": "Avshalom Elmalech",
    "Authors2": "David Sarne",
    "Authors3": "Noa Agmon",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Avshalom Elmalech, David Sarne , Noa Agmon",
    "Groups1": "Cognitive Modeling (CM)",
    "Groups2": "Humans and AI (HAI)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Cognitive Modeling (CM);Humans and AI (HAI)",
    "Keywords10": "",
    "Keywords1": "Decision-making",
    "Keywords2": "Peer Designed Agents",
    "Keywords3": "The Doors Game",
    "Keywords4": "Simulating Humans",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Decision-making;Peer Designed Agents;The Doors Game;Simulating Humans",
    "Title": "Can Agent Development Affect Developer's Strategy?",
    "Topics10": "",
    "Topics1": "CM: Simulating Humans",
    "Topics2": "HAI: Understanding People, Theories, Concepts and Methods",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "CM: Simulating Humans;HAI: Understanding People, Theories, Concepts and Methods"
  },
  {
    "Document Index (generated)": 95,
    "Number of Records": 1,
    "Abstract": "Many distance learning algorithms have been developed in recent years. However, few of them consider the problem when the class labels of training data are noisy, and this may lead to serious performance deterioration. In this paper, we present a robust distance learning method in the presence of label noise, by extending a previous non-parametric discriminative distance learning algorithm, i.e., Neighbourhood Components Analysis (NCA). Particularly, we model the conditional probability of each point’s true label over all the possible classe labels, and use it for a more robust estimation of intra-class scatter matrix. The model is then optimized within the EM framework. In addition, considering that the model tends to be complex under the situation of label noise, we propose to regularize its objective function to prevent overﬁtting. Our experiments on several UCI datasets and a real dataset with unknown noise patterns show that the proposed RNCA is more tolerant to class label noise compared to the original NCA method.",
    "Authors1": "Dong Wang",
    "Authors2": "Xiaoyang Tan",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Dong Wang , Xiaoyang Tan",
    "Groups1": "Machine Learning Applications (MLA)",
    "Groups2": "Novel Machine Learning Algorithms (NMLA)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Machine Learning Applications (MLA);Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "label noise",
    "Keywords2": "robust neighbourhood components analysis",
    "Keywords3": "distance learning",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "label noise;robust neighbourhood components analysis;distance learning",
    "Title": "Robust Distance Learning in the Presence of Label Noise",
    "Topics10": "",
    "Topics1": "NMLA: Feature Construction/Reformulation",
    "Topics2": "NMLA: Supervised Learning (Other)",
    "Topics3": "NMLA: Machine Learning (General/other)",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Feature Construction/Reformulation;NMLA: Supervised Learning (Other);NMLA: Machine Learning (General/other)"
  },
  {
    "Document Index (generated)": 96,
    "Number of Records": 1,
    "Abstract": "In the Real-Time Agent-Centered Search (RTACS) problem,\nan agent has to arrive at a goal location while acting and\nreasoning in the physical state space. Traditionally, RTACS\nproblems are solved by propagating and updating heuristic\nvalues of states visited by the agent. In existing RTACS\nalgorithms (e.g., the LRTA* family) the agent may revisit\neach state a many times causing the entire procedure to be\nquadratic in the state space. In this paper we study the Iterative\nDeepening (ID) approach for solving RTACS. We then\npresent Exponential Deepening A* (EDA*), a RTACS algorithm\nwhere the threshold between successive Depth-First\ncalls is increased exponentially. We prove that EDA* results\nin a linear worst case bound and support this experimentally\nby demonstrating up to 10x reduction over existing RTACS\nsolvers WRT. states expanded and CPU runtime.",
    "Authors1": "Guni Sharon",
    "Authors2": "Ariel Felner",
    "Authors3": "Nathan Sturtevant",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Guni Sharon, Ariel Felner , Nathan Sturtevant",
    "Groups1": "Heuristic Search and Optimization (HSO)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Heuristic Search and Optimization (HSO)",
    "Keywords10": "",
    "Keywords1": "Heuristic Search",
    "Keywords2": "Real-Time Search",
    "Keywords3": "Agent-Centered Search",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Heuristic Search;Real-Time Search;Agent-Centered Search",
    "Title": "Exponential Deepening A* for Real-Time Agent-Centered Search",
    "Topics10": "",
    "Topics1": "HSO: Heuristic Search",
    "Topics2": "HSO: Evaluation and Analysis (Search and Optimization)",
    "Topics3": "HSO: Search (General/Other)",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "HSO: Heuristic Search;HSO: Evaluation and Analysis (Search and Optimization);HSO: Search (General/Other)"
  },
  {
    "Document Index (generated)": 97,
    "Number of Records": 1,
    "Abstract": "Face recognition has been widely studied due to its importance in various applications. However, the case that both training images and testing images are corrupted is not well addressed. Motivated by the success of low-rank matrix recovery, we propose a novel semi-supervised low-rank matrix recovery algorithm for robust face recognition. The proposed method can learn robust discriminative representations for both training images and testing images simultaneously by exploiting the classwise block-diagonal structure. Specifically, low-rank matrix approximation can handle the possible contamination of data and the sparse noises. Moreover, the classwise block-diagonal structure is exploited to promote discrimination between different classes. The above issues are formulated into a unified objective function and we design an efficient optimization procedure based on augmented Lagrange multiplier method to solve it. Extensive experiments on three public databases are performed to validate the effectiveness of our approach. The strong identification capability of representations with block-diagonal structure is verified.",
    "Authors1": "Yong Li",
    "Authors2": "Jing Liu",
    "Authors3": "Zechao Li",
    "Authors4": "Yangmuzi Zhang",
    "Authors5": "Hanqing Lu",
    "Authors6": "Songde Ma",
    "Authors7": "",
    "Authors": "Yong Li, Jing Liu, Zechao Li, Yangmuzi Zhang, Hanqing Lu , Songde Ma",
    "Groups1": "Vision (VIS)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Vision (VIS)",
    "Keywords10": "",
    "Keywords1": "Low-Rank Representations",
    "Keywords2": "Classwise Block-Diagonal Structure",
    "Keywords3": "Robust Face Recognition",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Low-Rank Representations;Classwise Block-Diagonal Structure;Robust Face Recognition",
    "Title": "Learning Low-Rank Representations with Classwise Block-Diagonal Structure for Robust Face Recognition",
    "Topics10": "",
    "Topics1": "CS: Structural learning and knowledge capture",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "CS: Structural learning and knowledge capture"
  },
  {
    "Document Index (generated)": 98,
    "Number of Records": 1,
    "Abstract": "A model of the problem of charging and discharging electrical vehicles as a congestion game is presented. A generalization of congestion games -- feedback congestion games (FCG) -- is introduced. The charging of grid-integrated vehicles, which can also discharge energy back to the grid, is a natural FCG application. FCGs are proven to be exact potential games and therefore converge to a pure-strategy Nash equilibrium by an iterated better-response process. A compact representation and an algorithm that enable efficient best-response search are presented. A detailed empirical evaluation assesses the performance of the iterated best-response process. The evaluation considers the quality of the resulting solutions and the rate of convergence to a stable state. The effect of allowing to also discharge batteries using FCG is compared to scenarios that only include charging and is found to dramatically improve the predictability of the achieved solutions as well as the balancing of load.",
    "Authors1": "Benny Lutati",
    "Authors2": "Vadim Levit",
    "Authors3": "Tal Grinshpoun",
    "Authors4": "Amnon Meisels",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Benny Lutati, Vadim Levit, Tal Grinshpoun , Amnon Meisels",
    "Groups1": "Computational Sustainability and AI (CSAI)",
    "Groups2": "Game Theory and Economic Paradigms (GTEP)",
    "Groups3": "Multiagent Systems (MAS)",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Computational Sustainability and AI (CSAI);Game Theory and Economic Paradigms (GTEP);Multiagent Systems (MAS)",
    "Keywords10": "",
    "Keywords1": "Congestion games",
    "Keywords2": "Potential games",
    "Keywords3": "EV charging",
    "Keywords4": "V2G",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Congestion games;Potential games;EV charging;V2G",
    "Title": "Congestion Games for V2G-Enabled EV Charging",
    "Topics10": "",
    "Topics1": "CSAI: Modeling the interactions of agents with different and often conflicting interests",
    "Topics2": "GTEP: Coordination and Collaboration",
    "Topics3": "MAS: Distributed Problem Solving",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "CSAI: Modeling the interactions of agents with different and often conflicting interests;GTEP: Coordination and Collaboration;MAS: Distributed Problem Solving"
  },
  {
    "Document Index (generated)": 99,
    "Number of Records": 1,
    "Abstract": "An important requirement of household energy simulation models is their accuracy in estimating energy demand and its fluctuations. Occupant behavior has a major impact upon energy demand. However, Markov chains, the traditional approach to model occupant behavior, (1) has limitations in accurately capturing the coordinated behavior of occupants and (2) is prone to over-fitting. To address these issues, we propose a novel approach that relies on a combination of data mining techniques. The core idea of our model is to determine the behavior of occupants based on nearest neighbor comparison over a database of sample data. Importantly, the model takes into account features related to the coordination of occupants' activities. We use a customized distance function suited for mixed categorical and numerical data. Further, association rule learning allows us to capture the coordination between occupants. Using real data from four households in Japan we are able to show that our model outperforms the traditional Markov chain model with respect to occupant coordination and generalization of behavior patterns.",
    "Authors1": "Márcia Baptista",
    "Authors2": "Anjie Fang",
    "Authors3": "Helmut Prendinger",
    "Authors4": "Rui Prada",
    "Authors5": "Yohei Yamaguchi",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Márcia Baptista, Anjie Fang, Helmut Prendinger, Rui Prada , Yohei Yamaguchi",
    "Groups1": "Machine Learning Applications (MLA)",
    "Groups2": "Multiagent Systems (MAS)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Machine Learning Applications (MLA);Multiagent Systems (MAS)",
    "Keywords10": "",
    "Keywords1": "Household occupant behavior modeling",
    "Keywords2": "Markov chain models",
    "Keywords3": "Nearest Neighbor algorithm",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Household occupant behavior modeling;Markov chain models;Nearest Neighbor algorithm",
    "Title": "Accurate Household Occupant Behavior Modeling Based on Data Mining Techniques",
    "Topics10": "",
    "Topics1": "MLA: Applications of Supervised Learning",
    "Topics2": "MLA: Machine Learning Applications (General/other)",
    "Topics3": "MAS: Agent-based Simulation and Emergent Behavior",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "MLA: Applications of Supervised Learning;MLA: Machine Learning Applications (General/other);MAS: Agent-based Simulation and Emergent Behavior"
  },
  {
    "Document Index (generated)": 100,
    "Number of Records": 1,
    "Abstract": "Scenario-based serious-games have become a main tool for\nlearning new skills and capabilities. An important factor in\nthe development of such systems is reducing the time and cost\noverhead in manually creating content for these scenarios. To do so, we present ScenarioGen, an automatic method for generating content about everyday activities through combining computer science techniques with the crowd. ScenarioGen uses the crowd in three different ways: to capture a database of scenarios of everyday activities, to generate a database of likely replacements for specific events within that scenario, and to evaluate the resulting scenarios. We evaluated ScenarioGen in 6 different content domains and found that it was consistently rated as coherent and consistent as the originally captured content. We also compared ScenarioGen’s content to that created by traditional planning techniques. We found that both methods were equally effective in generated coherent and consistent scenarios, yet ScenarioGen’s content was found to be more varied and easier to create.",
    "Authors1": "Sigal Sina",
    "Authors2": "Avi Rosenfeld",
    "Authors3": "Sarit Kraus",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Sigal Sina, Avi Rosenfeld , Sarit Kraus",
    "Groups1": "Game Playing and Interactive Entertainment (GPIE)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Playing and Interactive Entertainment (GPIE)",
    "Keywords10": "",
    "Keywords1": "Scenario-Based Serious-Games",
    "Keywords2": "Generated Content",
    "Keywords3": "Crowd-Sourcing",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Scenario-Based Serious-Games;Generated Content;Crowd-Sourcing",
    "Title": "Generating Content for Scenario-Based Serious-Games using CrowdSourcing",
    "Topics10": "",
    "Topics1": "GPIE: Procedural Content Generation",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GPIE: Procedural Content Generation"
  },
  {
    "Document Index (generated)": 101,
    "Number of Records": 1,
    "Abstract": "ABox abduction is an important reasoning mechanism for description logic ontologies. It computes all minimal explanations (sets of ABox assertions) whose appending to a consistent ontology enforces the entailment of an observation while keeps the ontology consistent. We focus on practical computation for a general problem of ABox abduction, called the query abduction problem, where an observation is a Boolean conjunctive query and the explanations may contain fresh individuals neither in the ontology nor in the observation. However, in this problem there can be infinitely many minimal explanations. Hence we first identify a class of TBoxes called first-order rewritable TBoxes. It guarantees the existence of finitely many minimal explanations and is sufficient for many ontology applications. To reduce the number of explanations that need to be computed, we introduce a special kind of minimal explanations called representative explanations from which all minimal explanations can be retrieved. We develop a tractable method (in data complexity) for computing all representative explanations in a consistent ontology whose TBox is first-order rewritable. Experimental results demonstrate that the method is efficient and scalable for ontologies with large ABoxes.",
    "Authors1": "Jianfeng Du",
    "Authors2": "Kewen Wang",
    "Authors3": "Yi-Dong Shen",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Jianfeng Du, Kewen Wang , Yi-Dong Shen",
    "Groups1": "Knowledge Representation and Reasoning (KRR)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Knowledge Representation and Reasoning (KRR)",
    "Keywords10": "",
    "Keywords1": "ABox abduction",
    "Keywords2": "abductive reasoning",
    "Keywords3": "query abduction problem",
    "Keywords4": "description logics",
    "Keywords5": "first-order rewritable",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "ABox abduction;abductive reasoning;query abduction problem;description logics;first-order rewritable",
    "Title": "A Tractable Approach to ABox Abduction over Description Logic Ontologies",
    "Topics10": "",
    "Topics1": "KRR: Description Logics",
    "Topics2": "KRR: Diagnosis and Abductive Reasoning",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "KRR: Description Logics;KRR: Diagnosis and Abductive Reasoning"
  },
  {
    "Document Index (generated)": 102,
    "Number of Records": 1,
    "Abstract": "Dynamic online content becomes the zeitgeist. Vibrant user groups are essential participants and promoters behind it. Studying temporal dynamics is a valuable means to uncover group characters. Since different user groups usually tend to have highly diverse interest and show distinct behavior patterns, they will exhibit varying temporal dynamics. However, most current work only use global trends of temporal topics and fail to distinguish such fine-grained patterns across groups.  \n\nIn this paper, we propose GrosToT (Group Specific Topics-over-Time), a unified probabilistic model which infers latent user groups and temporal topics. It can model group-specific temporal topic variation from social media stream. By leveraging the comprehensive group-specific temporal patterns, GrosToT significantly outperforms state-of-the-art dynamics modeling methods. Our proposed approach shows advantage not only in temporal dynamics modeling but also group content exploration. Based on GrosToT, we uncover the interplay between group interest and temporal dynamics. Specifically, we find that group's attention to their medium-interested topics are event-driven, showing rich bursts; while its engagement in group's dominating topics are interest-driven, remaining stable over time. The dynamics over different groups vary and reflect the groups' intention.",
    "Authors1": "Zhiting Hu",
    "Authors2": "Junjie Yao",
    "Authors3": "Bin Cui",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Zhiting Hu, Junjie Yao , Bin Cui",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "Machine Learning Applications (MLA)",
    "Groups3": "NLP and Knowledge Representation (NLPKR)",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW);Machine Learning Applications (MLA);NLP and Knowledge Representation (NLPKR)",
    "Keywords10": "",
    "Keywords1": "Social media",
    "Keywords2": "temporal dynamics",
    "Keywords3": "topic modeling",
    "Keywords4": "user group",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Social media;temporal dynamics;topic modeling;user group",
    "Title": "User Group Oriented Dynamics Exploration",
    "Topics10": "",
    "Topics1": "AIW: Human language technologies for web systems, including text summarization and machine translation",
    "Topics2": "AIW: Languages, tools, and methodologies for representing, managing, and visualizing semantic web data",
    "Topics3": "AIW: Machine learning and the web",
    "Topics4": "AIW: Web-based opinion extraction and trend spotting",
    "Topics5": "MLA: Networks",
    "Topics6": "NLPKR: Semantics and Summarization",
    "Topics7": "NLPKR: Natural Language Processing (General/Other)",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: Human language technologies for web systems, including text summarization and machine translation;AIW: Languages, tools, and methodologies for representing, managing, and visualizing semantic web data;AIW: Machine learning and the web;AIW: Web-based opinion extraction and trend spotting;MLA: Networks;NLPKR: Semantics and Summarization;NLPKR: Natural Language Processing (General/Other)"
  },
  {
    "Document Index (generated)": 103,
    "Number of Records": 1,
    "Abstract": "This paper presents the beginnings of an automatic statistician, focusing on regression problems.  Our system explores an open-ended space of possible statistical models to discover a good explanation of the data, and then produces a detailed report with figures and natural-language text.\n\nOur approach treats unknown functions nonparametrically using Gaussian processes, which has two important consequences. First, Gaussian processes model functions in terms of high-level properties (e.g. smoothness, trends, periodicity, changepoints).\nTaken together with the compositional structure of our language of models, this allows us to automatically describe functions through a decomposition into additive parts.  Second, the use of flexible nonparametric models and a rich language for composing them in an open-ended manner also results in state-of-the-art extrapolation performance evaluated over 13 real time series data sets from various domains.",
    "Authors1": "James Lloyd",
    "Authors2": "David Duvenaud",
    "Authors3": "Roger Grosse",
    "Authors4": "Josh Tenenbaum",
    "Authors5": "Zoubin Ghahramani",
    "Authors6": "",
    "Authors7": "",
    "Authors": "James Lloyd, David Duvenaud, Roger Grosse, Josh Tenenbaum , Zoubin Ghahramani",
    "Groups1": "Machine Learning Applications (MLA)",
    "Groups2": "Novel Machine Learning Algorithms (NMLA)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Machine Learning Applications (MLA);Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "Automatic statistician",
    "Keywords2": "gaussian processes",
    "Keywords3": "regression",
    "Keywords4": "bayesian",
    "Keywords5": "summarization",
    "Keywords6": "model description",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Automatic statistician;gaussian processes;regression;bayesian;summarization;model description",
    "Title": "Automatic Construction and Natural-Language Description of Nonparametric Regression Models",
    "Topics10": "",
    "Topics1": "MLA: Applications of Supervised Learning",
    "Topics2": "NMLA: Bayesian Learning",
    "Topics3": "NMLA: Kernel Methods",
    "Topics4": "NMLA: Time-Series/Data Streams",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "MLA: Applications of Supervised Learning;NMLA: Bayesian Learning;NMLA: Kernel Methods;NMLA: Time-Series/Data Streams"
  },
  {
    "Document Index (generated)": 104,
    "Number of Records": 1,
    "Abstract": "We introduce a new application of online dialogue analysis: supporting pedagogical assessment of online Q&A discussions. Extending the existing speech act framework, we capture common emotional expressions that often appear in student discussions, such as frustration and degree of certainty, and present a viable approach for the classification. We demonstrate how such dialogue information can be used in analyzing student discussions and identifying difficulties. In particular, the difficulty indicators are aligned to discussion patterns and student performance. We found that frustration occurs more frequently in longer discussions. The students who frequently express frustration tend to get lower grades than others. On the other hand, frequency of high certainty expressions is positively correlated with the performance. We believe emotional and informational dialogue roles are important factors in explaining discussion development and student performance. We expect such online dialogue analyses can become a powerful assessment tool for instructors and education researchers.",
    "Authors1": "Jaebong Yoo",
    "Authors2": "Jihie Kim",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Jaebong Yoo , Jihie Kim",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "Applications (APP)",
    "Groups3": "NLP and Machine Learning (NLPML)",
    "Groups4": "NLP and Text Mining (NLPTM)",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW);Applications (APP);NLP and Machine Learning (NLPML);NLP and Text Mining (NLPTM)",
    "Keywords10": "",
    "Keywords1": "Student online discussions",
    "Keywords2": "dialog analysis (emotional or information roles)",
    "Keywords3": "student performance prediction",
    "Keywords4": "computational linguistic features",
    "Keywords5": "educational data mining",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Student online discussions;dialog analysis (emotional or information roles);student performance prediction;computational linguistic features;educational data mining",
    "Title": "Capturing Difficulty Expressions in Student Online Q&A Discussions",
    "Topics10": "",
    "Topics1": "AIW: Question answering on the web",
    "Topics2": "APP: Computer-Aided Education",
    "Topics3": "MLA: Machine Learning Applications (General/other)",
    "Topics4": "NLPML: Discourse and Dialogue",
    "Topics5": "NLPML: Text Classification",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: Question answering on the web;APP: Computer-Aided Education;MLA: Machine Learning Applications (General/other);NLPML: Discourse and Dialogue;NLPML: Text Classification"
  },
  {
    "Document Index (generated)": 105,
    "Number of Records": 1,
    "Abstract": "Inference in large scale graphical models is an important task in many domains, and in particular probabilistic relational models (e.g. Markov logic networks). Such models often exhibit considerable symmetry, and it is a challenge to devise algorithms that exploit this symmetry to speed up inference. Recently, the automorphism group has been proposed to formalize mathematically what \"exploiting symmetry\" means. However, obtaining symmetry derived from automorphism is GI-hard, and consequently only a small fraction of the symmetry is easily available for effective employment. In this paper, we improve upon efficiency in two ways. First, we introduce the Permutation Constraint Graph (PCG), a platform on which greater portions of the symmetries can be revealed and exploited. PCGs classify clusters of variables by projecting relations between cluster members onto a graph, allowing for the efficient pruning of symmetrical clusters even before their generation. Second, we introduce a novel framework based on PCGs for the Sherali-Adams hierarchy of linear program (LP) relaxations, dedicated to exploiting this symmetry for the benefit of tight Maximum A Posteriori (MAP) approximations. Combined with the pruning power of PCG, the framework quickly generates compact formulations for otherwise intractable LPs as demonstrated by several empirical results.",
    "Authors1": "Udi Apsel",
    "Authors2": "Kristian Kersting",
    "Authors3": "Martin Mladenov",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Udi Apsel, Kristian Kersting , Martin Mladenov",
    "Groups1": "Reasoning under Uncertainty (RU)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Reasoning under Uncertainty (RU)",
    "Keywords10": "",
    "Keywords1": "Lifted Probabilistic Inference",
    "Keywords2": "Statistical Relational Learning",
    "Keywords3": "MAP Estimation",
    "Keywords4": "Linear Programming",
    "Keywords5": "Sherali-Adams Hierarchy",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Lifted Probabilistic Inference;Statistical Relational Learning;MAP Estimation;Linear Programming;Sherali-Adams Hierarchy",
    "Title": "Lifting Relational MAP-LP Relaxations using Permutation Constraint Graphs",
    "Topics10": "",
    "Topics1": "RU: Probabilistic Inference",
    "Topics2": "RU: Relational Probabilistic Models",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "RU: Probabilistic Inference;RU: Relational Probabilistic Models"
  },
  {
    "Document Index (generated)": 106,
    "Number of Records": 1,
    "Abstract": "The paper proposes a dynamic method, Recursive SBDS\n(ReSBDS), for efficient partial symmetry breaking. We\nfirst demonstrate how (partial) SBDS misses important\npruning opportunities when given only a subset of symmetries\nto break. The investigation pinpoints the culprit\nand in turn suggests rectification. The main idea is to\nadd extra conditional constraints during search recursively\nto prune also symmetric nodes of some pruned\nsubtrees. Thus, ReSBDS can break extra symmetry\ncompositions, but is carefully designed to break only the\nones that are easy to identify and inexpensive to break.\nWe present theorems to guarantee the soundness and\ntermination of our approach, and compare our method\nwith popular static and dynamic methods. When the\nvariable (value) heuristic is static, ReSBDS is also complete\nin eliminating all interchangeable variables (values)\ngiven only the generator symmetries. Extensive\nexperimentations confirm the efficiency of ReSBDS,\nwhen compared against state of the art methods.",
    "Authors1": "Zichen Zhu",
    "Authors2": "Jimmy Lee",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Zichen Zhu , Jimmy Lee",
    "Groups1": "Search and Constraint Satisfaction (SCS)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Search and Constraint Satisfaction (SCS)",
    "Keywords10": "",
    "Keywords1": "constraint satisfaction problems",
    "Keywords2": "symmetry breaking",
    "Keywords3": "SBDS",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "constraint satisfaction problems;symmetry breaking;SBDS",
    "Title": "Boosting SBDS for Partial Symmetry Breaking in Constraint Programming",
    "Topics10": "",
    "Topics1": "SCS: Constraint Satisfaction",
    "Topics2": "SCS: SAT and CSP: Modeling/Formulations",
    "Topics3": "SCS: Constraint Satisfaction (General/other)",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "SCS: Constraint Satisfaction;SCS: SAT and CSP: Modeling/Formulations;SCS: Constraint Satisfaction (General/other)"
  },
  {
    "Document Index (generated)": 107,
    "Number of Records": 1,
    "Abstract": "Multi-agent learning is a challenging open task in artificial intelligence. It is known an interesting connection between multi-agent learning algorithms and evolutionary game theory, showing that the learning dynamics of some algorithms can be modeled as replicator dynamics with a mutation term. Inspired by the recent sequence-form replicator dynamics, we develop a new version of the Q-learning algorithm working on the sequence form of an extensive-form game allowing thus an exponential reduction of the dynamics length w.r.t. those of the normal form. The dynamics of the proposed algorithm can be modeled by using the sequence-form replicator dynamics with a mutation term. We show that, although sequence-form and normal-form replicator dynamics are realization equivalent, the Q-learning algorithm applied to the two forms have non-realization equivalent dynamics. Originally from the previous works on evolutionary game theory models form multi-agent learning, we produce an experimental evaluation to show the accuracy of the model.",
    "Authors1": "Fabio Panozzo",
    "Authors2": "Nicola Gatti",
    "Authors3": "Marcello Restelli",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Fabio Panozzo, Nicola Gatti , Marcello Restelli",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "Multiagent Systems (MAS)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP);Multiagent Systems (MAS)",
    "Keywords10": "",
    "Keywords1": "Game Theory",
    "Keywords2": "Multiagent learning",
    "Keywords3": "Evolutionary game theory",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Game Theory;Multiagent learning;Evolutionary game theory",
    "Title": "Evolutionary dynamics of learning algorithms over the sequence form",
    "Topics10": "",
    "Topics1": "GTEP: Adversarial Learning",
    "Topics2": "GTEP: Equilibrium",
    "Topics3": "MAS: Multiagent Learning",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Adversarial Learning;GTEP: Equilibrium;MAS: Multiagent Learning"
  },
  {
    "Document Index (generated)": 108,
    "Number of Records": 1,
    "Abstract": "Qualitative Possibilistic Mixed-Observable MDPs ($\\pi$-MOMDPs), generalizing\n$\\pi$-MDPs and $\\pi$-POMDPs, are well-suited models to planning under\nuncertainty with mixed-observability when transition, observation and reward\nfunctions are not precisely known. Functions defining the model as well as\nintermediate calculations are valued in a finite possibilistic scale\n$\\mathcal{L}$, which induces a \\emph{finite} belief state space under partial\nobservability contrary to its probabilistic counterpart. In this paper, we\npropose the first study of factored $\\pi$-MOMDP models in order to solve large\nstructured planning problems under \\emph{imprecise} uncertainty, or considered\nas qualitative approximations of probabilistic problems. Building upon the SPUDD\nalgorithm for solving factored (probabilistic) MDPs, we conceived a symbolic\nalgorithm named PPUDD for solving factored $\\pi$-MOMDPs. Whereas SPUDD's\ndecision diagrams' leaves may be as large as the state space since their values\nare real numbers aggregated through additions and multiplications, PPUDD's ones\nalways remain in the finite scale $\\echL$ via $\\min$ and $\\max$ operations only.\nOur experiments show that PPUDD's computation time is much lower than SPUDD,\nSymbolic-HSVI and APPL for possibilistic and probabilistic versions of the same\nbenchmarks under either total or mixed observability, while providing\nhigh-quality policies.",
    "Authors1": "Nicolas Drougard",
    "Authors2": "Florent Teichteil-Königsbuch",
    "Authors3": "Jean-Loup Farges",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Nicolas Drougard, Florent Teichteil-Königsbuch , Jean-Loup Farges",
    "Groups1": "Knowledge Representation and Reasoning (KRR)",
    "Groups2": "Planning and Scheduling (PS)",
    "Groups3": "Reasoning under Uncertainty (RU)",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Knowledge Representation and Reasoning (KRR);Planning and Scheduling (PS);Reasoning under Uncertainty (RU)",
    "Keywords10": "",
    "Keywords1": "Qualitative Planning under Uncertainty",
    "Keywords2": "Symbolic Planning with Decision Diagrams",
    "Keywords3": "Possibilistic (PO)MDPs",
    "Keywords4": "Mixed Observability",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Qualitative Planning under Uncertainty;Symbolic Planning with Decision Diagrams;Possibilistic (PO)MDPs;Mixed Observability",
    "Title": "Structured Possibilistic Planning using Decision Diagrams",
    "Topics10": "RU: Uncertainty in AI (General/Other)",
    "Topics1": "KRR: Qualitative Reasoning",
    "Topics2": "KRR: Reasoning with Beliefs",
    "Topics3": "PS: Markov Models of Environments",
    "Topics4": "PS: Probabilistic Planning",
    "Topics5": "PS: Planning (General/Other)",
    "Topics6": "RU: Graphical Models (Other)",
    "Topics7": "RU: Decision/Utility Theory",
    "Topics8": "RU: Sequential Decision Making",
    "Topics9": "RU: Uncertainty Representations",
    "Topics": "KRR: Qualitative Reasoning;KRR: Reasoning with Beliefs;PS: Markov Models of Environments;PS: Probabilistic Planning;PS: Planning (General/Other);RU: Graphical Models (Other);RU: Decision/Utility Theory;RU: Sequential Decision Making;RU: Uncertainty Representations;RU: Uncertainty in AI (General/Other)"
  },
  {
    "Document Index (generated)": 109,
    "Number of Records": 1,
    "Abstract": "Multi-Instance Multi-Label (MIML) is a learning framework where an example is associated with multiple labels and represented by a set of feature vectors (multiple instances). In the original formalization of MIML learning, instances come from a single source (single view). To leverage multiple information sources (multi-view), we develop a multi-view MIML framework based on hierarchical Bayesian Network, and present an effective learning algorithm based on variational inference. The model can naturally deal with the examples in which some views could be absent (partial examples). On multi-view datasets, it is shown that our method is better than other multi-view and single-view approaches particularly in the presence of partial examples. On single-view benchmarks, extensive evaluation shows that our approach is highly comparable or better than other MIML approaches on labeling examples and instances. Moreover, our method can effectively handle datasets with a large number of labels.",
    "Authors1": "Cam-Tu Nguyen",
    "Authors2": "Xiaoliang Wang",
    "Authors3": "Zhi-Hua Zhou",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Cam-Tu Nguyen, Xiaoliang Wang , Zhi-Hua Zhou",
    "Groups1": "Machine Learning Applications (MLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Machine Learning Applications (MLA)",
    "Keywords10": "",
    "Keywords1": "multi-view learning.",
    "Keywords2": "multi-instance multi-label learning.",
    "Keywords3": "partial examples.",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "multi-view learning.;multi-instance multi-label learning.;partial examples.",
    "Title": "Labeling Complicated Objects: Multi-View Multi-Instance Multi-Label Learning",
    "Topics10": "",
    "Topics1": "AIW: AI for multimedia and multimodal web applications",
    "Topics2": "MLA: Applications of Supervised Learning",
    "Topics3": "MLA: Machine Learning Applications (General/other)",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: AI for multimedia and multimodal web applications;MLA: Applications of Supervised Learning;MLA: Machine Learning Applications (General/other)"
  },
  {
    "Document Index (generated)": 110,
    "Number of Records": 1,
    "Abstract": "In this paper we study when an LTL formula on finite traces (LTLf formula) is insensitive to infiniteness, that is, it can be correctly handled as a formula on infinite traces under the assumption that at a certain point the infinite trace starts repeating an end event forever, trivializing all other propositions to false. This intuition has been put forward and (wrongly) assumed to hold in general in the literature. We define a necessary and sufficient condition to characterize whether an LTLf formula is insensitive to infiniteness, which can be automatically checked by any LTL reasoner. Then, we show that typical LTLf specification patterns used in process and service modeling in CS, as well as trajectory constraints in Planning and transition-based LTLf specifications of action domains in KR, are indeed very often insensitive to infiniteness. This may help to explain why the assumption of interpreting LTL on finite and on infinite traces has been (wrongly) blurred. Possibly because of this blurring, virtually all literature detours to Buechi automata for constructing the NFA that accepts the traces satisfying an LTLf formula. As a further contribution, we give a simple direct algorithm for computing such NFA.",
    "Authors1": "Giuseppe De Giacomo",
    "Authors2": "Riccardo De Masellis",
    "Authors3": "Marco Montali",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Giuseppe De Giacomo, Riccardo De Masellis , Marco Montali",
    "Groups1": "Knowledge Representation and Reasoning (KRR)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Knowledge Representation and Reasoning (KRR)",
    "Keywords10": "",
    "Keywords1": "Linear Temporal Logic",
    "Keywords2": "Finite Traces",
    "Keywords3": "Reasoning about Actions",
    "Keywords4": "Trajectory Constraints in Planning",
    "Keywords5": "Logic-Based Process and Service Modelling",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Linear Temporal Logic;Finite Traces;Reasoning about Actions;Trajectory Constraints in Planning;Logic-Based Process and Service Modelling",
    "Title": "Reasoning on LTL on Finite Traces: Insensitivity to Infiniteness",
    "Topics10": "",
    "Topics1": "AIW: AI for web services: semantic descriptions, planning, matching, and coordination",
    "Topics2": "KRR: Action, Change, and Causality",
    "Topics3": "PS: Temporal Planning",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: AI for web services: semantic descriptions, planning, matching, and coordination;KRR: Action, Change, and Causality;PS: Temporal Planning"
  },
  {
    "Document Index (generated)": 111,
    "Number of Records": 1,
    "Abstract": "Vendors of all types face the problem of selecting a slate of product offerings---their assortment or catalog---that will maximize their profits.  The profitability of a catalog is determined by both customer preferences and the offerings of their competitors.\n\nWe develop a game-theoretic model for analyzing the vendor \\emph{catalog optimization} problem in the face of competing vendors. We show that computing a best response is intractable in general, but can be solved by dynamic programming given certain informational or structural assumptions about consumer preferences.\nWe also analyze conditions under which pure Nash equilibria exist. We study the price of anarchy (and stability), where applicable.",
    "Authors1": "Joel Oren",
    "Authors2": "Nina Narodytska",
    "Authors3": "Craig Boutilier",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Joel Oren, Nina Narodytska , Craig Boutilier",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "Knowledge Representation and Reasoning (KRR)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP);Knowledge Representation and Reasoning (KRR)",
    "Keywords10": "",
    "Keywords1": "Competitive assortment optimization",
    "Keywords2": "Nash equilibrium",
    "Keywords3": "Price of Stability",
    "Keywords4": "Computational social choice",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Competitive assortment optimization;Nash equilibrium;Price of Stability;Computational social choice",
    "Title": "A Game-theoretic Analysis of Catalog Optimization",
    "Topics10": "",
    "Topics1": "GTEP: Auctions and Market-Based Systems",
    "Topics2": "GTEP: Game Theory",
    "Topics3": "GTEP: Social Choice / Voting",
    "Topics4": "GTEP: Equilibrium",
    "Topics5": "GTEP: Imperfect Information",
    "Topics6": "KRR: Preferences",
    "Topics7": "KRR: Reasoning with Beliefs",
    "Topics8": "MAS: E-Commerce",
    "Topics9": "",
    "Topics": "GTEP: Auctions and Market-Based Systems;GTEP: Game Theory;GTEP: Social Choice / Voting;GTEP: Equilibrium;GTEP: Imperfect Information;KRR: Preferences;KRR: Reasoning with Beliefs;MAS: E-Commerce"
  },
  {
    "Document Index (generated)": 112,
    "Number of Records": 1,
    "Abstract": "We present three new filtering algorithms for the disjunctive constraint that all have a linear running time\ncomplexity in the number of tasks. The first algorithm filters the tasks according to the rules of the time tabling. The second algorithm performs an overload check that could also be used for the cumulative constraint. The third algorithm enforces the rules of detectable precedences. The two last algorithms use a new data structure that we introduce and that we call the time line. This data structure provides many constant time operations that were previously implemented in logarithmic time by the Theta-tree data structure. Experiments show that these new algorithms are competitive even for a small number of tasks and outperforms existing algorithms as the number of tasks increases.",
    "Authors1": "Hamed Fahimi",
    "Authors2": "Claude-Guy Quimper",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Hamed Fahimi , Claude-Guy Quimper",
    "Groups1": "Knowledge Representation and Reasoning (KRR)",
    "Groups2": "Planning and Scheduling (PS)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Knowledge Representation and Reasoning (KRR);Planning and Scheduling (PS)",
    "Keywords10": "",
    "Keywords1": "Constraint programming",
    "Keywords2": "Scheduling",
    "Keywords3": "Global constraints",
    "Keywords4": "Filtering algorithms",
    "Keywords5": "Disjunctive constraint",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Constraint programming;Scheduling;Global constraints;Filtering algorithms;Disjunctive constraint",
    "Title": "Linear-Time Filtering Algorithms for the Disjunctive Constraint",
    "Topics10": "",
    "Topics1": "PS: Scheduling",
    "Topics2": "SCS: Constraint Satisfaction",
    "Topics3": "SCS: Global Constraints",
    "Topics4": "SCS: Constraint Satisfaction (General/other)",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "PS: Scheduling;SCS: Constraint Satisfaction;SCS: Global Constraints;SCS: Constraint Satisfaction (General/other)"
  },
  {
    "Document Index (generated)": 113,
    "Number of Records": 1,
    "Abstract": "Tensor completion is an important topic in the area of image processing and computer vision research, which is generally built on extraction of the intrinsic structure of tensor data. However, tensor completion techniques are rarely used for action classification, which heavily relies on the extracted features of high-dimensional tensors as well. In this paper, we proposed a method for video based action classification via low-rank tensor completion. Since there could be distortion and corruption in the tensor, we projected the tensor into the subspace, which contains the invariant structure of the tensor and be used as the input of the classifier. The key point is that we aim to calculate the optimal projection matrices, which have the low-rank structure and are used to obtain the subspace. In order to integrate the useful supervisory information of data, we adopt the discriminant analysis criterion to learn the projection matrices and the augmented Lagrange multiplier (ALM) algorithm to solve the multi-variate optimization problem. We explained the properties of the projection matrices, which indicate the different meanings in the row space, column space and frame space, respectively. Experiments demonstrate that our method has obtained better accuracy compared with some other state-of-the-art low-rank tensor methods on MSR Hand Gesture 3D database and MSR Action 3D database.",
    "Authors1": "Chengcheng Jia",
    "Authors2": "Guoqiang Zhong",
    "Authors3": "Yun Fu",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Chengcheng Jia, Guoqiang Zhong , Yun Fu",
    "Groups1": "Machine Learning Applications (MLA)",
    "Groups2": "Vision (VIS)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Machine Learning Applications (MLA);Vision (VIS)",
    "Keywords10": "",
    "Keywords1": "low-rank",
    "Keywords2": "tensor",
    "Keywords3": "action recognition",
    "Keywords4": "discriminant analysis",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "low-rank;tensor;action recognition;discriminant analysis",
    "Title": "Low-Rank Tensor Completion with Discriminant Analysis for Action Classification",
    "Topics10": "",
    "Topics1": "MLA: Applications of Supervised Learning",
    "Topics2": "VIS: Face and Gesture Recognition",
    "Topics3": "VIS: Videos",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "MLA: Applications of Supervised Learning;VIS: Face and Gesture Recognition;VIS: Videos"
  },
  {
    "Document Index (generated)": 114,
    "Number of Records": 1,
    "Abstract": "Programming-by-example (PBE) has recently seen important advances in the domain of text editing,  but existing technology is restricted to transformations on relatively small unstructured text strings. In this paper we address structural/formatting transformations in richly formatted documents, using an approach based on the idea of least general generalizations from inductive inference, which avoids the scalability issues faced by state-of-the-art PBE methods.  We describe a novel domain specific language (DSL) that can succinctly describe expressive transformations over XML structures (used for describing richly formatted content) and is equipped with a natural partial ordering between programs based on a subsumption relation. We then describe a synthesis algorithm that, given a set of input-output examples of XML structures, identifies a minimal DSL program that is consistent with the examples. We present experimental results over a benchmark of formatting tasks that we collected from online help forums, which show an average of 4.1 examples required for task completion in a few seconds.",
    "Authors1": "Mohammad Raza",
    "Authors2": "Sumit Gulwani",
    "Authors3": "Natasa Milic-Frayling",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Mohammad Raza, Sumit Gulwani , Natasa Milic-Frayling",
    "Groups1": "Applications (APP)",
    "Groups2": "Heuristic Search and Optimization (HSO)",
    "Groups3": "Knowledge Representation and Reasoning (KRR)",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Applications (APP);Heuristic Search and Optimization (HSO);Knowledge Representation and Reasoning (KRR)",
    "Keywords10": "",
    "Keywords1": "Programming by example",
    "Keywords2": "Inductive inference",
    "Keywords3": "XML transformations",
    "Keywords4": "Program synthesis",
    "Keywords5": "Document editing interfaces",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Programming by example;Inductive inference;XML transformations;Program synthesis;Document editing interfaces",
    "Title": "Programming by Example using Least General Generalizations",
    "Topics10": "",
    "Topics1": "APP: Intelligent User Interfaces",
    "Topics2": "APP: Other Applications",
    "Topics3": "HSO: Search (General/Other)",
    "Topics4": "KRR: Knowledge Representation Languages",
    "Topics5": "KRR: Knowledge Representation (General/Other)",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "APP: Intelligent User Interfaces;APP: Other Applications;HSO: Search (General/Other);KRR: Knowledge Representation Languages;KRR: Knowledge Representation (General/Other)"
  },
  {
    "Document Index (generated)": 115,
    "Number of Records": 1,
    "Abstract": "Recent work has shown that diverse teams can outperform a uniform team made of copies of the best agent. However, there are fundamental questions that were not asked before. When should we use diverse or uniform teams? How does the performance change as the action space or the teams get larger? Hence, we present a new model of diversity for teams, that is more general than previous models. We prove that the performance of a diverse team improves as the size of the action space gets larger. Concerning the size of the diverse team, we show that the performance converges exponentially fast to the optimal one as we increase the number of agents. We present synthetic experiments that allow us to gain further insights: even though a diverse team outperforms a uniform team when the size of the action space increases, the uniform team will eventually again play better than the diverse team for a large enough action space. We verify our predictions in a system of Go playing agents, where we show a diverse team that improves in performance as the board size increases, and eventually overcomes a uniform team.",
    "Authors1": "Le",
    "Authors2": "ro Soriano Marcolino",
    "Authors3": "Haifeng Xu",
    "Authors4": "Albert Xin Jiang",
    "Authors5": "Milind Tambe",
    "Authors6": "Emma Bowring",
    "Authors7": "",
    "Authors": "Le,ro Soriano Marcolino, Haifeng Xu, Albert Xin Jiang, Milind Tambe , Emma Bowring",
    "Groups1": "Multiagent Systems (MAS)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Multiagent Systems (MAS)",
    "Keywords10": "",
    "Keywords1": "Team formation",
    "Keywords2": "Coordination & Collaboration",
    "Keywords3": "Distributed AI",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Team formation;Coordination & Collaboration;Distributed AI",
    "Title": "Give a Hard Problem to a Diverse Team: Exploring Large Action Spaces",
    "Topics10": "",
    "Topics1": "MAS: Coordination and Collaboration",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "MAS: Coordination and Collaboration"
  },
  {
    "Document Index (generated)": 116,
    "Number of Records": 1,
    "Abstract": "In this paper, we describe a simple randomized algorithm that runs in polynomial time and solves connected row convex (CRC) constraints in a distributed setting. CRC constraints generalize many known tractable classes of constraints like 2-SAT and implicational constraints. They can model problems in many domains including temporal reasoning and geometric reasoning; and generally speaking, play the role of ``Gaussians'' in the logical world. Our simple randomized algorithm for solving them in distributed settings, therefore, has a number of important applications. We support our claims through empirical results. We also generalize our algorithm to tractable classes of tree convex constraints.",
    "Authors1": "Nguyen Duc Thien",
    "Authors2": "T. K. Satish Kumar",
    "Authors3": "William Yeoh",
    "Authors4": "Sven Koenig",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Nguyen Duc Thien, T. K. Satish Kumar, William Yeoh , Sven Koenig",
    "Groups1": "Multiagent Systems (MAS)",
    "Groups2": "Search and Constraint Satisfaction (SCS)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Multiagent Systems (MAS);Search and Constraint Satisfaction (SCS)",
    "Keywords10": "",
    "Keywords1": "Connected Row Convex Constraints",
    "Keywords2": "Distributed CSP",
    "Keywords3": "Randomized Algorithms",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Connected Row Convex Constraints;Distributed CSP;Randomized Algorithms",
    "Title": "A Simple Polynomial-Time Randomized Distributed Algorithm for Connected Row Convex Constraints",
    "Topics10": "",
    "Topics1": "MAS: Distributed Problem Solving",
    "Topics2": "SCS: Distributed CSP/Optimization",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "MAS: Distributed Problem Solving;SCS: Distributed CSP/Optimization"
  },
  {
    "Document Index (generated)": 117,
    "Number of Records": 1,
    "Abstract": "Topic models have been widely used for sentiment analysis. Previous studies shows that supervised topic model can better model the sentiment expressions. However most of existing topic methods only model the sentiment text information, but do not consider the user, who expressed the sentiment, and the item, which the sentiment is expressed on. Since different users may use different sentiment expressions for different items, we argue that it is better to incorporate the user and item information into the topic model for sentiment analysis. In this paper, we propose a novel Supervised User-Item based Topic model, called SUIT model, for sentiment analysis. It can simultaneously utilize the textual topic and latent user-item factors. Our proposed method uses the tensor outer product of text topic proportion vector, user latent factor and item latent factor to model the sentiment label generalization. Extensive experiments are conducted on two datasets: review dataset and microblog dataset. The results demonstrate the advantages of our model. It shows significant improvement compared with supervised topic models and collaborative filtering methods.",
    "Authors1": "Fangtao Li",
    "Authors2": "Sheng Wang",
    "Authors3": "Shenghua Liu",
    "Authors4": "Ming Zhang",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Fangtao Li, Sheng Wang, Shenghua Liu , Ming Zhang",
    "Groups1": "NLP and Text Mining (NLPTM)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "NLP and Text Mining (NLPTM)",
    "Keywords10": "",
    "Keywords1": "topic model",
    "Keywords2": "sentiment analysis",
    "Keywords3": "review rating",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "topic model;sentiment analysis;review rating",
    "Title": "SUIT: A Supervised User-Item based Topic model for Sentiment Analysis",
    "Topics10": "",
    "Topics1": "AIW: Web-based opinion extraction and trend spotting",
    "Topics2": "NLPTM: Information Extraction",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: Web-based opinion extraction and trend spotting;NLPTM: Information Extraction"
  },
  {
    "Document Index (generated)": 118,
    "Number of Records": 1,
    "Abstract": "Game designs often center on the game mechanics - rules governing the logical evolution of the game. We seek to develop an intelligent system that generates computer games. As first steps towards this goal we present a composable and cross-domain representation for game mechanics that draws from AI planning action representations. We use a constraint solver to generate mechanics subject to design requirements on the form of those mechanics - what they do in the game. A planner takes a set of generated mechanics and tests whether those mechanics meet playability requirements - controlling how mechanics function in a game to affect player behavior. We demonstrate our system by modeling and generating mechanics in a role-playing game, platformer game, and combined role-playing-platformer game.",
    "Authors1": "Alex",
    "Authors2": "er Zook",
    "Authors3": "Mark Riedl",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Alex,er Zook , Mark Riedl",
    "Groups1": "Game Playing and Interactive Entertainment (GPIE)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Playing and Interactive Entertainment (GPIE)",
    "Keywords10": "",
    "Keywords1": "procedural content generation",
    "Keywords2": "game generation",
    "Keywords3": "game mechanics",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "procedural content generation;game generation;game mechanics",
    "Title": "Automatic Game Design via Mechanic Generation",
    "Topics10": "",
    "Topics1": "GPIE: AI in Game Design",
    "Topics2": "GPIE: Procedural Content Generation",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GPIE: AI in Game Design;GPIE: Procedural Content Generation"
  },
  {
    "Document Index (generated)": 119,
    "Number of Records": 1,
    "Abstract": "In this paper, we present an extension of the cascading Indian buffet process (CIBP) intended to learning arbitrary directed acyclic graph structures as opposed to the CIBP, which is limited to purely layered structures. The extended cascading Indian buffet process (eCIBP) essentially consists in adding an extra sampling step to the CIBP to generate connections between non-consecutive layers. In the context of graphical model structure learning, the proposed approach allows learning structures having an unbounded number of hidden random variables and automatically selecting the model complexity. We evaluated the extended process on multivariate density estimation and structure identification tasks by measuring the structure complexity and predictive performance. The results suggest the extension leads to extracting simpler graphs without scarifying predictive precision.",
    "Authors1": "Patrick Dallaire",
    "Authors2": "Philippe Giguère",
    "Authors3": "Brahim Chaib-Draa",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Patrick Dallaire, Philippe Giguère , Brahim Chaib-Draa",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "Structure learning",
    "Keywords2": "Bayesian Learning",
    "Keywords3": "Bayesian nonparametrics",
    "Keywords4": "Graphical models",
    "Keywords5": "Deep belief networks",
    "Keywords6": "Infinite directed acyclic graphs",
    "Keywords7": "MCMC inference",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Structure learning;Bayesian Learning;Bayesian nonparametrics;Graphical models;Deep belief networks;Infinite directed acyclic graphs;MCMC inference",
    "Title": "Learning the Structure of Probabilistic Graphical Models with an Extended Cascading Indian Buffet Process",
    "Topics10": "",
    "Topics1": "NMLA: Bayesian Learning",
    "Topics2": "NMLA: Data Mining and Knowledge Discovery",
    "Topics3": "NMLA: Graphical Model Learning",
    "Topics4": "RU: Bayesian Networks",
    "Topics5": "RU: Graphical Models (Other)",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Bayesian Learning;NMLA: Data Mining and Knowledge Discovery;NMLA: Graphical Model Learning;RU: Bayesian Networks;RU: Graphical Models (Other)"
  },
  {
    "Document Index (generated)": 120,
    "Number of Records": 1,
    "Abstract": "Various perceptual domains have underlying compositional semantics that are rarely captured in current models.  We suspect this is because directly learning the compositional structure has evaded these models.  Yet, the compositional structure of a given domain can be grounded in a separate domain thereby simplifying its learning.  To that end, we propose a new approach to modeling bimodal percepts that explicitly relates distinct projections across each modality and then jointly learns a bimodal sparse representation.  The resulting model enables compositionality across these distinct projections and hence can generalize to unobserved percepts spanned by this compositional basis.  For example, our model can be trained on \"red triangles\" and \"blue squares\"; yet, implicitly will also have learned \"red squares\" and \"blue triangles\".  The structure of the projections and hence the compositional basis is learned automatically for a given language model.  To test our model, we have acquired a new bimodal dataset comprising images and spoken utterances of colored shapes in a tabletop setup.  Our experiments demonstrate the benefits of explicitly leveraging compositionality in both quantitative and human evaluation studies.",
    "Authors1": "Suren Kumar",
    "Authors2": "Vikas Dhiman",
    "Authors3": "Jason J. Corso",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Suren Kumar, Vikas Dhiman , Jason J. Corso",
    "Groups1": "Cognitive Systems (CS)",
    "Groups2": "Novel Machine Learning Algorithms (NMLA)",
    "Groups3": "Vision (VIS)",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Cognitive Systems (CS);Novel Machine Learning Algorithms (NMLA);Vision (VIS)",
    "Keywords10": "",
    "Keywords1": "compositional model",
    "Keywords2": "bimodal sparse representation",
    "Keywords3": "vision and audio",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "compositional model;bimodal sparse representation;vision and audio",
    "Title": "Learning Compositional Sparse Models of Bimodal Percepts",
    "Topics10": "",
    "Topics1": "CS: Structural learning and knowledge capture",
    "Topics2": "NMLA: Dimension Reduction/Feature Selection",
    "Topics3": "VIS: Language and Vision",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "CS: Structural learning and knowledge capture;NMLA: Dimension Reduction/Feature Selection;VIS: Language and Vision"
  },
  {
    "Document Index (generated)": 121,
    "Number of Records": 1,
    "Abstract": "We introduce Dramatis, a computational model of suspense based on a reformulation of a psychological definition of the suspense phenomenon. In this reformulation, suspense is correlated with the audience’s ability to generate a plan for the protagonist to avoid an impending negative outcome. Dramatis measures the suspense level by generating such a plan and determining its perceived likelihood of success. We report on three evaluations of Dramatis, including a comparison of Dramatis output to the suspense reported by human readers, as well as ablative tests of Dramatis components. In these studies, we found that Dramatis output corresponded to the suspense ratings given by human readers for stories in three separate domains.",
    "Authors1": "Brian O'Neill",
    "Authors2": "Mark Riedl",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Brian O'Neill , Mark Riedl",
    "Groups1": "Applications (APP)",
    "Groups2": "Game Playing and Interactive Entertainment (GPIE)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Applications (APP);Game Playing and Interactive Entertainment (GPIE)",
    "Keywords10": "",
    "Keywords1": "computational creativity",
    "Keywords2": "psychological models",
    "Keywords3": "computational aesthetics",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "computational creativity;psychological models;computational aesthetics",
    "Title": "Dramatis: A Computational Model of Suspense",
    "Topics10": "",
    "Topics1": "APP: Art and Music",
    "Topics2": "GPIE: AI Storytelling",
    "Topics3": "GPIE: Computational Creativity and Generative Art",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "APP: Art and Music;GPIE: AI Storytelling;GPIE: Computational Creativity and Generative Art"
  },
  {
    "Document Index (generated)": 122,
    "Number of Records": 1,
    "Abstract": "We consider the problem of learning soft assignments of N items to K categories given two sources of information: an item-category similarity matrix, which encourages items to be assigned to categories they are similar to (and to not be assigned to categories they are dissimilar to), and an item-item similarity matrix, which encourages similar items to have similar assignments. We propose a simple quadratic programming model that captures this intuition. We give necessary conditions for its solution to be unique, define an out-of-sample mapping, and derive a simple, effective training algorithm based on the alternating direction method of multipliers. The model predicts reasonable assignments from even a few similarity values, and can be seen as a generalization of semisupervised learning. It is particularly useful when items naturally belong to multiple categories, as for example when annotating documents with keywords or pictures with tags, with partially tagged items, or when the categories have complex interrelations (e.g. hierarchical) that are unknown.",
    "Authors1": "Miguel Carreira-Perpinan",
    "Authors2": "Weiran Wang",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Miguel Carreira-Perpinan , Weiran Wang",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "semi-supervised learning",
    "Keywords2": "convex optimization",
    "Keywords3": "ADMM",
    "Keywords4": "soft assignment",
    "Keywords5": "Laplacian smoothing",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "semi-supervised learning;convex optimization;ADMM;soft assignment;Laplacian smoothing",
    "Title": "LASS: A Simple Assignment Model with Laplacian Smoothing",
    "Topics10": "",
    "Topics1": "HSO: Optimization",
    "Topics2": "NMLA: Semisupervised Learning",
    "Topics3": "RU: Uncertainty in AI (General/Other)",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "HSO: Optimization;NMLA: Semisupervised Learning;RU: Uncertainty in AI (General/Other)"
  },
  {
    "Document Index (generated)": 123,
    "Number of Records": 1,
    "Abstract": "Our research aims at building interactive robots and agent that can expand their knowledge by interacting with human users. In this paper, we focus on learning goal-oriented tasks from situated interactive instructions. Learning novel tasks is a challenging computational problem requiring the agent to acquire a variety of knowledge including goal definitions and hierarchical control information. We frame acquisition of hierarchical tasks as an explanation-based learning (EBL) problem and propose an interactive learning variant of EBL for a robotic agent. We show that our approach can exploit information in situated instructions along with the domain knowledge to demonstrate fast generalization on several tasks.The knowledge acquired transfers across structurally similar tasks. Finally, we show that our approach seamlessly combines agent-driven exploration with instructions for mixed-initiative learning.",
    "Authors1": "Shiwali Mohan",
    "Authors2": "John Laird",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Shiwali Mohan , John Laird",
    "Groups1": "Cognitive Systems (CS)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Cognitive Systems (CS)",
    "Keywords10": "",
    "Keywords1": "task learning",
    "Keywords2": "interactive learning",
    "Keywords3": "explanation-based learning",
    "Keywords4": "situated interactive instruction",
    "Keywords5": "learning for robots",
    "Keywords6": "learning from dialog",
    "Keywords7": "Soar",
    "Keywords8": "cognitive architecture",
    "Keywords9": "",
    "Keywords": "task learning;interactive learning;explanation-based learning;situated interactive instruction;learning for robots;learning from dialog;Soar;cognitive architecture",
    "Title": "Learning Goal-Oriented Hierarchical Tasks from Situated Interactive Instruction",
    "Topics10": "",
    "Topics1": "CM: Agent Architectures",
    "Topics2": "CM: Symbolic AI",
    "Topics3": "CS: Social cognition and interaction",
    "Topics4": "CS: Structural learning and knowledge capture",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "CM: Agent Architectures;CM: Symbolic AI;CS: Social cognition and interaction;CS: Structural learning and knowledge capture"
  },
  {
    "Document Index (generated)": 124,
    "Number of Records": 1,
    "Abstract": "Robust scheduling is essential to many autonomous systems and logistics tasks. Probabilistic formalisms quantify the risk of schedule failure, which is essential for mission critical applications. Probabilistic methods for solving temporal problems exist that attempt to minimize the probability of schedule failure. These methods are overly conservative, resulting in a loss in schedule utility. Chance constrained formalism address this problem by imposing bounds on risk, while maximizing utility subject to these risk bounds. \n\nIn this paper we present the probabilistic Simple Temporal Network (pSTN), a probabilistic formalism for representing temporal problems with bounded risk and a utility over event timing. We introduce a constrained optimisation algorithm for pSTNs that achieves compactness and efficiency through a problem encoding in terms of a parameterised STNU and its reformulation as a parameterised STN. We demonstrate through a car sharing application that our chance-constrained approach runs in the same time as the previous probabilistic approach, yields solutions with utility improvements of at least 5% over previous arts, while guaranteeing operation within the specified risk bound.",
    "Authors1": "Cheng Fang",
    "Authors2": "Peng Yu",
    "Authors3": "Brian Williams",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Cheng Fang, Peng Yu , Brian Williams",
    "Groups1": "Planning and Scheduling (PS)",
    "Groups2": "Reasoning under Uncertainty (RU)",
    "Groups3": "Search and Constraint Satisfaction (SCS)",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Planning and Scheduling (PS);Reasoning under Uncertainty (RU);Search and Constraint Satisfaction (SCS)",
    "Keywords10": "",
    "Keywords1": "scheduling",
    "Keywords2": "probabilistic",
    "Keywords3": "STNU",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "scheduling;probabilistic;STNU",
    "Title": "Chance-constrained Probabilistic Simple Temporal Problems",
    "Topics10": "",
    "Topics1": "PS: Probabilistic Planning",
    "Topics2": "PS: Scheduling",
    "Topics3": "PS: Temporal Planning",
    "Topics4": "SCS: Constraint Optimization",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "PS: Probabilistic Planning;PS: Scheduling;PS: Temporal Planning;SCS: Constraint Optimization"
  },
  {
    "Document Index (generated)": 125,
    "Number of Records": 1,
    "Abstract": "Combinatorial auctions are multiple-item auctions in which bidders may place bids on any package (subset) of goods. This additional expressibility produces benefits that have led to combinatorial auctions becoming extremely important both in practice and in theory. In the computer science community, research has focused primarily on computation and incentive compatibility. The latter concerns a specific form of bidder misrepresentation. However, with modern forms of bid submission, such as electronic bidding, new types of cheating become feasible. For combinatorial auctions, prominent amongst them is false-name bidding; that is, bidding under pseudonyms. The ubiquitous Vickrey-Clarke-Groves (VCG) mechanism is incentive compatible and produces optimal allocations, but it is not false-name-proof; bidders can increase their utility by submitting bids under multiple identifiers. Consequently, there has recently been much interest in the design and analysis of false-name-proof auction mechanisms. \n \nSuch false-name-proof mechanisms, however, can produce allocations with very low economic efficiency/social welfare. In contrast, we show that, provided the degree to which different goods are complementary is bounded (as is the case in many important, practical auctions), the VCG mechanism gives a constant efficiency guarantee. Such efficiency guarantees hold even at equilibria where the agents bid in a manner that is not individually rational. Thus, while an individual bidder may \npersonally benefit greatly from making false-name bids, this will have only a small detrimental effect on the objective of the auctioneer: maximizing economic efficiency. Thus, from the auctioneer's viewpoint the VCG mechanism remains preferable to false-name-proof mechanisms.",
    "Authors1": "Adrian Vetta",
    "Authors2": "Colleen Alkalay-Houlihan",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Adrian Vetta , Colleen Alkalay-Houlihan",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "Multiagent Systems (MAS)",
    "Groups3": "Reasoning under Uncertainty (RU)",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP);Multiagent Systems (MAS);Reasoning under Uncertainty (RU)",
    "Keywords10": "",
    "Keywords1": "- GTEP: Auctions and Market-Based Systems",
    "Keywords2": "- GTEP: Equilibrium",
    "Keywords3": "- MAS: E-Commerce",
    "Keywords4": "- MAS: Mechanism Design",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "- GTEP: Auctions and Market-Based Systems;- GTEP: Equilibrium;- MAS: E-Commerce;- MAS: Mechanism Design",
    "Title": "False-Name Bidding and Economic Efficiency in Combinatorial Auctions",
    "Topics10": "",
    "Topics1": "GTEP: Auctions and Market-Based Systems",
    "Topics2": "GTEP: Game Theory",
    "Topics3": "GTEP: Equilibrium",
    "Topics4": "GTEP: Imperfect Information",
    "Topics5": "MAS: E-Commerce",
    "Topics6": "MAS: Evaluation and Analysis (Multiagent Systems)",
    "Topics7": "RU: Decision/Utility Theory",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Auctions and Market-Based Systems;GTEP: Game Theory;GTEP: Equilibrium;GTEP: Imperfect Information;MAS: E-Commerce;MAS: Evaluation and Analysis (Multiagent Systems);RU: Decision/Utility Theory"
  },
  {
    "Document Index (generated)": 126,
    "Number of Records": 1,
    "Abstract": "Joint learning of similar tasks has been a popular trend in visual recognition and proven to be beneficial. The between-task similarity typically provides useful cues, such as feature sharing, for learning visual classifiers. By contrast, the competition relationship between visual recognition tasks (\\eg, content independent writer identification and handwriting recognition) remains largely under-explored.\nIntuitively, the between-task competition can be used to guide the feature selection process that plays a key role when learning a visual classifier.\nMotivated by this intuition, we propose a novel algorithm to exploit competition relationship for improving visual recognition tasks. More specifically, given a target task and its competing tasks, we jointly model them by a generalized additive regression model with  competition constraints. This constraint effectively discourages choosing of irrelevant features (weak learners) that are good for the \n tasks with competition relationships . The proposed algorithm is named \\emph{CompBoost} since it can be viewed extended from the RealAdaboost algorithm. We apply CompBoost to two visual recognition applications: (1) content-independent writer identification from handwriting scripts by exploiting competing tasks of handwriting recognition, and (2) actor-independent facial expression recognition by exploiting competing tasks of face recognition. In both experiments our approach demonstrates promising performance gains by exploiting the between-task competition relationships.",
    "Authors1": "Liang Du",
    "Authors2": "Haibin Ling",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Liang Du , Haibin Ling",
    "Groups1": "Applications (APP)",
    "Groups2": "Machine Learning Applications (MLA)",
    "Groups3": "Vision (VIS)",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Applications (APP);Machine Learning Applications (MLA);Vision (VIS)",
    "Keywords10": "",
    "Keywords1": "Competition relationships",
    "Keywords2": "jointly learning",
    "Keywords3": "visual recognition",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Competition relationships;jointly learning;visual recognition",
    "Title": "Exploiting Competition Relationship for Robust Visual Recognition",
    "Topics10": "",
    "Topics1": "APP: Other Applications",
    "Topics2": "MLA: Applications of Supervised Learning",
    "Topics3": "VIS: Categorization",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "APP: Other Applications;MLA: Applications of Supervised Learning;VIS: Categorization"
  },
  {
    "Document Index (generated)": 127,
    "Number of Records": 1,
    "Abstract": "Color refinement is a basic algorithmic routine for graph isomorphism\ntesting and has recently been used for computing graph kernels as well as for lifting belief propagation and linear programming.  \nSo far, color refinement has been treated as a combinatorial \nproblem. Instead, we treat it as a nonlinear continuous optimization problem and prove that\nit implements a conditional gradient optimizer that can be turned into \ngraph clustering approaches using hashing and truncated power iterations. This shows that color refinement \nis easy to understand in terms of (local) random walks, easy to implement (matrix-vector multiplications) and is readily parallelizable. \nWe support our theoretical results with experimental evidence on real-world graphs with millions of edges.",
    "Authors1": "Kristian Kersting",
    "Authors2": "Martin Mladenov",
    "Authors3": "Roman Garnet",
    "Authors4": "Martin Grohe",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Kristian Kersting, Martin Mladenov, Roman Garnet , Martin Grohe",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "Reasoning under Uncertainty (RU)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA);Reasoning under Uncertainty (RU)",
    "Keywords10": "",
    "Keywords1": "Lifted Belief Propagation",
    "Keywords2": "Color Refinement",
    "Keywords3": "Fractional Automorphism",
    "Keywords4": "Conditional Gradient",
    "Keywords5": "Power Iteration",
    "Keywords6": "Continuous Optimization",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Lifted Belief Propagation;Color Refinement;Fractional Automorphism;Conditional Gradient;Power Iteration;Continuous Optimization",
    "Title": "Power Iterated Color Refinement",
    "Topics10": "",
    "Topics1": "NMLA: Relational/Graph-Based Learning",
    "Topics2": "RU: Relational Probabilistic Models",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Relational/Graph-Based Learning;RU: Relational Probabilistic Models"
  },
  {
    "Document Index (generated)": 128,
    "Number of Records": 1,
    "Abstract": "In heterogeneous multi-robot teams, robustness and flexibility are increased by the diversity of the robots, each contributing different capabilities. Yet platform-\nindependence is desirable when planning actions for the various robots. This work develops a framework for task planning based on a platform-independent model\nof robots capabilities, building on a temporal planner. Generating new data objects during planning is essential to reflect data flow between actions in a robotic system. This requires online action instantiation, for which we present a novel approach. Required concurrency of actions is an essential part of robotic systems and therefore is incorporated in the framework. We evaluate the planner on benchmark domains and present results on an example object transportation task in simulation.",
    "Authors1": "Jennifer Buehler",
    "Authors2": "Maurice Pagnucco",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Jennifer Buehler , Maurice Pagnucco",
    "Groups1": "Planning and Scheduling (PS)",
    "Groups2": "Robotics (ROB)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Planning and Scheduling (PS);Robotics (ROB)",
    "Keywords10": "",
    "Keywords1": "Robot Task Planning",
    "Keywords2": "Temporal Planning",
    "Keywords3": "Heterogeneous Multi Robot Systems",
    "Keywords4": "Robot capabilities",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Robot Task Planning;Temporal Planning;Heterogeneous Multi Robot Systems;Robot capabilities",
    "Title": "A Framework for Task Planning in Heterogeneous Multi Robot Systems Based on Robot Capabilities",
    "Topics10": "",
    "Topics1": "PS: Temporal Planning",
    "Topics2": "PS: Planning (General/Other)",
    "Topics3": "ROB: Multi-Robot Systems",
    "Topics4": "ROB: Robotics (General/Other)",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "PS: Temporal Planning;PS: Planning (General/Other);ROB: Multi-Robot Systems;ROB: Robotics (General/Other)"
  },
  {
    "Document Index (generated)": 129,
    "Number of Records": 1,
    "Abstract": "This paper studies the problems associated with active learning, in which multiple users with varying levels of expertise are available for labeling data. Annotations collected from different users may be noisy and unreliable, and the quality of labeled data needs to be maintained for data mining tasks. Previous solutions have included estimating individual user reliability based on existing knowledge in each task, but for this to be effective each task requires a large quantity of labeled data to provide accurate estimates. In practice, annotation budgets for a given target task are limited, so each example can be presented to only a few users, each of whom can only label a few examples. To overcome data scarcity we propose a new probabilistic model that transfers knowledge from abundant unlabeled data in auxiliary domains to help estimate labelers' expertise. Based on this model we present a novel active learning algorithm that: a) simultaneously selects the most informative example and b) queries its label from the labeler with the best expertise. Experiments on both text and image datasets demonstrate that our proposed method outperforms other state-of-the-art active learning methods.",
    "Authors1": "Meng Fang",
    "Authors2": "Jie Yin",
    "Authors3": "Dacheng Tao",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Meng Fang, Jie Yin , Dacheng Tao",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "Active learning",
    "Keywords2": "Multiple labelers",
    "Keywords3": "Knowledge transfer",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Active learning;Multiple labelers;Knowledge transfer",
    "Title": "Active Learning Using Knowledge Transfer from Unlabeled Data",
    "Topics10": "",
    "Topics1": "NMLA: Active Learning",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Active Learning"
  },
  {
    "Document Index (generated)": 130,
    "Number of Records": 1,
    "Abstract": "We propose a combination of AI techniques to improve software testing. When a test fails, a model-based diagnosis (MBD) algorithm is used to propose a set of possible explanations. We call these explanations \"diagnoses\". Then, a planning algorithm is used to suggest further tests to identify the correct diagnosis. A tester preforms these tests and reports their outcome back to the MBD algorithm, which uses this information to prune incorrect diagnoses. This iterative process continues until the correct diagnosis is returned. We call this testing paradigm Test, Diagnose and Plan (TDP). Several test planning algorithms are proposed to minimize the number of TDP iterations, and consequently the number of tests required until the correct diagnosis is found. Experimental results show that benefits of using an MDP-based planning algorithms over greedy test planning.",
    "Authors1": "Tom Zamir",
    "Authors2": "Roni Stern",
    "Authors3": "Meir Kalech",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Tom Zamir, Roni Stern , Meir Kalech",
    "Groups1": "Applications (APP)",
    "Groups2": "Knowledge Representation and Reasoning (KRR)",
    "Groups3": "Planning and Scheduling (PS)",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Applications (APP);Knowledge Representation and Reasoning (KRR);Planning and Scheduling (PS)",
    "Keywords10": "",
    "Keywords1": "Model based diagnosis",
    "Keywords2": "Software engineering",
    "Keywords3": "Planning",
    "Keywords4": "Testing",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Model based diagnosis;Software engineering;Planning;Testing",
    "Title": "Using Model-Based Diagnosis to Improve Software Testing",
    "Topics10": "",
    "Topics1": "APP: Other Applications",
    "Topics2": "KRR: Automated Reasoning and Theorem Proving",
    "Topics3": "KRR: Diagnosis and Abductive Reasoning",
    "Topics4": "PS: Model-Based Reasoning",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "APP: Other Applications;KRR: Automated Reasoning and Theorem Proving;KRR: Diagnosis and Abductive Reasoning;PS: Model-Based Reasoning"
  },
  {
    "Document Index (generated)": 131,
    "Number of Records": 1,
    "Abstract": "In machine learning and statistics, probabilistic inference involving multimodal distributions is quite difficult. This is especially true in high dimensional problems, where most existing algorithms cannot easily move from one mode to another. To address this issue, we propose a novel Bayesian inference approach based on Markov Chain Monte Carlo. Our method can effectively sample from multimodal distributions, especially when the dimension is high and the modes are isolated. To this end, it exploits and modifies the Riemannian geometric properties of the target distribution to create wormholes connecting modes in order to facilitate moving between them. Further, our proposed method uses the regeneration technique in order to adapt the algorithm by identifying new modes and updating the network of wormholes without affecting the stationary distribution. To find new modes, as opposed to rediscovering those previously identified, we employ a novel mode searching algorithm that explores a residual energy function obtained by subtracting an approximate Gaussian mixture density (based on previously discovered modes) from the target density function.",
    "Authors1": "Shiwei Lan",
    "Authors2": "Jeffrey Streets",
    "Authors3": "Babak Shahbaba",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Shiwei Lan, Jeffrey Streets , Babak Shahbaba",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "Bayesian Inference",
    "Keywords2": "Computational Statistics",
    "Keywords3": "Markov Chain Monte Carlo",
    "Keywords4": "Multimodal Distributions",
    "Keywords5": "Geometric Methods",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Bayesian Inference;Computational Statistics;Markov Chain Monte Carlo;Multimodal Distributions;Geometric Methods",
    "Title": "Wormhole Hamiltonian Monte Carlo",
    "Topics10": "",
    "Topics1": "NMLA: Bayesian Learning",
    "Topics2": "NMLA: Machine Learning (General/other)",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Bayesian Learning;NMLA: Machine Learning (General/other)"
  },
  {
    "Document Index (generated)": 132,
    "Number of Records": 1,
    "Abstract": "We present an enhanced hybrid approach to OWL query answering that combines an RDF triple-store with a fully-fledged OWL reasoner in order to provide scalable ``pay as you go'' performance. The enhancements presented here include an extension to deal with arbitrary OWL ontologies, and several optimisations that significantly improve scalability. We have implemented these techniques in a prototype system, a preliminary evaluation of which has produced very encouraging results.",
    "Authors1": "Yujiao Zhou",
    "Authors2": "Yavor Nenov",
    "Authors3": "Bernardo Cuenca Grau",
    "Authors4": "Ian Horrocks",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Yujiao Zhou, Yavor Nenov, Bernardo Cuenca Grau , Ian Horrocks",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "Knowledge Representation and Reasoning (KRR)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW);Knowledge Representation and Reasoning (KRR)",
    "Keywords10": "",
    "Keywords1": "OWL",
    "Keywords2": "ontologies",
    "Keywords3": "triple store",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "OWL;ontologies;triple store",
    "Title": "Pay-as-you-go OWL Query Answering Using a Triple Store",
    "Topics10": "",
    "Topics1": "AIW: Searching, querying, visualizing, and interpreting the semantic web",
    "Topics2": "KRR: Ontologies",
    "Topics3": "KRR: Automated Reasoning and Theorem Proving",
    "Topics4": "KRR: Description Logics",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: Searching, querying, visualizing, and interpreting the semantic web;KRR: Ontologies;KRR: Automated Reasoning and Theorem Proving;KRR: Description Logics"
  },
  {
    "Document Index (generated)": 133,
    "Number of Records": 1,
    "Abstract": "Imitation Learning (IL) is a popular approach for teaching behavior policies to agents by demonstrating the desired target policy. While the approach has lead to many successes, IL often requires a large set of demonstrations to achieve robust learning, which can be expensive for the teacher. In this paper, we consider a novel approach to improve the learning efficiency of IL by providing a shaping reward function in addition to the usual demonstrations. Shaping rewards are numeric functions of states (and possibly actions) that are generally easily specified and capture general principles of desired behavior, without necessarily completely specifying the behavior. Shaping rewards have been used extensively in reinforcement learning, but have been seldom considered for IL, though they are often easy to specify. Our main contribution is to propose an IL approach that learns from both shaping rewards and demonstrations. We demonstrate the effectiveness of the approach across several IL problems, even when the shaping reward is not fully consistent with the demonstrations.",
    "Authors1": "Kshitij Judah",
    "Authors2": "Alan Fern",
    "Authors3": "Prasad Tadepalli",
    "Authors4": "Robby Goetschalckx",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Kshitij Judah, Alan Fern, Prasad Tadepalli , Robby Goetschalckx",
    "Groups1": "Reasoning under Uncertainty (RU)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Reasoning under Uncertainty (RU)",
    "Keywords10": "",
    "Keywords1": "Imitation Learning",
    "Keywords2": "Reinforcement Learning",
    "Keywords3": "Reward Shaping",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Imitation Learning;Reinforcement Learning;Reward Shaping",
    "Title": "Imitation Learning with Demonstrations and Shaping Rewards",
    "Topics10": "",
    "Topics1": "RU: Sequential Decision Making",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "RU: Sequential Decision Making"
  },
  {
    "Document Index (generated)": 134,
    "Number of Records": 1,
    "Abstract": "Thompson Sampling (TS) has  surged a lot of interest due to its good\nempirical\nperformance, in particular in the computational advertising. Though successful,\nthe tools for its performance analysis appeared only recently.  In this paper,\nwe describe and analyze SpectralTS for a bandit problem, where\nthe payoffs of the choices are smooth given an underlying graph. In\nthis\nsetting, each choice is a node of a graph and the expected payoffs of the\nneighboring nodes are assumed to be similar.  Although the setting has\napplication both in recommender systems and advertising, the traditional\nalgorithms would scale poorly with the number of choices. For that purpose we\nconsider an effective dimension $d$, which is small in real-world graphs.\nBuilding on prior work, we deliver the analysis showing that the regret of\nSpectralTS scales with $d\\sqrt{T \\ln N}$, where $T$ is the time\nhorizon and $N$ is the number of choices. Since a $d\\sqrt{T \\ln N}$ regret is\ncomparable to the known results, SpectralTS offers a computationally more\nefficient alternative. We also show that our algorithm is competitive on both\nsynthetic and real-world data.",
    "Authors1": "Tomáš Kocák",
    "Authors2": "Michal Valko",
    "Authors3": "Remi Munos",
    "Authors4": "Shipra Agrawal",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Tomáš Kocák, Michal Valko, Remi Munos , Shipra Agrawal",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "Reasoning under Uncertainty (RU)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA);Reasoning under Uncertainty (RU)",
    "Keywords10": "",
    "Keywords1": "Spectral bandits",
    "Keywords2": "Thompson Sampling",
    "Keywords3": "Smooth functions on graphs",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Spectral bandits;Thompson Sampling;Smooth functions on graphs",
    "Title": "Spectral Thompson Sampling",
    "Topics10": "",
    "Topics1": "NMLA: Online Learning",
    "Topics2": "NMLA: Recommender Systems",
    "Topics3": "RU: Sequential Decision Making",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Online Learning;NMLA: Recommender Systems;RU: Sequential Decision Making"
  },
  {
    "Document Index (generated)": 135,
    "Number of Records": 1,
    "Abstract": "We study the problem where a task (or multiple unrelated tasks) must be executed, there are multiple\nmachines/agents that can potentially perform the task, and our\nobjective is to minimize the expected sum of the agents' processing\ntimes.  Each agent does not know exactly how long it will take him to\nfinish the task; he only knows the distribution from which this time\nis drawn.  These times are independent across agents and the\ndistributions fulfill the monotone hazard rate condition.  Agents are\nselfish and will lie about their distributions if this increases their\nexpected utility.\n\nWe study different variations of the Vickrey mechanism that take as input the agents' reported distributions and the players' realized running times and that output a schedule that minimizes the expected sum of processing times, as well as payments that make it an ex-post equilibrium for the agents to both truthfully report their\ndistributions and exert full effort to complete the task. We devise the ChPE mechanism, which is uniquely tailored to our problem, and has many desirable properties including: not rewarding agents that fail to finish the task and having non-negative payments.",
    "Authors1": "Vincent Conitzer",
    "Authors2": "Angelina Vidali",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Vincent Conitzer , Angelina Vidali",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "Multiagent Systems (MAS)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP);Multiagent Systems (MAS)",
    "Keywords10": "",
    "Keywords1": "mechanism design",
    "Keywords2": "scheduling mechanisms",
    "Keywords3": "game theory",
    "Keywords4": "uncertainity",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "mechanism design;scheduling mechanisms;game theory;uncertainity",
    "Title": "Mechanism Design for Scheduling with Uncertain Execution Time.",
    "Topics10": "",
    "Topics1": "GTEP: Auctions and Market-Based Systems",
    "Topics2": "GTEP: Game Theory",
    "Topics3": "MAS: Mechanism Design",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Auctions and Market-Based Systems;GTEP: Game Theory;MAS: Mechanism Design"
  },
  {
    "Document Index (generated)": 136,
    "Number of Records": 1,
    "Abstract": "We consider voting situations in which some candidates may turn out to be unavailable. When determining availability is costly (e.g., in terms of money, time, or computation), voting prior to determining candidate availability and testing the winner's availability *after* the vote may be beneficial.  However, since few voting rules are robust to candidate deletion, winner determination requires a number of such availability tests. We outline a model for analyzing such problems, defining *robust winners* relative to potential candidate unavailability. We assess the complexity of computing robust winners for several voting rules.  Assuming a distribution over availability, and costs for availability tests/queries, we describe algorithms for *optimal query policies*, which minimize the expected cost of determining true winners.",
    "Authors1": "Craig Boutilier",
    "Authors2": "Jérôme Lang",
    "Authors3": "Joel Oren",
    "Authors4": "Hector Palacios",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Craig Boutilier, Jérôme Lang, Joel Oren , Hector Palacios",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "Multiagent Systems (MAS)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP);Multiagent Systems (MAS)",
    "Keywords10": "",
    "Keywords1": "voting",
    "Keywords2": "candidate availability",
    "Keywords3": "query policies",
    "Keywords4": "robust winner determination",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "voting;candidate availability;query policies;robust winner determination",
    "Title": "Robust Winners and Winner Determination Policies under Candidate Uncertainty",
    "Topics10": "",
    "Topics1": "APP: Computational Social Science",
    "Topics2": "GTEP: Social Choice / Voting",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "APP: Computational Social Science;GTEP: Social Choice / Voting"
  },
  {
    "Document Index (generated)": 137,
    "Number of Records": 1,
    "Abstract": "Maintaining and cultivating student engagement is a critical component of education. In various teaching settings, communication via online forums, electronic quizzes, and interaction with multimedia can include valuable information for assessing and understanding student engagement. Massive open online courses (MOOCs) measure large-scale data of this nature and provide the opportunity for data-driven study. Characterizing student engagement as a course progresses helps identify student learning patterns and can aid in minimizing dropout rates, initiating instructor intervention. In this paper, we construct a probabilistic model connecting student behavior and class completion, formulating student engagement types as latent variables. We show that our model accurately identifies course success indicators, which can be used by instructors to initiate interventions and assist students.",
    "Authors1": "Arti Ramesh",
    "Authors2": "Dan Goldwasser",
    "Authors3": "Bert Huang",
    "Authors4": "Hal Daume Iii",
    "Authors5": "Lise Getoor",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Arti Ramesh, Dan Goldwasser, Bert Huang, Hal Daume Iii , Lise Getoor",
    "Groups1": "Applications (APP)",
    "Groups2": "Machine Learning Applications (MLA)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Applications (APP);Machine Learning Applications (MLA)",
    "Keywords10": "",
    "Keywords1": "probabilistic modeling",
    "Keywords2": "structured prediction",
    "Keywords3": "data-driven methods in education",
    "Keywords4": "MOOC",
    "Keywords5": "online education",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "probabilistic modeling;structured prediction;data-driven methods in education;MOOC;online education",
    "Title": "Learning Latent Engagement Patterns of Students in Online Courses",
    "Topics10": "",
    "Topics1": "APP: Computer-Aided Education",
    "Topics2": "HAI: Understanding People, Theories, Concepts and Methods",
    "Topics3": "MLA: Machine Learning Applications (General/other)",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "APP: Computer-Aided Education;HAI: Understanding People, Theories, Concepts and Methods;MLA: Machine Learning Applications (General/other)"
  },
  {
    "Document Index (generated)": 138,
    "Number of Records": 1,
    "Abstract": "In this paper we propose a novel method for image semantic segmentation\nusing multiple graphs. The\nmulti-view affinity graph is constructed by leveraging the consistency between semantic space and multiple visual spaces.\nWith\nblock-diagonal constraints, we enforce the affinity matrix to be sparse such that the pairwise\npotential for  dissimilar superpixels is close to zero. By a divide-and-conquer strategy, the optimization for learning affinity matrix is  decomposed into several subproblems that can be solved in parallel. Using the $neighborhood$ $relationship$ between superpixels and the $consistency$ between\naffinity matrix  and label-confidence matrix, we infer the semantic label for each superpixel of unlabeled images by  minimizing an objective whose closed form solution can be easily obtained.\n Experimental results on two real-world\nimage datasets demonstrate the effectiveness of our method.",
    "Authors1": "Ke Zhang",
    "Authors2": "Wei Zhang",
    "Authors3": "Sheng Zeng",
    "Authors4": "Xiangyang Xue",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Ke Zhang, Wei Zhang, Sheng Zeng , Xiangyang Xue",
    "Groups1": "Machine Learning Applications (MLA)",
    "Groups2": "Novel Machine Learning Algorithms (NMLA)",
    "Groups3": "Vision (VIS)",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Machine Learning Applications (MLA);Novel Machine Learning Algorithms (NMLA);Vision (VIS)",
    "Keywords10": "",
    "Keywords1": "Image Semantic Segmentation",
    "Keywords2": "Block-Diagonal Constraints",
    "Keywords3": "MultiView Affinity Graph",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Image Semantic Segmentation;Block-Diagonal Constraints;MultiView Affinity Graph",
    "Title": "Semantic Segmentation Using Multiple Graphs with Block-Diagonal Constraints",
    "Topics10": "",
    "Topics1": "MLA: Applications of Supervised Learning",
    "Topics2": "NMLA: Classification",
    "Topics3": "NMLA: Relational/Graph-Based Learning",
    "Topics4": "VIS: Categorization",
    "Topics5": "VIS: Object Detection",
    "Topics6": "VIS: Object Recognition",
    "Topics7": "VIS: Statistical Methods and Learning",
    "Topics8": "",
    "Topics9": "",
    "Topics": "MLA: Applications of Supervised Learning;NMLA: Classification;NMLA: Relational/Graph-Based Learning;VIS: Categorization;VIS: Object Detection;VIS: Object Recognition;VIS: Statistical Methods and Learning"
  },
  {
    "Document Index (generated)": 139,
    "Number of Records": 1,
    "Abstract": "There are two complementary ways to evaluate planning algorithms: performance on benchmark problems derived from real applications and analysis of performance on parametrized families of problems with known properties. Prior to this work, few means of generating parametrized families of hard planning problems were known. We generate hard planning problems from the solvable/unsolvable phase transition region of well-studied NP-complete problems that map naturally to navigation and scheduling, aspects common to many planning domains. Our results confirm exponential scaling of hardness with problem size, even at very small problem sizes. We observe significant differences between state-of-the-art planners on these problem families, enabling us to gain insight into the relative strengths and weaknesses of these planners. These families provide complementary test sets exhibiting properties not found in existing benchmarks.",
    "Authors1": "Eleanor Rieffel",
    "Authors2": "Davide Venturelli",
    "Authors3": "Minh Do",
    "Authors4": "Itay Hen",
    "Authors5": "Jeremy Frank",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Eleanor Rieffel, Davide Venturelli, Minh Do, Itay Hen , Jeremy Frank",
    "Groups1": "Planning and Scheduling (PS)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Planning and Scheduling (PS)",
    "Keywords10": "",
    "Keywords1": "parametrized families",
    "Keywords2": "scaling analysis",
    "Keywords3": "phase transition",
    "Keywords4": "benchmark planning problems",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "parametrized families;scaling analysis;phase transition;benchmark planning problems",
    "Title": "Parametrized Families of Hard Planning Problems from Phase Transitions",
    "Topics10": "",
    "Topics1": "PS: Scheduling",
    "Topics2": "PS: Planning (General/Other)",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "PS: Scheduling;PS: Planning (General/Other)"
  },
  {
    "Document Index (generated)": 140,
    "Number of Records": 1,
    "Abstract": "In this paper, we systematically study the problem of dataless hierarchical text classification. Unlike standard text classification schemes that rely on supervised training, dataless classification depends on understanding the labels of the sought after categories and requires no labeled data. Given a collection of text documents and a set of labels, we show that understanding the labels can be used to categorize the documents to the corresponding categories. This is done by embedding both labels and documents in a semantic space that allows one to compute meaningful semantic similarity between a document and a potential label. We show that this scheme can be used to support accurate multiclass classification without any supervision. We study several semantic representations and show how to improve the classification using bootstrapping methods.  Our results show that bootstrapped dataless classification is competitive with supervised classification with thousands of labeled examples.",
    "Authors1": "Yangqiu Song",
    "Authors2": "Dan Roth",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Yangqiu Song , Dan Roth",
    "Groups1": "NLP and Machine Learning (NLPML)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "NLP and Machine Learning (NLPML)",
    "Keywords10": "",
    "Keywords1": "Hierarchical Text Classification",
    "Keywords2": "Dataless Text Classification",
    "Keywords3": "Semantic Representation",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Hierarchical Text Classification;Dataless Text Classification;Semantic Representation",
    "Title": "On Dataless Hierarchical Text Classification",
    "Topics10": "",
    "Topics1": "NLPML: Text Classification",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NLPML: Text Classification"
  },
  {
    "Document Index (generated)": 141,
    "Number of Records": 1,
    "Abstract": "We report a novel approach to addressing the Raven’s Progressive Matrices (RPM) tests, one based upon purely visual representations. Our technique introduces the calculation of confidence in an answer and the automatic adjustment of level of resolution if that confidence is insufficient. We first describe the nature of the visual analogies found on the RPM.  We then exhibit our algorithm and work through a detailed example.  Finally, we present the performance of our algorithm on the four major variants of the RPM tests, illustrating the impact of confidence.  This is the first such account of any computational model against the entirety of the Raven’s.",
    "Authors1": "Keith McGreggor",
    "Authors2": "Ashok Goel",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Keith McGreggor , Ashok Goel",
    "Groups1": "Knowledge Representation and Reasoning (KRR)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Knowledge Representation and Reasoning (KRR)",
    "Keywords10": "",
    "Keywords1": "Visual Representations",
    "Keywords2": "Reasoning",
    "Keywords3": "Analogy",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Visual Representations;Reasoning;Analogy",
    "Title": "Confident Reasoning on Raven’s Progressive Matrices Tests",
    "Topics10": "",
    "Topics1": "KRR: Geometric, Spatial, and Temporal Reasoning",
    "Topics2": "KRR: Knowledge Representation (General/Other)",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "KRR: Geometric, Spatial, and Temporal Reasoning;KRR: Knowledge Representation (General/Other)"
  },
  {
    "Document Index (generated)": 142,
    "Number of Records": 1,
    "Abstract": "Dimensionality reduction (DR) is often used as a preprocessing step in classification, but usually one first fixes the DR mapping, possibly using label information, and then learns a classifier (a filter approach). Best performance would be obtained by optimizing the classification error jointly over DR mapping and classifier (a wrapper approach), but this is a difficult nonconvex problem, particularly with nonlinear DR. Using the method of auxiliary coordinates, we give a simple, efficient algorithm to train a combination of nonlinear DR and a classifier, and apply it to a RBF mapping with a linear SVM. This alternates steps where we train the RBF mapping and a linear SVM as usual regression and classification, respectively, with a closed-form step that coordinates both. The resulting nonlinear low-dimensional classifier achieves classification errors competitive with the state-of-the-art but is fast at training and testing, and allows the user to trade off runtime for classification accuracy easily. We then study the role of nonlinear DR in linear classification, and the interplay between the DR mapping, the number of latent dimensions and the number of classes. When trained jointly, the DR mapping takes an extreme role in eliminating variation: it tends to collapse classes in latent space, erasing all manifold structure, and lay out class centroids so they are linearly separable with maximum margin.",
    "Authors1": "Weiran Wang",
    "Authors2": "Miguel Carreira-Perpinan",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Weiran Wang , Miguel Carreira-Perpinan",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "dimensionality reduction",
    "Keywords2": "nonlinear classification",
    "Keywords3": "optimization",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "dimensionality reduction;nonlinear classification;optimization",
    "Title": "The Role of Dimensionality Reduction in Linear Classification",
    "Topics10": "",
    "Topics1": "HSO: Optimization",
    "Topics2": "NMLA: Classification",
    "Topics3": "NMLA: Dimension Reduction/Feature Selection",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "HSO: Optimization;NMLA: Classification;NMLA: Dimension Reduction/Feature Selection"
  },
  {
    "Document Index (generated)": 143,
    "Number of Records": 1,
    "Abstract": "We present a ping-pong-playing robot that learns to improve its swings with human advice.  Our method learns a reward function over the joint space of task and policy parameters.  This allows the robot to explore policy space more intelligently by leveraging active learning techniques to explore the reward surface\nin a way that trades off exploration vs. exploitation to maximize the total cumulative reward over time.  Multimodal stochastic polices can also easily be learned with this approach when the reward function is multimodal in the policy parameters.  We extend the recently-developed Gaussian Process Bandit\nOptimization framework to include advice from human domain experts.",
    "Authors1": "Jared Glover",
    "Authors2": "Charlotte Zhu",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Jared Glover , Charlotte Zhu",
    "Groups1": "Heuristic Search and Optimization (HSO)",
    "Groups2": "Humans and AI (HAI)",
    "Groups3": "Machine Learning Applications (MLA)",
    "Groups4": "Reasoning under Uncertainty (RU)",
    "Groups5": "Robotics (ROB)",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Heuristic Search and Optimization (HSO);Humans and AI (HAI);Machine Learning Applications (MLA);Reasoning under Uncertainty (RU);Robotics (ROB)",
    "Keywords10": "",
    "Keywords1": "robot table tennis",
    "Keywords2": "gaussian process bandits",
    "Keywords3": "human advice",
    "Keywords4": "coaching robots",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "robot table tennis;gaussian process bandits;human advice;coaching robots",
    "Title": "Generalizing Policy Advice with Gaussian Process Bandits for Dynamic Skill Improvement",
    "Topics10": "",
    "Topics1": "HSO: Heuristic Search",
    "Topics2": "HAI: Human-Computer Interaction",
    "Topics3": "MLA: Machine Learning Applications (General/other)",
    "Topics4": "RU: Decision/Utility Theory",
    "Topics5": "RU: Sequential Decision Making",
    "Topics6": "ROB: Robotics (General/Other)",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "HSO: Heuristic Search;HAI: Human-Computer Interaction;MLA: Machine Learning Applications (General/other);RU: Decision/Utility Theory;RU: Sequential Decision Making;ROB: Robotics (General/Other)"
  },
  {
    "Document Index (generated)": 144,
    "Number of Records": 1,
    "Abstract": "Nowadays, most recommender systems (RSs) mainly aim to suggest appropriate items for individuals. Due to the social nature of human beings, group activities have become an integral part of our daily life, thus motivating the study on group RS (GRS). However, most existing methods used by GRS make recommendations through aggregating individual ratings or individual predictive results rather than considering the collective features that govern user choices made within a group. As a result, such methods are heavily sensitive to data, hence they often fail to learn group preferences when the data are slightly inconsistent with predefined aggregation assumptions. To this end, we devise a novel GRS approach which accommodates both individual choices and group decisions in a joint model. More specifically, we propose a deep-architecture model built with a collective deep belief network and dual-wing restricted Boltzmann machine. With such a deep model, we can use high-level features, which are induced from lower-level features, to represent group preference so as to relieve the vulnerability of data. Finally, the experiments conducted on a real-world dataset prove the superiority of our deep model over other state-of-the-art methods.",
    "Authors1": "Liang Hu",
    "Authors2": "Jian Cao",
    "Authors3": "Gu",
    "Authors4": "ong Xu",
    "Authors5": "Longbing Cao",
    "Authors6": "Zhiping Gu",
    "Authors7": "Wei Cao",
    "Authors": "Liang Hu, Jian Cao, Gu,ong Xu, Longbing Cao, Zhiping Gu , Wei Cao",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "Novel Machine Learning Algorithms (NMLA)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW);Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "Group Recommender System",
    "Keywords2": "Deep Learning",
    "Keywords3": "Feature Learning",
    "Keywords4": "Deep Belief Network",
    "Keywords5": "Restricted Boltzmann Machine",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Group Recommender System;Deep Learning;Feature Learning;Deep Belief Network;Restricted Boltzmann Machine",
    "Title": "Deep Modeling of Group Preferences for Group-based Recommendation",
    "Topics10": "",
    "Topics1": "AIW: Web-based recommendation systems",
    "Topics2": "NMLA: Preferences/Ranking Learning",
    "Topics3": "NMLA: Recommender Systems",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: Web-based recommendation systems;NMLA: Preferences/Ranking Learning;NMLA: Recommender Systems"
  },
  {
    "Document Index (generated)": 145,
    "Number of Records": 1,
    "Abstract": "Supervised metric learning plays a substantial role in statistical classification. Conventional metric learning algorithms have limited utility when the training data and the testing data are drawn from related but different domains (i.e., source domain and target domain). Although this issue has got some progress in feature-based transfer learning, most of the work in this area suffers from non-trivial optimization and pays little attention to preserving the discriminating information. In this paper, we propose a novel metric learning algorithm to transfer knowledge from the source domain to the target domain in an information-theoretic setting, where a shared Mahalanobis distance across two domains is learnt by combining  three goals together: 1) reducing the distribution difference between different domains; 2) preserving the geometry of target domain data; 3) aligning the geometry of source domain data with its label information. Based on this combination, the learnt Mahalanobis distance   effectively transfers the discriminating power and propagates  standard classifiers  across two domains. More importantly, our proposed method has  closed-form solution and can be efficiently optimized. Experiments on two real-world applications (i.e., face recognition and text classification) demonstrate the effectiveness and efficiency of our proposed method.",
    "Authors1": "Wei Wang",
    "Authors2": "",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Wei Wang",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "Mahalanobis distance",
    "Keywords2": "metric learning",
    "Keywords3": "transfer learning",
    "Keywords4": "relative entropy",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Mahalanobis distance;metric learning;transfer learning;relative entropy",
    "Title": "Cross-Domain Metric Learning Based on Information Theory",
    "Topics10": "",
    "Topics1": "NMLA: Transfer, Adaptation, Multitask Learning",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Transfer, Adaptation, Multitask Learning"
  },
  {
    "Document Index (generated)": 146,
    "Number of Records": 1,
    "Abstract": "Spatial scan statistics is used for discovery of spatial regions with significantly higher scores according to some density measure. In disease surveillance, spatial scan is a standard tool to detect spatial regions whose population has significantly higher disease risk than the overall population. In this important application, called the disease mapping, current residence is typically used to define the location of individuals from the population. Considering the mobility of humans at various temporal and spatial scales, using only information about the current residence can be insufficient because it ignores a multitude of exposures that occur away from home or which had occurred at previous residences. In this paper, we propose a novel spatial scan statistic that allows disease mapping in a mobile population. We also propose a computationally efficient disease mapping algorithm that uses the proposed statistic to find the significant high-risk spatial regions. The experimental results demonstrate that the proposed algorithm is superior to the traditional disease mapping algorithms in discovering high-risk regions in mobile populations. Moreover, the algorithm is applicable on large populations and over dense spatial grids.",
    "Authors1": "Liang Lan",
    "Authors2": "Vuk Malbasa",
    "Authors3": "Slobodan Vucetic",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Liang Lan, Vuk Malbasa , Slobodan Vucetic",
    "Groups1": "Applications (APP)",
    "Groups2": "Computational Sustainability and AI (CSAI)",
    "Groups3": "Machine Learning Applications (MLA)",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Applications (APP);Computational Sustainability and AI (CSAI);Machine Learning Applications (MLA)",
    "Keywords10": "",
    "Keywords1": "disease mapping",
    "Keywords2": "spatial scan",
    "Keywords3": "mobile data",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "disease mapping;spatial scan;mobile data",
    "Title": "Spatial Scan for Disease Mapping on a Mobile Population",
    "Topics10": "",
    "Topics1": "APP: AI and Natural Sciences",
    "Topics2": "CSAI: Modeling and prediction of dynamic and spatiotemporal phenomena and systems",
    "Topics3": "CSAI: Control and optimization of dynamic and spatiotemporal systems",
    "Topics4": "MLA: Machine Learning Applications (General/other)",
    "Topics5": "NMLA: Machine Learning (General/other)",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "APP: AI and Natural Sciences;CSAI: Modeling and prediction of dynamic and spatiotemporal phenomena and systems;CSAI: Control and optimization of dynamic and spatiotemporal systems;MLA: Machine Learning Applications (General/other);NMLA: Machine Learning (General/other)"
  },
  {
    "Document Index (generated)": 147,
    "Number of Records": 1,
    "Abstract": "Search with Subgoal Graphs (Uras, Koenig, and Hernandez 2013) was a non-dominated optimal path-planning algorithm in the Grid-Based Path Planning Competitions 2012 and 2013. During a preprocessing phase, it computes a Simple Subgoal Graph, which is analogous to a visibility graph for continuous terrain, and then partitions the subgoals into global and local subgoals to obtain a Two-Level Subgoal Graph. During the path-planning phase, it performs an A* search that ignores local subgoals that are not relevant to the search, which significantly reduces the size of the graph being searched.\n\nIn this paper, we generalize this partitioning process to any undirected graph and show that it can be recursively applied to generate more than two levels, which reduces the size of the graph being searched even further. We distinguish between basic partitioning, which only partitions the vertices into different levels, and advanced partitioning, which can also add new edges. We show that the construction of Simple Subgoal Graphs from grids and the construction of Two-Level Subgoal Graphs from Simple Subgoal Graphs are instances of generalized partitioning. We then report on experiments on Subgoal Graphs that demonstrate the effects of different types and levels of partitioning. We also report on experiments that demonstrate that our new N-Level Subgoal Graphs with several additional improvements achieve a better performance compared to Two-Level Subgoal graphs from (Uras, Koenig, and Hernandez 2013).",
    "Authors1": "Tansel Uras",
    "Authors2": "Sven Koenig",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Tansel Uras , Sven Koenig",
    "Groups1": "Heuristic Search and Optimization (HSO)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Heuristic Search and Optimization (HSO)",
    "Keywords10": "",
    "Keywords1": "Hierarchical search",
    "Keywords2": "Path planning",
    "Keywords3": "Subgoals",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Hierarchical search;Path planning;Subgoals",
    "Title": "Identifying Hierarchies for Fast Optimal Search",
    "Topics10": "",
    "Topics1": "HSO: Heuristic Search",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "HSO: Heuristic Search"
  },
  {
    "Document Index (generated)": 148,
    "Number of Records": 1,
    "Abstract": "While the ensemble method of boosting has been extensively studied, considerably less attention has been devoted to the task of designing good weak learning algorithms. In this paper we consider the problem of designing weak learners that are especially adept to the boosting procedure and  specifically the AdaBoost algorithm.\n\nFirst we describe conditions desirable for a weak learning algorithm.  We then propose using sparse parity functions as weak learners, which have many of our desired properties, as weak learners in boosting.  Our experimental tests show the proposed weak learners to be competitive with the most widely used ones: decision stumps and pruned decision trees.",
    "Authors1": "Lev Reyzin",
    "Authors2": "",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Lev Reyzin",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "choosing weak learners",
    "Keywords2": "boosting",
    "Keywords3": "parity functions",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "choosing weak learners;boosting;parity functions",
    "Title": "On Boosting Sparse Parities",
    "Topics10": "",
    "Topics1": "NMLA: Ensemble Methods",
    "Topics2": "NMLA: Machine Learning (General/other)",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Ensemble Methods;NMLA: Machine Learning (General/other)"
  },
  {
    "Document Index (generated)": 149,
    "Number of Records": 1,
    "Abstract": "In this paper, we solve cooperative decentralized stochastic planning problems, where the interactions between agents (specified using transition and reward functions) are dependent on the number of agents (and not on the identity of the individual agents) involved in the interaction. A collision of robots in a narrow corridor, defender teams coordinating patrol activities to secure a target, etc. are examples of such anonymous interactions.  Formally, we consider problems that are a subset of the well known Decentralized MDP (DEC-MDP) model, where the anonymity in interactions is specified within the joint reward and transition functions. In this paper, we make the following key contributions:\\\\\n(a) A generic model, Decentralized Stochastic Planning with Anonymous InteracTions (D-SPAIT) to represent stochastic planning problems in cooperative domains with anonymity in interactions.\\\\\n(b) An optimization based formulation along with theoretical results that establish scalability properties for general D-SPAIT problems.  \\\\\n(c) Optimization formulations, whose scalability has little or no dependence on the number of agents, for solving certain classes of D-SPAIT problems optimally. \\\\\n(d) Finally, we demonstrate the performance of our optimization approaches on randomly generated benchmark problems from the literature.",
    "Authors1": "Pradeep Varakantham",
    "Authors2": "Yossiri Adulyasak",
    "Authors3": "Patrick Jaillet",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Pradeep Varakantham, Yossiri Adulyasak , Patrick Jaillet",
    "Groups1": "Multiagent Systems (MAS)",
    "Groups2": "Planning and Scheduling (PS)",
    "Groups3": "Reasoning under Uncertainty (RU)",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Multiagent Systems (MAS);Planning and Scheduling (PS);Reasoning under Uncertainty (RU)",
    "Keywords10": "",
    "Keywords1": "Planning under uncertainty",
    "Keywords2": "Multiagent Systems",
    "Keywords3": "DEC-MDP",
    "Keywords4": "Optimization",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Planning under uncertainty;Multiagent Systems;DEC-MDP;Optimization",
    "Title": "Decentralized Stochastic Planning with Anonymity in Interactions",
    "Topics10": "",
    "Topics1": "PS: Markov Models of Environments",
    "Topics2": "RU: Decision/Utility Theory",
    "Topics3": "RU: Uncertainty in AI (General/Other)",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "PS: Markov Models of Environments;RU: Decision/Utility Theory;RU: Uncertainty in AI (General/Other)"
  },
  {
    "Document Index (generated)": 150,
    "Number of Records": 1,
    "Abstract": "Regret matching is a widely-used algorithm for learning how to act.\n\nWe begin by proving that regrets on actions in one setting (game) can be transferred to warm start the regrets for solving a different setting with same structure but different payoffs that can be written as a function of parameters.  We prove how this can be done by carefully discounting the prior regrets. This provides, to our knowledge, the first warm-starting method for no-regret learning.  It also extends to warm-starting the widely-adopted counterfactual regret minimization (CFR) algorithm for large incomplete-information games; we show this experimentally as well.\n\nWe then study optimizing a parameter vector for a player in a two-player zero-sum game (e.g., optimizing bet sizes to use in poker). We propose a custom gradient descent algorithm that provably finds a locally optimal parameter vector while leveraging our warm-start theory to significantly save regret-matching iterations at each step. It optimizes the parameter vector while simultaneously finding an equilibrium. We present experiments in no-limit Leduc Hold'em and no-limit Texas Hold'em  to optimize bet sizing.  This amounts to the first action abstraction algorithm (algorithm for selecting a small number of discrete actions to use from a continuum of actions---a key preprocessing step for solving large games using current equilibrium-finding algorithms) with convergence guarantees for extensive-form games.",
    "Authors1": "Noam Brown",
    "Authors2": "Tuomas S",
    "Authors3": "holm",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Noam Brown , Tuomas S,holm",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP)",
    "Keywords10": "",
    "Keywords1": "Large Incomplete-Information Games",
    "Keywords2": "Poker",
    "Keywords3": "Game Solving",
    "Keywords4": "No-Regret Learning",
    "Keywords5": "Counterfactual Regret Minimization",
    "Keywords6": "Regret Matching",
    "Keywords7": "Regret Minimization",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Large Incomplete-Information Games;Poker;Game Solving;No-Regret Learning;Counterfactual Regret Minimization;Regret Matching;Regret Minimization",
    "Title": "Regret Transfer and Parameter Optimization",
    "Topics10": "",
    "Topics1": "GTEP: Game Theory",
    "Topics2": "GTEP: Equilibrium",
    "Topics3": "GTEP: Imperfect Information",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Game Theory;GTEP: Equilibrium;GTEP: Imperfect Information"
  },
  {
    "Document Index (generated)": 151,
    "Number of Records": 1,
    "Abstract": "In many real-world applications of learning, the environment is open and changes gradually, which requires the system to have the ability of detecting and adapting to the changes. Class-incremental learning (C-IL) is an important and practical problem where data from unseen augmented classes are fed, but has not been studied well in the past. In C-IL, the system should beware of predicting instances from augmented classes as a seen class, and thus faces the challenge that no such instances were shown in training. In this paper, we investigate tackling the challenge by using unlabeled data, which can be cheaply collected in many real-world applications. We propose the LACU framework as well as the LACU-SVM approach to learn the concept of seen classes while incorporating the structure presented in the unlabeled data, so that the misclassification risks among the seen classes as well as between the augmented and the seen classes are minimized simultaneously. Experiments on diverse datasets show the effectiveness of the proposed approach.",
    "Authors1": "Qing Da",
    "Authors2": "Yang Yu",
    "Authors3": "Zhi-Hua Zhou",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Qing Da, Yang Yu , Zhi-Hua Zhou",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "open set classification",
    "Keywords2": "unlabeled data",
    "Keywords3": "support vector machines",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "open set classification;unlabeled data;support vector machines",
    "Title": "Learning with Augmented Class by Exploiting Unlabeled Data",
    "Topics10": "",
    "Topics1": "NMLA: Classification",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Classification"
  },
  {
    "Document Index (generated)": 152,
    "Number of Records": 1,
    "Abstract": "Low-rank coding (LRC), originated from matrix decomposition, is recently introduced into image classification. Following the standard bag-of-words (BOW) pipeline, coding the data matrix in the sense of low-rankness incorporates contextual information into the traditional BOW model and it can capture the dependency relationship among neighbor patches. This differs from the traditional sparse coding paradigms which encode patches independently. Current LRC-based methods use l1 norm to increase the discrimination and sparsity of the learned codes. However, such methods fail to consider the local manifold structure between data space and dictionary space. To solve this problem, we propose a locality-constrained low-rank coding (LCLR) algorithm for image representations. By using the geometric structure information as a regularization term, the obtained representations are more discriminative. In addition, we present a fast and stable online algorithm to solve the optimization problem. In the experiments, we evaluate LCLR on four benchmarks, including one face recognition dataset (extended Yale B), one handwritten digit recognition dataset (USPS), and two image datasets (Scene13 for scene recognition and Caltech101 for object recognition). Experimental results show that our approach outperforms many state-of-the-art algorithms even with a linear classifier.",
    "Authors1": "Ziheng Jiang",
    "Authors2": "Ping Guo",
    "Authors3": "Lihong Peng",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Ziheng Jiang, Ping Guo , Lihong Peng",
    "Groups1": "Vision (VIS)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Vision (VIS)",
    "Keywords10": "",
    "Keywords1": "Bag-of-words Model",
    "Keywords2": "Mid-level Representations",
    "Keywords3": "Locality Coding",
    "Keywords4": "Low-rank Coding",
    "Keywords5": "Inexact Augmented Lagrange Multiplier",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Bag-of-words Model;Mid-level Representations;Locality Coding;Low-rank Coding;Inexact Augmented Lagrange Multiplier",
    "Title": "Locality-constrained Low-rank Coding for Image Classification",
    "Topics10": "",
    "Topics1": "VIS: Categorization",
    "Topics2": "VIS: Face and Gesture Recognition",
    "Topics3": "VIS: Object Recognition",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "VIS: Categorization;VIS: Face and Gesture Recognition;VIS: Object Recognition"
  },
  {
    "Document Index (generated)": 153,
    "Number of Records": 1,
    "Abstract": "This paper resolves previous problems in the Multi-Strategy architecture for online learning of robotic behaviours.\nThe hybrid method includes a symbolic qualitative planner that constructs an approximate solution to a control problem.\nThe approximate solution provides constraints for a numerical optimisation algorithm, which is used to refine the qualitative plan into an operational policy.\nIntroducing quantitative constraints into the planner gives previously unachievable domain independent reasoning.\nThe method is demonstrated on a multi-tracked robot intended for urban search and rescue.",
    "Authors1": "Timothy Wiley",
    "Authors2": "Claude Sammut",
    "Authors3": "Ivan Bratko",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Timothy Wiley, Claude Sammut , Ivan Bratko",
    "Groups1": "Cognitive Systems (CS)",
    "Groups2": "Robotics (ROB)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Cognitive Systems (CS);Robotics (ROB)",
    "Keywords10": "",
    "Keywords1": "Robotics",
    "Keywords2": "Online Machine Learning",
    "Keywords3": "Multi-Strategy Architecture",
    "Keywords4": "Qualitative Reasoning",
    "Keywords5": "Qualitative Planning",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Robotics;Online Machine Learning;Multi-Strategy Architecture;Qualitative Reasoning;Qualitative Planning",
    "Title": "Qualitative Planning with Quantitative Constraints for Online Learning of Robotic Behaviours",
    "Topics10": "",
    "Topics1": "CS: Problem solving and decision making",
    "Topics2": "ROB: Behavior and Control",
    "Topics3": "ROB: Motion and Path Planning",
    "Topics4": "ROB: Robotics (General/Other)",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "CS: Problem solving and decision making;ROB: Behavior and Control;ROB: Motion and Path Planning;ROB: Robotics (General/Other)"
  },
  {
    "Document Index (generated)": 154,
    "Number of Records": 1,
    "Abstract": "Many multi-agent coordination problems can be represented\nas DCOPs. Motivated by task allocation in disaster\nresponse, we extend standard DCOP models to consider\nuncertain task rewards where the outcome of completing\na task depends on its current state, which is randomly\ndrawn from unknown distributions. The goal of\nsolving this problem is to find a solution for all agents\nthat minimizes the overall worst-case loss. This is a\nchallenging problem for centralized algorithms because\nthe search space grows exponentially with the number\nof agents and is nontrivial for existing algorithms for\nstandard DCOPs. To address this, we propose a novel\ndecentralized algorithm that incorporates Max-Sum\nwith iterative constraint generation to solve the problem\nby passing messages among agents. By so doing, our\napproach scales well and can solve instances of the task\nallocation problem with hundreds of agents and tasks.",
    "Authors1": "Feng Wu",
    "Authors2": "",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Feng Wu",
    "Groups1": "Multiagent Systems (MAS)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Multiagent Systems (MAS)",
    "Keywords10": "",
    "Keywords1": "Multi-Agent Coordination",
    "Keywords2": "Uncertain Task Rewards",
    "Keywords3": "DCOP",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Multi-Agent Coordination;Uncertain Task Rewards;DCOP",
    "Title": "Regret-Based Multi-Agent Coordination with Uncertain Task Rewards",
    "Topics10": "",
    "Topics1": "MAS: Coordination and Collaboration",
    "Topics2": "MAS: Distributed Problem Solving",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "MAS: Coordination and Collaboration;MAS: Distributed Problem Solving"
  },
  {
    "Document Index (generated)": 155,
    "Number of Records": 1,
    "Abstract": "We present a general framework for association learning where entities are embedded in a common latent semantic space to allow relatedness to be expressed by geometry---an approach that underlies the state of the art for link prediction, relation learning, multi-label tagging, relevance retrieval and ranking.  Although current approaches rely on local training algorithms applied to non-convex formulations, we demonstrate how general convex relaxations can be easily achieved for entity embedding, both for the standard multi-linear and prototype-distance response models.  We propose an incremental optimization strategy that exploits decomposition to allow scaling.  An experimental evaluation reveals the advantages of tractable and repeatable global training in different case studies.",
    "Authors1": "Farzaneh Mirzazadeh",
    "Authors2": "Yuhong Guo",
    "Authors3": "Dale Schuurmans",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Farzaneh Mirzazadeh, Yuhong Guo , Dale Schuurmans",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "convex relaxation",
    "Keywords2": "matrix norm regularization",
    "Keywords3": "relation learning",
    "Keywords4": "representation learning",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "convex relaxation;matrix norm regularization;relation learning;representation learning",
    "Title": "Convex Co-embedding",
    "Topics10": "",
    "Topics1": "NMLA: Dimension Reduction/Feature Selection",
    "Topics2": "NMLA: Relational/Graph-Based Learning",
    "Topics3": "NMLA: Supervised Learning (Other)",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Dimension Reduction/Feature Selection;NMLA: Relational/Graph-Based Learning;NMLA: Supervised Learning (Other)"
  },
  {
    "Document Index (generated)": 156,
    "Number of Records": 1,
    "Abstract": "Decomposition can be defined as a technique to obtain complete solutions by easy composition of partial solutions. Typically, these partial solutions are obtained by distributed and concurrent local problem solving without communication between the individual problem solvers. Constraint decomposition plays an important role in distributed databases, distributed scheduling and violation detection: Here, it enables conflict-free local decision making, while avoiding communication overloading. One of the main issues in decomposition is the loss of flexibility due to the composition technique used. Here, flexibility roughly refers to the freedom in choosing suitable values for the variables in order to satisfy the constraints. In this paper we concentrate on linear constraint systems and efficient decomposition techniques for these systems. Using a generalization of a flexibility metric developed for STNs, we show how  an efficient decomposition technique for linear constraints can be derived that minimizes the loss of flexibility due to decomposition.  As a by-product of our decomposition technique, we show that an intuitively attractive flexibility metric for linear constraint systems can be developed where decomposition does not incur any loss of flexibility.",
    "Authors1": "Cees Witteveen",
    "Authors2": "Michel Wilson",
    "Authors3": "Tomas Klos",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Cees Witteveen, Michel Wilson , Tomas Klos",
    "Groups1": "Heuristic Search and Optimization (HSO)",
    "Groups2": "Multiagent Systems (MAS)",
    "Groups3": "Planning and Scheduling (PS)",
    "Groups4": "Search and Constraint Satisfaction (SCS)",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Heuristic Search and Optimization (HSO);Multiagent Systems (MAS);Planning and Scheduling (PS);Search and Constraint Satisfaction (SCS)",
    "Keywords10": "",
    "Keywords1": "temporal decoupling",
    "Keywords2": "constraint solving",
    "Keywords3": "linear programming",
    "Keywords4": "flexibility",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "temporal decoupling;constraint solving;linear programming;flexibility",
    "Title": "Optimal Decoupling in Linear Constraint Systems",
    "Topics10": "SCS: Constraint Satisfaction (General/other)",
    "Topics1": "HSO: Optimization",
    "Topics2": "MAS: Distributed Problem Solving",
    "Topics3": "MAS: Multiagent Planning",
    "Topics4": "PS: Scheduling",
    "Topics5": "PS: Temporal Planning",
    "Topics6": "PS: Planning (General/Other)",
    "Topics7": "SCS: Constraint Satisfaction",
    "Topics8": "SCS: Constraint Optimization",
    "Topics9": "SCS: Global Constraints",
    "Topics": "HSO: Optimization;MAS: Distributed Problem Solving;MAS: Multiagent Planning;PS: Scheduling;PS: Temporal Planning;PS: Planning (General/Other);SCS: Constraint Satisfaction;SCS: Constraint Optimization;SCS: Global Constraints;SCS: Constraint Satisfaction (General/other)"
  },
  {
    "Document Index (generated)": 157,
    "Number of Records": 1,
    "Abstract": "Social explanation, the statement with the form of ”A and B also like the item”, is widely used in almost all the major recommender systems in the web and effectively improves the persuasiveness of the recommendation results by convincing more users to try. This paper presents the first algorithm to generate the most persuasive social explanation by recommending the optimal set of users to be put in the explanation. New challenges like modeling persuasiveness of multiple users, different types of users in social network, sparsity of likes, are discussed in depth and solved in our algorithm. The extensive evaluation demonstrates the advantage of our proposed algorithm compared with traditional methods.",
    "Authors1": "Beidou Wang",
    "Authors2": "Martin Ester",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Beidou Wang , Martin Ester",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW)",
    "Keywords10": "",
    "Keywords1": "Recommendation Explanation",
    "Keywords2": "Social Explanation",
    "Keywords3": "Social Network",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Recommendation Explanation;Social Explanation;Social Network",
    "Title": "Who also likes it? Generating the most Persuasive Social Explanations in Recommender Systems",
    "Topics10": "",
    "Topics1": "AIW: Social networking and community identification",
    "Topics2": "AIW: Web-based recommendation systems",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: Social networking and community identification;AIW: Web-based recommendation systems"
  },
  {
    "Document Index (generated)": 158,
    "Number of Records": 1,
    "Abstract": "Planning with sensing actions under partial observability is a computationally challenging problem that is fundamental to the realization of AI tasks in areas as diverse as robotics, game playing, and diagnostic problem solving.  In this paper we explore a particular class of planning problems where the initial state specification includes a set of state constraints or so-called state invariants and where uncertainty about the state monotonically decreases.  Recent work on generating plans for partially observable domains has advocated for online planning, claiming that offline plans are often too large to generate.  Unfortunately, planning online can lead to avoidable deadends, and the generated plan only addresses the particular sequence of observations realized during the execution.  Here we push the envelope on this challenging problem, proposing a technique for generating conditional (aka contingent) plans offline.  The conditional plans we produce will eventually achieve the goal for all consistent sequences of observations for which a solution exists.  The key to our planner's success is the reliance on state-of-the-art techniques for fully observable non-deterministic (FOND) planning. In particular, we use an existing compilation for converting a planning problem under partial observability and sensing to a FOND planning problem. With a modified FOND planner in hand, we are able to scale beyond previous techniques for contingent planning and compute solutions that are orders of magnitude smaller than previously possible in some domains.",
    "Authors1": "Christian Muise",
    "Authors2": "Vaishak Belle",
    "Authors3": "Sheila Mcilraith",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Christian Muise, Vaishak Belle , Sheila Mcilraith",
    "Groups1": "Planning and Scheduling (PS)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Planning and Scheduling (PS)",
    "Keywords10": "",
    "Keywords1": "contingent planning",
    "Keywords2": "conditional planning",
    "Keywords3": "partial observability",
    "Keywords4": "planning and sensing",
    "Keywords5": "offline planning",
    "Keywords6": "FOND",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "contingent planning;conditional planning;partial observability;planning and sensing;offline planning;FOND",
    "Title": "Computing Contingent Plans via Fully Observable Non-Deterministic Planning",
    "Topics10": "",
    "Topics1": "PS: Deterministic Planning",
    "Topics2": "PS: Planning (General/Other)",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "PS: Deterministic Planning;PS: Planning (General/Other)"
  },
  {
    "Document Index (generated)": 159,
    "Number of Records": 1,
    "Abstract": "In the field of NLP, most of the existing domain adaptation studies belong to the feature-based adaptation, while the research of instance-based adaptation is very scarce. In this work, we propose a new instance-based adaptation model, called in-target-domain logistic approximation (ILA). In ILA, we adapt the source-domain data to the target domain by a logistic approximation. The normalized in-target-domain probability is assigned as an instance weight to each of the source-domain training data. An instance-weighted classification model is trained finally for the cross-domain classification problem. Compared to the previous techniques, ILA conducts instance adaptation in a dimensionality-reduced linear feature space to ensure efficiency in high-dimensional NLP tasks. The instance weights in ILA are learnt by leveraging the criteria of both maximum likelihood and minimum statistical distance. The empirical results on two NLP tasks including text categorization and sentiment classification show that our ILA model beats the state-of-the-art instance adaptation methods significantly, in cross-domain classification accuracy, parameter stability and computational efficiency.",
    "Authors1": "Rui Xia",
    "Authors2": "Jianfei Yu",
    "Authors3": "Feng Xu",
    "Authors4": "Shumei Wang",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Rui Xia, Jianfei Yu, Feng Xu , Shumei Wang",
    "Groups1": "NLP and Machine Learning (NLPML)",
    "Groups2": "Novel Machine Learning Algorithms (NMLA)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "NLP and Machine Learning (NLPML);Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "domain adaptation",
    "Keywords2": "instance adaptation",
    "Keywords3": "instance-based adaptation",
    "Keywords4": "density-ratio estimation",
    "Keywords5": "text categorization",
    "Keywords6": "sentiment classification",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "domain adaptation;instance adaptation;instance-based adaptation;density-ratio estimation;text categorization;sentiment classification",
    "Title": "Instance-based Domain Adaptation in NLP via In-target-domain Logistic Approximation",
    "Topics10": "",
    "Topics1": "NLPML: Text Classification",
    "Topics2": "NLPML: Natural Language Processing (General/Other)",
    "Topics3": "NMLA: Transfer, Adaptation, Multitask Learning",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NLPML: Text Classification;NLPML: Natural Language Processing (General/Other);NMLA: Transfer, Adaptation, Multitask Learning"
  },
  {
    "Document Index (generated)": 160,
    "Number of Records": 1,
    "Abstract": "The popularity of online shopping has contributed to the development of comparison shopping agents (CSAs) aiming to facilitate buyers' ability to compare prices of online stores for any desired product. Furthermore, the plethora of CSAs in today’s markets enables buyers to query more than a single CSA when shopping, thus expanding even further the list of sellers whose prices they obtain. This potentially decreases the chance of a purchase based on the prices outputted as a result of any single query, and consequently decreases each CSAs’ expected revenue per-query. Obviously, a CSA can improve its competence in such settings by acquiring more sellers’ prices, potentially resulting in a more attractive ``best price''. In this paper we suggest a complementary approach that improves the attractiveness of a CSA by presenting the prices to the user in a specific intelligent manner, which is based on known cognitive-biases.\nThe advantage of this approach is its ability to affect the buyer’s tendency to terminate her search for a better price, hence avoid querying further CSAs, without having the CSA spend any of its resources on finding better prices to present.\nThe effectiveness of our method is demonstrated using real data, collected from four CSAs for five products. Our experiments with people confirm that the suggested method effectively influence people in a way that is highly advantageous to the CSA.",
    "Authors1": "Chen Hajaj",
    "Authors2": "Noam Hazon",
    "Authors3": "David Sarne",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Chen Hajaj, Noam Hazon , David Sarne",
    "Groups1": "Humans and AI (HAI)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Humans and AI (HAI)",
    "Keywords10": "",
    "Keywords1": "comparison shopping agents",
    "Keywords2": "belief-adjustment",
    "Keywords3": "ordering",
    "Keywords4": "experimentation",
    "Keywords5": "eCommerce",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "comparison shopping agents;belief-adjustment;ordering;experimentation;eCommerce",
    "Title": "Ordering Effects and Belief Adjustment in the Use of Comparison Shopping Agents",
    "Topics10": "",
    "Topics1": "HAI: Human-Computer Interaction",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "HAI: Human-Computer Interaction"
  },
  {
    "Document Index (generated)": 161,
    "Number of Records": 1,
    "Abstract": "We consider the class of convex minimization problems, composed of a self-concordant function, such as the logdet metric, a convex data fidelity term h() and, a regularizing -- possibly non-smooth -- function g(), accompanied with an easily computable proximity operator. These type of problems have recently attracted a great deal of interest, mainly due to their omnipresence in top-notch applications. Under this locally Lipschitz continuous gradient setting, we analyze the convergence behavior of proximal Newton schemes with the added twist of a probable presence of inexact evaluations; a scenario that has not been considered yet, to the best of our knowledge. By using standard convex tools combined with self-concordance machinery, we provide a concise convergence theory with attractive convergence rate guarantees, and enhance state-of-the-art optimization schemes to accommodate such developments. Experimental results on sparse covariance estimation show the merits of our algorithm, both in terms of recovery efficiency and complexity, rendering the proposed framework a suitable choice for such problems.",
    "Authors1": "Anastasios Kyrillidis",
    "Authors2": "Rabeeh Karimi Mahabadi",
    "Authors3": "Quoc Tran-Dinh",
    "Authors4": "Volkan Cevher",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Anastasios Kyrillidis, Rabeeh Karimi Mahabadi, Quoc Tran-Dinh , Volkan Cevher",
    "Groups1": "Machine Learning Applications (MLA)",
    "Groups2": "Novel Machine Learning Algorithms (NMLA)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Machine Learning Applications (MLA);Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "Inexact proximal Newton methods",
    "Keywords2": "Sparse covariance estimation",
    "Keywords3": "Self-concordance property",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Inexact proximal Newton methods;Sparse covariance estimation;Self-concordance property",
    "Title": "Scalable sparse covariance estimation via self-concordance",
    "Topics10": "",
    "Topics1": "MLA: Machine Learning Applications (General/other)",
    "Topics2": "NMLA: Big Data / Scalability",
    "Topics3": "NMLA: Data Mining and Knowledge Discovery",
    "Topics4": "NMLA: Graphical Model Learning",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "MLA: Machine Learning Applications (General/other);NMLA: Big Data / Scalability;NMLA: Data Mining and Knowledge Discovery;NMLA: Graphical Model Learning"
  },
  {
    "Document Index (generated)": 162,
    "Number of Records": 1,
    "Abstract": "Designing mechanisms that satisfy individual rationality, Pareto efficiency, and strategyproofness is one of the most important problems in mechanism design. In this paper we investigate mechanism design for exchange models where each agent is initially endowed with a set of goods, each agent may have indifferences on distinct bundles of goods, and monetary transfers are not allowed. Sönmez (1999) showed that in such models, those three properties are not compatible in general. The impossibility, however, only holds under an assumption on preference domains.\nThe purpose of this paper is to give a discussion on the compatibility of those three properties when the assumption does not hold. We first establish a preference domain called top-only preferences, which violates the assumption, and develop a class of exchange mechanisms satisfying all those properties. Each mechanism in the class utilizes one instance of mechanisms introduced by Saban and Sethuraman (2013). We also find a class of preference domains called m-chotomous preferences, where the assumption fails and those properties are incompatible.",
    "Authors1": "Akihisa Sonoda",
    "Authors2": "Etsushi Fujita",
    "Authors3": "Taiki Todo",
    "Authors4": "Makoto Yokoo",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Akihisa Sonoda, Etsushi Fujita, Taiki Todo , Makoto Yokoo",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP)",
    "Keywords10": "",
    "Keywords1": "Mechanism design",
    "Keywords2": "Exchange",
    "Keywords3": "Indifference",
    "Keywords4": "Pareto efficiency",
    "Keywords5": "Strategy-proofness",
    "Keywords6": "Individual rationality",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Mechanism design;Exchange;Indifference;Pareto efficiency;Strategy-proofness;Individual rationality",
    "Title": "Trading Multiple Indivisible Goods with Indifferences: Beyond Sönmez's Result",
    "Topics10": "",
    "Topics1": "GTEP: Game Theory",
    "Topics2": "GTEP: Social Choice / Voting",
    "Topics3": "MAS: E-Commerce",
    "Topics4": "MAS: Mechanism Design",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Game Theory;GTEP: Social Choice / Voting;MAS: E-Commerce;MAS: Mechanism Design"
  },
  {
    "Document Index (generated)": 163,
    "Number of Records": 1,
    "Abstract": "SenticNet is a publicly available semantic and affective resource for concept-level opinion mining and sentiment analysis. Rather than using graph-mining and dimensionality-reduction techniques, SenticNet 3 makes use of `energy flows' to connect various parts of extended common and common-sense knowledge representations to one another. SenticNet 3 models nuanced semantics and sentics (that is, the conceptual and affective information associated with multi-word natural language expressions), representing information with a symbolic opacity intermediate between that of neural networks and of typical symbolic systems.",
    "Authors1": "Erik Cambria",
    "Authors2": "",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Erik Cambria",
    "Groups1": "Cognitive Systems (CS)",
    "Groups2": "Knowledge Representation and Reasoning (KRR)",
    "Groups3": "NLP and Knowledge Representation (NLPKR)",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Cognitive Systems (CS);Knowledge Representation and Reasoning (KRR);NLP and Knowledge Representation (NLPKR)",
    "Keywords10": "",
    "Keywords1": "concept-level sentiment analysis",
    "Keywords2": "natural language processing",
    "Keywords3": "common-sense reasoning",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "concept-level sentiment analysis;natural language processing;common-sense reasoning",
    "Title": "SenticNet 3: A Common and Common-Sense Knowledge Base for Cognition-Driven Sentiment Analysis",
    "Topics10": "",
    "Topics1": "CS: Conceptual inference and reasoning",
    "Topics2": "KRR: Common-Sense Reasoning",
    "Topics3": "KRR: Knowledge Representation (General/Other)",
    "Topics4": "NLPKR: Natural Language Processing (General/Other)",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "CS: Conceptual inference and reasoning;KRR: Common-Sense Reasoning;KRR: Knowledge Representation (General/Other);NLPKR: Natural Language Processing (General/Other)"
  },
  {
    "Document Index (generated)": 164,
    "Number of Records": 1,
    "Abstract": "Multi-objective problems with correlated objectives are a class of problems that deserve specific attention. In contrast to typical multi-objective problems, they do not require the identification of trade-offs between the objectives, as (near-) optimal solutions for any objective are (near-) optimal for every objective. Intelligently combining the feedback from these objectives, instead of only looking at a single one, can improve optimization. This class of problems is very relevant in reinforcement learning, as any single-objective reinforcement learning problem can be framed as such a multi-objective problem using multiple reward shaping functions. After discussing this problem class, we propose a solution technique for such reinforcement learning problems, called adaptive objective selection. This technique  makes a temporal difference learner estimate the Q-function for each objective in parallel, and introduces a way to measure confidence in these estimates. This confidence metric is then used to choose which objective's estimates to use for action selection. We show significant improvements in performance over other plausible techniques on two problem domains. Finally, we provide an intuitive analysis of the technique's decisions, yielding insights into the nature of the problems being solved.",
    "Authors1": "Tim Brys",
    "Authors2": "Ann Nowé",
    "Authors3": "Daniel Kudenko",
    "Authors4": "Matthew E. Taylor",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Tim Brys, Ann Nowé, Daniel Kudenko , Matthew E. Taylor",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "Reinforcement Learning",
    "Keywords2": "Reward Shaping",
    "Keywords3": "Multi-Objective Optimization",
    "Keywords4": "Traffic Light Control",
    "Keywords5": "Pursuit Domain",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Reinforcement Learning;Reward Shaping;Multi-Objective Optimization;Traffic Light Control;Pursuit Domain",
    "Title": "Combining Multiple Correlated Reward and Shaping Signals by Measuring Confidence",
    "Topics10": "",
    "Topics1": "NMLA: Reinforcement Learning",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Reinforcement Learning"
  },
  {
    "Document Index (generated)": 165,
    "Number of Records": 1,
    "Abstract": "Markov processes are widely used to generate sequences that imitate a given style, using random walk. Random walk generates sequences by iteratively concatenating states to prefixes of length equal or less than the given Markov order. However, at higher orders, Markov chains tend to replicate chunks of the corpus with a size possibly higher than the order, a primary form of plagiarism. In fact, the Markov order defines a maximum length for training but not for generation. In the framework of constraint satisfaction (CSP), we introduce MaxOrder. This global constraint ensures that generated sequences do not include chunks larger than a given maximum order. We exhibit an automaton that recognises the solution set, with a size linear in the size of the corpus. We propose a linear-time procedure to generate this automaton from a corpus and a given max order. We then use this automaton to achieve generalised arc consistency for the MaxOrder constraint, holding on a sequence of size n, in O(n.T) time, where T is the size of the automaton. We illustrate our approach by generating text sequences from text corpora with a maximum order guarantee, effectively controlling plagiarism.",
    "Authors1": "Alex",
    "Authors2": "re Papadopoulos",
    "Authors3": "Pierre Roy",
    "Authors4": "François Pachet",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Alex,re Papadopoulos, Pierre Roy , François Pachet",
    "Groups1": "Machine Learning Applications (MLA)",
    "Groups2": "Search and Constraint Satisfaction (SCS)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Machine Learning Applications (MLA);Search and Constraint Satisfaction (SCS)",
    "Keywords10": "",
    "Keywords1": "markov chains",
    "Keywords2": "plagiarism",
    "Keywords3": "constraint satisfaction",
    "Keywords4": "global constraints",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "markov chains;plagiarism;constraint satisfaction;global constraints",
    "Title": "Avoiding Plagiarism in Markov Sequence Generation",
    "Topics10": "",
    "Topics1": "APP: Art and Music",
    "Topics2": "MLA: Machine Learning Applications (General/other)",
    "Topics3": "SCS: Constraint Satisfaction",
    "Topics4": "SCS: Global Constraints",
    "Topics5": "SCS: Constraint Satisfaction (General/other)",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "APP: Art and Music;MLA: Machine Learning Applications (General/other);SCS: Constraint Satisfaction;SCS: Global Constraints;SCS: Constraint Satisfaction (General/other)"
  },
  {
    "Document Index (generated)": 166,
    "Number of Records": 1,
    "Abstract": "Air pollution has a direct impact to human health, and data-driven air quality models are useful for evaluating population exposure to air pollutants. In this paper, we propose a novel region-based Gaussian Process model for estimating urban air pollution dispersion, and applied it to a large dataset of ultrafine particle measurements collected from a network of trams monitoring levels of ultrafine particle dispersion in the city of Zurich. We show that compared to existing grid-based models, the region-based model produces better predictions across all aggregate time scales. The new model is appropriate for many useful user applications such as anomaly detection, exposure assessment and sensor optimization.",
    "Authors1": "Arnaud Jutzeler",
    "Authors2": "Jason Jingshi Li",
    "Authors3": "Boi Faltings",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Arnaud Jutzeler, Jason Jingshi Li , Boi Faltings",
    "Groups1": "Computational Sustainability and AI (CSAI)",
    "Groups2": "Machine Learning Applications (MLA)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Computational Sustainability and AI (CSAI);Machine Learning Applications (MLA)",
    "Keywords10": "",
    "Keywords1": "Spatial Reasoning",
    "Keywords2": "Computational Sustainability",
    "Keywords3": "Gaussian Process",
    "Keywords4": "Urban Air Quality",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Spatial Reasoning;Computational Sustainability;Gaussian Process;Urban Air Quality",
    "Title": "A Region-Based Model for Estimating Urban Air Pollution",
    "Topics10": "",
    "Topics1": "CSAI: Modeling and prediction of dynamic and spatiotemporal phenomena and systems",
    "Topics2": "MLA: Environmental",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "CSAI: Modeling and prediction of dynamic and spatiotemporal phenomena and systems;MLA: Environmental"
  },
  {
    "Document Index (generated)": 167,
    "Number of Records": 1,
    "Abstract": "We present and analyze a mechanism for the Combinatorial Public Project Problem (CPPP). The problem asks to select k out of m available items, so as to maximize the social welfare for autonomous agents with combinatorial preferences (valuation functions) over subsets of items. The CPPP constitutes an abstract model for decision making by autonomous agents and has been shown to present severe computational hardness, in the design of truthful approximation mechanisms. We study a non-truthful mechanism that is, however, practically relevant to multi-agent environments, by virtue of its natural simplicity. It employs an Item Bidding interface, wherein every agent issues a separate bid for the inclusion of each distinct item in the outcome; the k items with the highest sums of bids are chosen and agents are charged according to a VCG-based payment rule. For fairly expressive classes of the agents' valuation functions, we establish existence of socially optimal pure Nash and strong equilibria, that are resilient to coordinated deviations of subsets of agents. Subsequently we derive tight worst-case bounds on the approximation of the optimum social welfare achieved in equilibrium. We show that the mechanism's performance improves with the number of agents that can coordinate, and reaches half of the optimum welfare at strong equilibrium.",
    "Authors1": "Evangelos Markakis",
    "Authors2": "Orestis Telelis",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Evangelos Markakis , Orestis Telelis",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "Multiagent Systems (MAS)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP);Multiagent Systems (MAS)",
    "Keywords10": "",
    "Keywords1": "Public Project",
    "Keywords2": "Mechanisms",
    "Keywords3": "Valuation Function",
    "Keywords4": "Social Welfare",
    "Keywords5": "Nash Equilibrium",
    "Keywords6": "Strong Equilibrium",
    "Keywords7": "Price of Anarchy",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Public Project;Mechanisms;Valuation Function;Social Welfare;Nash Equilibrium;Strong Equilibrium;Price of Anarchy",
    "Title": "Item Bidding  for Combinatorial Public Projects",
    "Topics10": "",
    "Topics1": "GTEP: Game Theory",
    "Topics2": "GTEP: Coordination and Collaboration",
    "Topics3": "GTEP: Equilibrium",
    "Topics4": "MAS: Coordination and Collaboration",
    "Topics5": "MAS: Mechanism Design",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Game Theory;GTEP: Coordination and Collaboration;GTEP: Equilibrium;MAS: Coordination and Collaboration;MAS: Mechanism Design"
  },
  {
    "Document Index (generated)": 168,
    "Number of Records": 1,
    "Abstract": "For expressive ontology languages such as OWL 2 DL, classification is a computationally expensive task---2\\textsc{NExpTime}-complete in the worst case. Hence, it is highly desirable to be able to accurately estimate classification time, especially for large and complex ontologies. Recently, machine learning techniques have been successfully applied to predicting the reasoning \\emph{hardness category} for a given (ontology, reasoner) pair. In this paper, we further develop predictive models to estimate actual classification time using regression techniques, with ontology metrics as features. Our large-scale experiments on 6 state-of-the-art OWL 2 DL reasoners and more than 450 significantly diverse ontologies demonstrate that the prediction models achieve high accuracy, good generalizability and statistical significance. Such prediction models have a wide range of applications. We demonstrate how they can be used to efficiently and accurately identify \\emph{performance hotspots} in an large and complex ontology, an otherwise very time-consuming and resource-intensive task.",
    "Authors1": "Yong-Bin Kang",
    "Authors2": "Jeff Z. Pan",
    "Authors3": "Shonali Krishnaswamy",
    "Authors4": "Wudhichart Sawangphol",
    "Authors5": "Yuan-Fang Li",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Yong-Bin Kang, Jeff Z. Pan, Shonali Krishnaswamy, Wudhichart Sawangphol , Yuan-Fang Li",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW)",
    "Keywords10": "",
    "Keywords1": "Ontology",
    "Keywords2": "Reasoning performance",
    "Keywords3": "Semantic Web",
    "Keywords4": "Prediction",
    "Keywords5": "Regression",
    "Keywords6": "Performance hotspot detection",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Ontology;Reasoning performance;Semantic Web;Prediction;Regression;Performance hotspot detection",
    "Title": "How Long Will It Take? Accurate Prediction of Ontology Reasoning Performance",
    "Topics10": "",
    "Topics1": "AIW: Ontologies and the web: creation, extraction, evolution, mapping, merging, and alignment",
    "Topics2": "tags and folksonomies",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: Ontologies and the web: creation, extraction, evolution, mapping, merging, and alignment; tags and folksonomies"
  },
  {
    "Document Index (generated)": 169,
    "Number of Records": 1,
    "Abstract": "Backdoors measure the distance to tractable fragments\nand have become an important tool to find fixed-parameter\ntractable (fpt) algorithms. Despite their success, backdoors\nhave not been used for planning, a central problem\nin AI that has a high computational complexity. In this\nwork, we introduce two notions of backdoors building\nupon the causal graph. We analyze the complexity of\nfinding a small backdoor (detection) and using the backdoor\nto solve the problem (evaluation) in the light of\nplanning with (un)bounded domain/plan length. For each\nsetting we present either an fpt-result or rule out the existence\nthereof by showing parameterized intractability.\nIn three cases we achieve the most desirable outcome:\ndetection and evaluation are fpt.",
    "Authors1": "Martin Kronegger",
    "Authors2": "Sebastian Ordyniak",
    "Authors3": "Andreas Pf",
    "Authors4": "ler",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Martin Kronegger, Sebastian Ordyniak , Andreas Pf,ler",
    "Groups1": "Knowledge Representation and Reasoning (KRR)",
    "Groups2": "Planning and Scheduling (PS)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Knowledge Representation and Reasoning (KRR);Planning and Scheduling (PS)",
    "Keywords10": "",
    "Keywords1": "Planning",
    "Keywords2": "Backdoors",
    "Keywords3": "Fixed-parameter tractable algorithms",
    "Keywords4": "(Parameterized) complexity",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Planning;Backdoors;Fixed-parameter tractable algorithms;(Parameterized) complexity",
    "Title": "Backdoors to Planning",
    "Topics10": "",
    "Topics1": "KRR: Computational Complexity of Reasoning",
    "Topics2": "PS: Deterministic Planning",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "KRR: Computational Complexity of Reasoning;PS: Deterministic Planning"
  },
  {
    "Document Index (generated)": 170,
    "Number of Records": 1,
    "Abstract": "Realistic multi-agent team applications often feature dynamic environments with soft deadlines that penalize late execution of tasks.  This puts a premium on quickly allocating tasks to agents, but finding the optimal allocation is NP-hard due to temporal and spatial constraints that require tasks to be executed sequentially by agents.\n\nWe propose FMC_TA, a novel task allocation algorithm that allows tasks to be easily sequenced to yield high-quality solutions. FMC_TA first finds allocations that are fair (envy-free), balancing the load and sharing important tasks between agents, and efficient (Pareto optimal) in a simplified version of the problem.  It computes such allocations in polynomial or pseudo-polynomial time (centrally or distributedly, respectively) using a Fisher market with agents as buyers and tasks as goods. It then heuristically schedules the allocations, taking into account inter-agent constraints on shared tasks.\n\nWe empirically compare our algorithm to state-of-the-art incomplete methods, both centralized and distributed, on law enforcement problems inspired by real police logs.  The results show a clear advantage for FMC_TA both in total utility and in other measures commonly used by law enforcement authorities.",
    "Authors1": "Sofia Amador",
    "Authors2": "Steven Okamoto",
    "Authors3": "Roie Zivan",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Sofia Amador, Steven Okamoto , Roie Zivan",
    "Groups1": "Multiagent Systems (MAS)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Multiagent Systems (MAS)",
    "Keywords10": "",
    "Keywords1": "Task Allocation",
    "Keywords2": "Dynamic Problem",
    "Keywords3": "Cooperative Agents",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Task Allocation;Dynamic Problem;Cooperative Agents",
    "Title": "Dynamic Multi-Agent Task Allocation with Spatial and Temporal Constraints",
    "Topics10": "",
    "Topics1": "MAS: Coordination and Collaboration",
    "Topics2": "MAS: Distributed Problem Solving",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "MAS: Coordination and Collaboration;MAS: Distributed Problem Solving"
  },
  {
    "Document Index (generated)": 171,
    "Number of Records": 1,
    "Abstract": "We study the problem of rewriting a disjunctive datalog program into plain datalog. We show that a disjunctive program is rewritable if and only if it is equivalent to a linear disjunctive program, thus providing a novel characterisation of datalog rewritability. Motivated by this result, we propose weakly linear disjunctive datalog---a novel rule-based KR language that extends both datalog and linear disjunctive datalog and for which reasoning is tractable in data complexity. We then explore applications of weakly linear programs to ontology reasoning and propose a tractable extension of OWL 2 RL with disjunctive axioms. Our empirical results suggest that many non-Horn ontologies can be reduced to weakly linear programs and that query answering over such ontologies using a datalog engine is feasible in practice.",
    "Authors1": "Mark Kaminski",
    "Authors2": "Yavor Nenov",
    "Authors3": "Bernardo Cuenca Grau",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Mark Kaminski, Yavor Nenov , Bernardo Cuenca Grau",
    "Groups1": "Knowledge Representation and Reasoning (KRR)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Knowledge Representation and Reasoning (KRR)",
    "Keywords10": "",
    "Keywords1": "disjunctive datalog",
    "Keywords2": "tractable reasoning",
    "Keywords3": "ontology-based query answering",
    "Keywords4": "OWL 2",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "disjunctive datalog;tractable reasoning;ontology-based query answering;OWL 2",
    "Title": "Datalog Rewritability of Disjunctive Datalog Programs and its Applications to Ontology Reasoning",
    "Topics10": "",
    "Topics1": "KRR: Ontologies",
    "Topics2": "KRR: Automated Reasoning and Theorem Proving",
    "Topics3": "KRR: Computational Complexity of Reasoning",
    "Topics4": "KRR: Description Logics",
    "Topics5": "KRR: Knowledge Representation Languages",
    "Topics6": "KRR: Logic Programming",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "KRR: Ontologies;KRR: Automated Reasoning and Theorem Proving;KRR: Computational Complexity of Reasoning;KRR: Description Logics;KRR: Knowledge Representation Languages;KRR: Logic Programming"
  },
  {
    "Document Index (generated)": 172,
    "Number of Records": 1,
    "Abstract": "The VCG mechanism is the standard method to incentivize bidders in combinatorial auctions to bid truthfully. Under the VCG mechanism, the auctioneer can sometimes increase revenue by “burning” items. We study this phenomenon in a setting where items are described by a number of attributes. The value of an attribute corresponds to a quality level, and bidders’ valuations are non-decreasing in the quality levels. In addition to burning items, we allow the auctioneer to present\nsome of the attributes as lower quality than they actually are. We study the following two revenue maximization problems under VCG: finding an optimal way to mark down items by reducing their quality levels, and finding an optimal set of items to burn. We study the effect of the following parameters on the computational complexity of these two problems: the number of attributes, the number of quality levels per attribute, and the complexity of the bidders’ valuation functions. Bidders have unit demand, so VCG’s outcome can be computed in polynomial time, and the valuation functions we consider are step functions that are non-decreasing with the quality levels. We prove that both problems are NP-hard even in the following three simple settings: a) four attributes, arbitrarily many quality levels per attribute, and single-step valuation functions, b) arbitrarily many attributes, two quality levels per attribute, and single-step valuation functions, and c) one attribute, arbitrarily many quality-levels, and multi-step valuation functions. For the case where items have only one attribute, and every bidder has a single-step valuations (that is zero below some quality threshold), we show that both problems can be solved in polynomial-time using a dynamic programming approach. For this case, we also quantify how much better marking down is than item burning, and provide examples where the improvement is best possible. Finally, we compare the revenue of both approaches with computational experiments.",
    "Authors1": "Mingyu Guo",
    "Authors2": "Argyrios Deligkas",
    "Authors3": "Rahul Savani",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Mingyu Guo, Argyrios Deligkas , Rahul Savani",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "Multiagent Systems (MAS)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP);Multiagent Systems (MAS)",
    "Keywords10": "",
    "Keywords1": "auctions",
    "Keywords2": "mechanism design",
    "Keywords3": "VCG",
    "Keywords4": "revenue maximization",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "auctions;mechanism design;VCG;revenue maximization",
    "Title": "Increasing VCG revenue by decreasing the quality of items",
    "Topics10": "",
    "Topics1": "GTEP: Auctions and Market-Based Systems",
    "Topics2": "MAS: Mechanism Design",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Auctions and Market-Based Systems;MAS: Mechanism Design"
  },
  {
    "Document Index (generated)": 173,
    "Number of Records": 1,
    "Abstract": "Consider a family whose home is equipped with several service robots.  The actions planned for the robots (e.g., doing chores, playing with the children) must adhere to {\\em interaction constraints} relating them to human activities and preferences.  These constraints must be sufficiently expressive to model both temporal and logical dependencies among robot actions and human behavior, and must accommodate incomplete information regarding human activities.  In this paper we introduce an approach for automatically generating plans that are conformant wrt. given interaction constraints and partially specified human activities.  The approach allows to separate causal reasoning about actions from reasoning about interaction constraints, and we illustrate the computational advantage this brings with experiments on a large-scale (semi-)realistic household domain with hundreds of human activities and several robots.",
    "Authors1": "Uwe Köckemann",
    "Authors2": "Federico Pecora",
    "Authors3": "Lars Karlsson",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Uwe Köckemann, Federico Pecora , Lars Karlsson",
    "Groups1": "Knowledge Representation and Reasoning (KRR)",
    "Groups2": "Planning and Scheduling (PS)",
    "Groups3": "Search and Constraint Satisfaction (SCS)",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Knowledge Representation and Reasoning (KRR);Planning and Scheduling (PS);Search and Constraint Satisfaction (SCS)",
    "Keywords10": "",
    "Keywords1": "Constraint-based planning",
    "Keywords2": "Planning in inhabited environments",
    "Keywords3": "Human-aware planning",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Constraint-based planning;Planning in inhabited environments;Human-aware planning",
    "Title": "Grandpa Hates Robots - Interaction Constraints for Planning in Inhabited Environments",
    "Topics10": "",
    "Topics1": "KRR: Preferences",
    "Topics2": "PS: Scheduling",
    "Topics3": "PS: Temporal Planning",
    "Topics4": "PS: Planning (General/Other)",
    "Topics5": "SCS: Constraint Satisfaction (General/other)",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "KRR: Preferences;PS: Scheduling;PS: Temporal Planning;PS: Planning (General/Other);SCS: Constraint Satisfaction (General/other)"
  },
  {
    "Document Index (generated)": 174,
    "Number of Records": 1,
    "Abstract": "We report on a project aiming at developing a system that solves a\nwide range of math problems written in natural language. In the\nsystem, formal analysis of natural language semantics is coupled with\nautomated reasoning technologies including computer algebra, using\nlogic as their common language. We have developed a prototype system\nthat accepts as its input a linguistically annotated problem text.\nUsing the prototype system as a reference point, we analyzed real\nuniversity entrance examination problems from the viewpoint of\nend-to-end automated reasoning. Further, evaluation on entrance exam\nmock tests revealed that an optimistic estimate of the system’s\nperformance already matches human averages on a few test sets.",
    "Authors1": "Takuya Matsuzaki",
    "Authors2": "Hidenao Iwane",
    "Authors3": "Hirokazu Anai",
    "Authors4": "Noriko Arai",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Takuya Matsuzaki, Hidenao Iwane, Hirokazu Anai , Noriko Arai",
    "Groups1": "Knowledge Representation and Reasoning (KRR)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Knowledge Representation and Reasoning (KRR)",
    "Keywords10": "",
    "Keywords1": "natural language semantics",
    "Keywords2": "mathematical problem solving",
    "Keywords3": "automated reasoning",
    "Keywords4": "computer algebra",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "natural language semantics;mathematical problem solving;automated reasoning;computer algebra",
    "Title": "The Most Uncreative Examinee: A First Step toward Wide Coverage Natural Language Math Problem Solving",
    "Topics10": "",
    "Topics1": "KRR: Automated Reasoning and Theorem Proving",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "KRR: Automated Reasoning and Theorem Proving"
  },
  {
    "Document Index (generated)": 175,
    "Number of Records": 1,
    "Abstract": "Many Artificial Intelligence tasks need large amounts of commonsense knowledge. Because obtaining this knowledge through machine learning would require a huge amount of data, a better alternative is to elicit it from people through human computation. We consider the sentiment classification task, where knowledge about the contexts that impact word polarities is crucial but hard to acquire from data. We show a novel task design that allows us to crowdsource this knowledge through Amazon Mechanical Turk with high quality. We show that the commonsense knowledge acquired in this way dramatically improves the performance of established sentiment classification methods.",
    "Authors1": "Marina Boia",
    "Authors2": "Claudiu Cristian Musat",
    "Authors3": "Boi Faltings",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Marina Boia, Claudiu Cristian Musat , Boi Faltings",
    "Groups1": "Human-Computation and Crowd Sourcing (HCC)",
    "Groups2": "Knowledge Representation and Reasoning (KRR)",
    "Groups3": "NLP and Machine Learning (NLPML)",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Human-Computation and Crowd Sourcing (HCC);Knowledge Representation and Reasoning (KRR);NLP and Machine Learning (NLPML)",
    "Keywords10": "",
    "Keywords1": "human computation",
    "Keywords2": "games with a purpose",
    "Keywords3": "crowdsourcing",
    "Keywords4": "commonsense knowledge",
    "Keywords5": "sentiment analysis",
    "Keywords6": "context",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "human computation;games with a purpose;crowdsourcing;commonsense knowledge;sentiment analysis;context",
    "Title": "Acquiring Commonsense Knowledge for Sentiment Analysis through Human Computation",
    "Topics10": "",
    "Topics1": "HCC: Domain-specific implementation challenges in human computation games",
    "Topics2": "KRR: Knowledge Acquisition",
    "Topics3": "NLPML: Text Classification",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "HCC: Domain-specific implementation challenges in human computation games;KRR: Knowledge Acquisition;NLPML: Text Classification"
  },
  {
    "Document Index (generated)": 176,
    "Number of Records": 1,
    "Abstract": "Maximization of submodular functions has wide applications in artificial intelligence and machine learning. In this work, we study the problem of learning how to maximize an adaptive submodular function. The function is initially unknown and we learn it by interacting repeatedly with the environment. A major problem in applying existing solutions to this problem is that their regret bounds scale linearly with the size of the problem. Therefore, these solutions are impractical even for moderately large problems. In this work, we use the structure of real-world problems to make learning practical. We make three main contributions. First, we propose a practical algorithm for learning how to maximize an adaptive submodular function where the distribution of the states of each item is conditioned on its features. Second, we analyze this algorithm and show that its expected cumulative regret is polylogarithmic in time. Finally, we evaluate our algorithm on two real-world problems, movie recommendation and face detection, and show that high-quality policies can be learned in just several hundred interactions.",
    "Authors1": "Victor Gabillon",
    "Authors2": "Branislav Kveton",
    "Authors3": "Brian Eriksson",
    "Authors4": "S. Muthukrishnan",
    "Authors5": "Zheng Wen",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Victor Gabillon, Branislav Kveton, Brian Eriksson, S. Muthukrishnan , Zheng Wen",
    "Groups1": "Machine Learning Applications (MLA)",
    "Groups2": "Novel Machine Learning Algorithms (NMLA)",
    "Groups3": "Planning and Scheduling (PS)",
    "Groups4": "Reasoning under Uncertainty (RU)",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Machine Learning Applications (MLA);Novel Machine Learning Algorithms (NMLA);Planning and Scheduling (PS);Reasoning under Uncertainty (RU)",
    "Keywords10": "",
    "Keywords1": "Submodularity",
    "Keywords2": "Adaptive submodularity",
    "Keywords3": "Linear bandits",
    "Keywords4": "Online learning",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Submodularity;Adaptive submodularity;Linear bandits;Online learning",
    "Title": "Optimistic Adaptive Submodularity at Scale",
    "Topics10": "",
    "Topics1": "APP: Other Applications",
    "Topics2": "MLA: Machine Learning Applications (General/other)",
    "Topics3": "NMLA: Active Learning",
    "Topics4": "NMLA: Online Learning",
    "Topics5": "NMLA: Recommender Systems",
    "Topics6": "PS: Planning (General/Other)",
    "Topics7": "RU: Sequential Decision Making",
    "Topics8": "",
    "Topics9": "",
    "Topics": "APP: Other Applications;MLA: Machine Learning Applications (General/other);NMLA: Active Learning;NMLA: Online Learning;NMLA: Recommender Systems;PS: Planning (General/Other);RU: Sequential Decision Making"
  },
  {
    "Document Index (generated)": 177,
    "Number of Records": 1,
    "Abstract": "Click prediction is one of the fundamental problems in sponsored search. Most of existing studies took advantage of machine learning approaches to predict ad click for each event of ad view independently. While these studies aimed at providing a stationary interpretation on ad clicks, they were lack of the capability to understand user clicks in a dynamic way. As observed in real-world sponsored search system, user's behavior on the ad yield high dependency on how the user previously behaved along the time, especially in terms of the queries user submitted, click / non-click on ads, dwell time on landing page, etc. Inspired by these observations, we introduce a novel framework based on Recurrent Neural Networks (RNN) to model user's sequential behaviors into the click prediction process. Compared to traditional methods, this framework aims at effective click prediction by leveraging not only user's stationary historical behaviors but the rich information and patterns implied by user's dynamic sequential behaviors. Large scale evaluations on the click-through logs from a commercial search engine demonstrate that our approach can significantly improve the click prediction accuracy, compared to other time-independent approaches.",
    "Authors1": "Yuyu Zhang",
    "Authors2": "Hanjun Dai",
    "Authors3": "Chang Xu",
    "Authors4": "Jun Feng",
    "Authors5": "Taifeng Wang",
    "Authors6": "Jiang Bian",
    "Authors7": "Bin Wang",
    "Authors": "Yuyu Zhang, Hanjun Dai, Chang Xu, Jun Feng, Taifeng Wang, Jiang Bian, Bin Wang , Tie-Yan Liu",
    "Groups1": "Machine Learning Applications (MLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Machine Learning Applications (MLA)",
    "Keywords10": "",
    "Keywords1": "Sponsored Search",
    "Keywords2": "Recurrent Neural Network",
    "Keywords3": "Sequential Click Prediction",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Sponsored Search;Recurrent Neural Network;Sequential Click Prediction",
    "Title": "Sequential Click Prediction for Sponsored Search with Recurrent Neural Networks",
    "Topics10": "",
    "Topics1": "AIW: Enhancing web search and information retrieval",
    "Topics2": "AIW: Machine learning and the web",
    "Topics3": "MLA: Applications of Supervised Learning",
    "Topics4": "MLA: Machine Learning Applications (General/other)",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: Enhancing web search and information retrieval;AIW: Machine learning and the web;MLA: Applications of Supervised Learning;MLA: Machine Learning Applications (General/other)"
  },
  {
    "Document Index (generated)": 178,
    "Number of Records": 1,
    "Abstract": "Backdoor sets represent clever reasoning shortcuts through the search space for SAT and CSP.  By instantiating the backdoor variables one reduces the given instance to several easy instances that belong to a tractable class.  The overall time needed to solve the instance is exponential in the size of the backdoor set, hence it is a challenging problem to find a small backdoor set if one exists; over the last years this problem has been subject of intensive research.\n\nIn this paper we extend the classical notion of a strong backdoor set by allowing that different instantiations of the backdoor variables result in instances that belong to different base classes; the union of the base classes forms a heterogeneous base class.  Backdoor sets to heterogeneous base classes can be much smaller than backdoor sets to homogeneous ones, hence they are much more desirable but possibly harder to find.\n\nWe draw a detailed complexity landscape for the problem of detecting strong backdoor sets into heterogeneous base classes for SAT and CSP. We provide algorithms that establish fixed-parameter tractability under natural parameterizations, and we contrast the tractability results with hardness results that pinpoint the theoretical limits.",
    "Authors1": "Serge Gaspers",
    "Authors2": "Neeldhara Misra",
    "Authors3": "Sebastian Ordyniak",
    "Authors4": "Stefan Szeider",
    "Authors5": "Stanislav Živný",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Serge Gaspers, Neeldhara Misra, Sebastian Ordyniak, Stefan Szeider , Stanislav Živný",
    "Groups1": "Search and Constraint Satisfaction (SCS)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Search and Constraint Satisfaction (SCS)",
    "Keywords10": "",
    "Keywords1": "theoretical analysis",
    "Keywords2": "Constraint Satisfaction Problem (CSP)",
    "Keywords3": "Satisfiability (SAT)",
    "Keywords4": "polymorphism",
    "Keywords5": "backdoor set",
    "Keywords6": "parameterized complexity",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "theoretical analysis;Constraint Satisfaction Problem (CSP);Satisfiability (SAT);polymorphism;backdoor set;parameterized complexity",
    "Title": "Backdoors into Heterogeneous Classes of SAT and CSP",
    "Topics10": "",
    "Topics1": "KRR: Computational Complexity of Reasoning",
    "Topics2": "SCS: Constraint Satisfaction",
    "Topics3": "SCS: Satisfiability (General/Other)",
    "Topics4": "SCS: Constraint Satisfaction (General/other)",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "KRR: Computational Complexity of Reasoning;SCS: Constraint Satisfaction;SCS: Satisfiability (General/Other);SCS: Constraint Satisfaction (General/other)"
  },
  {
    "Document Index (generated)": 179,
    "Number of Records": 1,
    "Abstract": "This paper presents a theoretical as well as empirical study on the evolution of cooperation on complex social networks, following the continuous action iterated prisoner's dilemma (CAIPD) model. In particular, convergence to network-wide agreement is proven for both evolutionary networks with fixed interaction dynamics, as well as for coevolutionary networks where these dynamics change over time. Moreover, an extension to the CAIPD model is proposed that allows to model active influence of the evolution of cooperation in social networks. As such, this work contributes to a better understanding of behavioral change on social networks, and provides a first step towards their active control.",
    "Authors1": "Bijan Ranjbar-Sahraei",
    "Authors2": "Haitham Bou Ammar",
    "Authors3": "Daan Bloembergen",
    "Authors4": "Karl Tuyls",
    "Authors5": "Gerhard Weiss",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Bijan Ranjbar-Sahraei, Haitham Bou Ammar, Daan Bloembergen, Karl Tuyls , Gerhard Weiss",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "Multiagent Systems (MAS)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP);Multiagent Systems (MAS)",
    "Keywords10": "",
    "Keywords1": "coevolutionary networks",
    "Keywords2": "evolution of cooperation",
    "Keywords3": "influencing social networks",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "coevolutionary networks;evolution of cooperation;influencing social networks",
    "Title": "Theory of Cooperation in Complex Social Networks",
    "Topics10": "",
    "Topics1": "GTEP: Game Theory",
    "Topics2": "GTEP: Coordination and Collaboration",
    "Topics3": "GTEP: Equilibrium",
    "Topics4": "MAS: Agent-based Simulation and Emergent Behavior",
    "Topics5": "MAS: Coordination and Collaboration",
    "Topics6": "MAS: Evaluation and Analysis (Multiagent Systems)",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Game Theory;GTEP: Coordination and Collaboration;GTEP: Equilibrium;MAS: Agent-based Simulation and Emergent Behavior;MAS: Coordination and Collaboration;MAS: Evaluation and Analysis (Multiagent Systems)"
  },
  {
    "Document Index (generated)": 180,
    "Number of Records": 1,
    "Abstract": "Probabilistic inference in statistical relational learning and probabilistic programming can be realised using weighted model counting. Despite a lot of progress, computing weighted model counts exactly is still infeasible for most problems of interest, and one typically has to resort to approximation methods. We contribute a new bounded approximation method for weighted model counting based on probabilistic logic programming principles. Our bounded approximation algorithm is an anytime algorithm that provides lower and upper bounds on the weighted model count. An empirical evaluation on probabilistic logic programs shows that our approach is effective in many cases that are currently beyond the reach of exact methods.",
    "Authors1": "Joris Renkens",
    "Authors2": "Angelika Kimmig",
    "Authors3": "Guy Van den Broeck",
    "Authors4": "Luc De Raedt",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Joris Renkens, Angelika Kimmig, Guy Van den Broeck , Luc De Raedt",
    "Groups1": "Knowledge Representation and Reasoning (KRR)",
    "Groups2": "Reasoning under Uncertainty (RU)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Knowledge Representation and Reasoning (KRR);Reasoning under Uncertainty (RU)",
    "Keywords10": "",
    "Keywords1": "Probabilistic Logic Programming",
    "Keywords2": "Bounded Approximate Inference",
    "Keywords3": "Weighted Model Counting",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Probabilistic Logic Programming;Bounded Approximate Inference;Weighted Model Counting",
    "Title": "Explanation-Based Approximate Weighted Model Counting for Probabilistic Logics",
    "Topics10": "",
    "Topics1": "KRR: Logic Programming",
    "Topics2": "RU: Probabilistic Inference",
    "Topics3": "RU: Relational Probabilistic Models",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "KRR: Logic Programming;RU: Probabilistic Inference;RU: Relational Probabilistic Models"
  },
  {
    "Document Index (generated)": 181,
    "Number of Records": 1,
    "Abstract": "Valued decision diagrams (VDDs) are languages that represent functions mapping variable-value assignments to non-negative real numbers. They prove useful to compile cost functions, utility functions, or probability distributions. While the complexity of some queries (notably optimization) and transformations (notably conditioning) on VDD languages has been known for some time, there remain many significant queries and transformations, such as the various kinds of cuts, marginalizations, and combinations, the complexity of which has not been identified so far. This paper contributes to filling this gap and completing previous results about the time and space efficiency of VDD languages, thus leading to a knowledge compilation map for real-valued functions. Our results show that many tasks that are hard on valued CSPs are actually tractable on VDDs.",
    "Authors1": "Helene Fargier",
    "Authors2": "Pierre Marquis",
    "Authors3": "Alex",
    "Authors4": "re Niveau",
    "Authors5": "Nicolas Schmidt",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Helene Fargier, Pierre Marquis, Alex,re Niveau , Nicolas Schmidt",
    "Groups1": "Knowledge Representation and Reasoning (KRR)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Knowledge Representation and Reasoning (KRR)",
    "Keywords10": "",
    "Keywords1": "Decision Diagrams (ADD - AADD - OBDD - SLDD)",
    "Keywords2": "Knowledge Compilation",
    "Keywords3": "Complexity",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Decision Diagrams (ADD - AADD - OBDD - SLDD);Knowledge Compilation;Complexity",
    "Title": "A Knowledge Compilation Map for Ordered Real-Valued Decision Diagrams",
    "Topics10": "",
    "Topics1": "KRR: Computational Complexity of Reasoning",
    "Topics2": "KRR: Knowledge Representation Languages",
    "Topics3": "KRR: Preferences",
    "Topics4": "SCS: Constraint Optimization",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "KRR: Computational Complexity of Reasoning;KRR: Knowledge Representation Languages;KRR: Preferences;SCS: Constraint Optimization"
  },
  {
    "Document Index (generated)": 182,
    "Number of Records": 1,
    "Abstract": "In the Shift Bribery problem, we are given an election (based on preference orders), a preferred candidate p, and a budget. The goal is to ensure that p wins by shifting p higher in some voters' preference orders. However, each such shift request comes at a price (depending on the voter and on the extent of the shift) and we must not exceed the given budget. We study the parameterized computational complexity of Shift Bribery with respect to a number of parameters (pertaining to the nature of the solution sought and the size of the election) and several classes of price functions. When we parameterize Shift Bribery by the number of affected voters, then for each of our voting rules (Borda, Maximin, Copeland) the problem is W[2]-hard. If, instead, we parameterize by the number of positions by which p is shifted in total, then the problem is fixed-parameter tractable for Borda and Maximin, and is W[1]-hard for Copeland. If we parameterize by the budget for the cost of shifting, then the results depend on the price function class. We also show that Shift Bribery tends to be tractable when parameterized by the number of voters, but that the results for the number of candidates are more enigmatic.",
    "Authors1": "Robert Bredereck",
    "Authors2": "Jiehua Chen",
    "Authors3": "Piotr Faliszewski",
    "Authors4": "André Nichterlein",
    "Authors5": "Rolf Niedermeier",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Robert Bredereck, Jiehua Chen, Piotr Faliszewski, André Nichterlein , Rolf Niedermeier",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "Multiagent Systems (MAS)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP);Multiagent Systems (MAS)",
    "Keywords10": "",
    "Keywords1": "preferenced-based voting",
    "Keywords2": "campaign management",
    "Keywords3": "computational (in)tractability",
    "Keywords4": "parameterized complexity analysis",
    "Keywords5": "approximation",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "preferenced-based voting;campaign management;computational (in)tractability;parameterized complexity analysis;approximation",
    "Title": "Prices Matter for the Parameterized Complexity of Shift Bribery",
    "Topics10": "",
    "Topics1": "GTEP: Game Theory",
    "Topics2": "GTEP: Social Choice / Voting",
    "Topics3": "MAS: E-Commerce",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Game Theory;GTEP: Social Choice / Voting;MAS: E-Commerce"
  },
  {
    "Document Index (generated)": 183,
    "Number of Records": 1,
    "Abstract": "An activity recognition system tries to analyze measurements of activities of daily living (ADLs) and automatically recognize whether someone is sitting, walking or running. Most of the existing approaches either have to rely on a model trained by a preselected and manually labeled set of activities, or perform micro-pattern analysis method, which requires manual selection of the lengths and the number of micro-patterns. Because real life ADL datasets are massive, the cost associated with these manual efforts is too high. As a result, these approaches limit the discovery of ADL patterns from real life datasets in a scalable way.\n\nWe propose a novel approach to extract meaningful patterns found in time-series ADL data. We use a matrix decomposition method to isolate routines and deviations to obtain two different sets of clusters. We obtain the final memberships via the cross product of these sets. We validate our approach using two real-life ADL datasets and a well-known artificial dataset. Based on average silhouette width scores, our approach can capture strong structures in the underlying data. Furthermore, results show that our approach improves on the accuracy of the baseline algorithms by 12% with a statistical significance (p<0.05) using the Wilcoxon signed-rank comparison test.",
    "Authors1": "Onur Yuruten",
    "Authors2": "Jiyong Zhang",
    "Authors3": "Pearl Pu",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Onur Yuruten, Jiyong Zhang , Pearl Pu",
    "Groups1": "Machine Learning Applications (MLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Machine Learning Applications (MLA)",
    "Keywords10": "",
    "Keywords1": "activity recognition",
    "Keywords2": "activities of daily living",
    "Keywords3": "time series clustering",
    "Keywords4": "low rank and sparse matrix decomposition",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "activity recognition;activities of daily living;time series clustering;low rank and sparse matrix decomposition",
    "Title": "Decomposing Activities of Daily Living to Discover Routine Clusters",
    "Topics10": "",
    "Topics1": "MLA: Applications of Unsupervised Learning",
    "Topics2": "MLA: Machine Learning Applications (General/other)",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "MLA: Applications of Unsupervised Learning;MLA: Machine Learning Applications (General/other)"
  },
  {
    "Document Index (generated)": 184,
    "Number of Records": 1,
    "Abstract": "We present an algorithm for identity inference using only the information from the hair. Face recognition in the wild (i.e., unconstrained settings) is highly useful in a variety of applications, but performance suffers due to many factors, e.g., obscured face, lighting variation, extreme pose angle, and expression. It is well known that humans use hair information to guide identity decisions under many of these scenarios due to either the consistent hair appearance of the same subject or obvious hair discrepancy of different subjects, but little work exists to replicate this intelligence artificially. We propose a learned hair matcher using shape, color, and texture features derived from localized patches through an AdaBoost technique with abstaining weak classifiers when features are not present in the given location. The proposed hair matcher achieves 71.53% accuracy on the LFW View 2 dataset. Hair also reduces the error of a COTS face matcher through simple score-level fusion by 5.7%.",
    "Authors1": "Joseph Roth",
    "Authors2": "Xiaoming Liu",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Joseph Roth , Xiaoming Liu",
    "Groups1": "Vision (VIS)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Vision (VIS)",
    "Keywords10": "",
    "Keywords1": "Vision",
    "Keywords2": "Biometrics",
    "Keywords3": "Face Recognition",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Vision;Biometrics;Face Recognition",
    "Title": "On Hair Recognition in the Wild by Machine",
    "Topics10": "",
    "Topics1": "VIS: Face and Gesture Recognition",
    "Topics2": "VIS: Statistical Methods and Learning",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "VIS: Face and Gesture Recognition;VIS: Statistical Methods and Learning"
  },
  {
    "Document Index (generated)": 185,
    "Number of Records": 1,
    "Abstract": "Mapping relational data to RDF is an important task for the development of the\nSemantic Web. To this end, the W3C has recently released a Recommendation for\nthe so-called direct mapping of relational data to RDF. In this work, we \npropose an enrichment of the direct mapping to make it more faithful by \ntransferring also semantic information present in the relational schema from \nthe relational world to the RDF world. We thus introduce expressive \nidentification constraints to capture functional dependencies and define an \nRDF Normal Form, which precisely captures the classical Boyce-Codd Normal Form \nof relational schemas.",
    "Authors1": "Diego Calvanese",
    "Authors2": "Wolfgang Fischl",
    "Authors3": "Reinhard Pichler",
    "Authors4": "Emanuel Sallinger",
    "Authors5": "Mantas Simkus",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Diego Calvanese, Wolfgang Fischl, Reinhard Pichler, Emanuel Sallinger , Mantas Simkus",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "Knowledge Representation and Reasoning (KRR)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW);Knowledge Representation and Reasoning (KRR)",
    "Keywords10": "",
    "Keywords1": "identification constraints",
    "Keywords2": "functional dependencies",
    "Keywords3": "normal forms",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "identification constraints;functional dependencies;normal forms",
    "Title": "Capturing Relational Schemas and Functional Dependencies in RDFS",
    "Topics10": "",
    "Topics1": "AIW: Ontologies and the web: creation, extraction, evolution, mapping, merging, and alignment",
    "Topics2": "tags and folksonomies",
    "Topics3": "KRR: Description Logics",
    "Topics4": "KRR: Knowledge Representation (General/Other)",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: Ontologies and the web: creation, extraction, evolution, mapping, merging, and alignment; tags and folksonomies;KRR: Description Logics;KRR: Knowledge Representation (General/Other)"
  },
  {
    "Document Index (generated)": 186,
    "Number of Records": 1,
    "Abstract": "Core-guided approaches to solving MaxSat have proved to be  effective on industrial problems containing hard clauses and  weighted soft clauses (weighted partial MaxSat or WPM). These  approaches solve WPM problems by building a sequence of new WPM formulas, where in each formula a greater weight of soft clauses can be relaxed. Relaxation of the soft clauses is achieved via the addition of blocking variables to the soft clauses, along with constraints on these blocking variables. In this work we propose an alternative approach. Our approach also builds a sequence of new WPM formulas. However, these formulas are constructed using MaxSat resolution, a sound rule of inference for MaxSat. MaxSat resolution can in the worst case cause a quadratic blowup in the formula, so we propose a new compressed version of MaxSat resolution. Using compressed MaxSat resolution our new core-guided solver improves the state-of-the-art solving significantly more problems than other state-of-the-art solvers on the industrial benchmarks used in the 2013 MaxSat Solver Evaluation.",
    "Authors1": "Nina Narodytska",
    "Authors2": "Fahiem Bacchus",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Nina Narodytska , Fahiem Bacchus",
    "Groups1": "Search and Constraint Satisfaction (SCS)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Search and Constraint Satisfaction (SCS)",
    "Keywords10": "",
    "Keywords1": "maximum satisfiability",
    "Keywords2": "maxsat resolution",
    "Keywords3": "iterative SAT solving",
    "Keywords4": "weighted partial MaxSAT",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "maximum satisfiability;maxsat resolution;iterative SAT solving;weighted partial MaxSAT",
    "Title": "Maximum Satisfiability using core-guided MaxSAT Resolution",
    "Topics10": "",
    "Topics1": "SCS: Constraint Optimization",
    "Topics2": "SCS: SAT and CSP: Evaluation and Analysis",
    "Topics3": "SCS: SAT and CSP: Solvers and Tools",
    "Topics4": "SCS: Satisfiability (General/Other)",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "SCS: Constraint Optimization;SCS: SAT and CSP: Evaluation and Analysis;SCS: SAT and CSP: Solvers and Tools;SCS: Satisfiability (General/Other)"
  },
  {
    "Document Index (generated)": 187,
    "Number of Records": 1,
    "Abstract": "The conventional statistical machine translation (SMT) methods perform the decoding process by compositing a set of the translation rules which have the highest probability. However, the probabilities of the translation rules are calculated only according to the cooccurrence statistics in the bilingual corpus rather than the semantic meaning similarity. In this paper, we propose a Recursive Neural Network (RNN) based model that converts each translation rule into a compact real-valued vector in the semantic embedding space and performs the decoding process by minimizing the semantic gap between the source language string and its translation candidates at each state in a bottom-up structure. The RNN-based translation model is trained using a max-margin objective function. Extensive experiments on Chinese-to-English translation show that our RNN-based model can significantly improve the translation quality by up to 1.68 BLEU score.",
    "Authors1": "Jiajun Zhang",
    "Authors2": "",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Jiajun Zhang",
    "Groups1": "NLP and Knowledge Representation (NLPKR)",
    "Groups2": "NLP and Machine Learning (NLPML)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "NLP and Knowledge Representation (NLPKR);NLP and Machine Learning (NLPML)",
    "Keywords10": "",
    "Keywords1": "Statistical Machine Translation",
    "Keywords2": "Semantic Phrase Representation",
    "Keywords3": "Recursive Neural Networks",
    "Keywords4": "Semantic Gap Minimization",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Statistical Machine Translation;Semantic Phrase Representation;Recursive Neural Networks;Semantic Gap Minimization",
    "Title": "Mind the Gap: Machine Translation by Minimizing the Semantic Gap in Embedding Space",
    "Topics10": "",
    "Topics1": "NLPKR: Natural Language Processing (General/Other)",
    "Topics2": "NLPML: Natural Language Processing (General/Other)",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NLPKR: Natural Language Processing (General/Other);NLPML: Natural Language Processing (General/Other)"
  },
  {
    "Document Index (generated)": 188,
    "Number of Records": 1,
    "Abstract": "We develop a fast approximation algorithm called rounded dynamic programming (RDP) for stochastic network design problems on directed trees. The underlying model describes phenomena that spread away from the root of a tree, for example, the spread of influence in a hierarchical organization or fish in a river network. Actions can be taken to intervene in the network—for some cost—to increase the probability of propagation along an edge. Our algorithm selects a set of actions to maximize the overall spread in the network under a limited budget. We prove that the algorithm is a fully polynomial-time approximation scheme (FPTAS), that is, it finds (1−ε)-optimal solutions in time polynomial in the input size and 1/ε. We apply the algorithm to an important motivating problem in Computational Sustainability: that of efficiently allocating funds to remove barriers in a river network so fish can reach greater portions of their native range. Our experiments show that our algorithm is able to produce near- optimal solutions much faster than an existing technique.",
    "Authors1": "Xiaojian Wu",
    "Authors2": "Daniel Sheldon",
    "Authors3": "Shlomo Zilberstein",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Xiaojian Wu, Daniel Sheldon , Shlomo Zilberstein",
    "Groups1": "Computational Sustainability and AI (CSAI)",
    "Groups2": "Heuristic Search and Optimization (HSO)",
    "Groups3": "Planning and Scheduling (PS)",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Computational Sustainability and AI (CSAI);Heuristic Search and Optimization (HSO);Planning and Scheduling (PS)",
    "Keywords10": "",
    "Keywords1": "stochastic network design",
    "Keywords2": "dynamic programming",
    "Keywords3": "barrier removal",
    "Keywords4": "river networks",
    "Keywords5": "influence maximization",
    "Keywords6": "stochastic optimization",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "stochastic network design;dynamic programming;barrier removal;river networks;influence maximization;stochastic optimization",
    "Title": "Rounded Dynamic Programming for Tree-Structured Stochastic Network Design",
    "Topics10": "",
    "Topics1": "CSAI: Modeling and prediction of dynamic and spatiotemporal phenomena and systems",
    "Topics2": "CSAI: Control and optimization of dynamic and spatiotemporal systems",
    "Topics3": "CSAI: Network modeling, prediction, and optimization.",
    "Topics4": "HSO: Optimization",
    "Topics5": "PS: Probabilistic Planning",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "CSAI: Modeling and prediction of dynamic and spatiotemporal phenomena and systems;CSAI: Control and optimization of dynamic and spatiotemporal systems;CSAI: Network modeling, prediction, and optimization.;HSO: Optimization;PS: Probabilistic Planning"
  },
  {
    "Document Index (generated)": 189,
    "Number of Records": 1,
    "Abstract": "Information elicitation mechanisms represent an important component of many information aggregation techniques, such as product reviews, community sensing, or opinion polls. We propose a novel mechanism that elicits both private signals and beliefs. The mechanism extends the previous versions of the Bayesian Truth Serums (the original BTS, the RBTS, and the multi-valued BTS), by allowing small populations and non-binary private signals, while not requiring additional assumptions on the belief updating process. For priors that are sufficiently smooth, such as Gaussians, the mechanism allows signals to be continuous.",
    "Authors1": "Goran Radanovic",
    "Authors2": "Boi Faltings",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Goran Radanovic , Boi Faltings",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "Human-Computation and Crowd Sourcing (HCC)",
    "Groups3": "Multiagent Systems (MAS)",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP);Human-Computation and Crowd Sourcing (HCC);Multiagent Systems (MAS)",
    "Keywords10": "",
    "Keywords1": "Mechanism Design",
    "Keywords2": "Information elicitation",
    "Keywords3": "Peer prediction",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Mechanism Design;Information elicitation;Peer prediction",
    "Title": "Incentives for Truthful Information Elicitation of Continuous Signals",
    "Topics10": "",
    "Topics1": "GTEP: Game Theory",
    "Topics2": "GTEP: Equilibrium",
    "Topics3": "GTEP: Imperfect Information",
    "Topics4": "HCC: Game-theoretic mechanism design of incentives for motivation and honest reporting",
    "Topics5": "MAS: E-Commerce",
    "Topics6": "MAS: Mechanism Design",
    "Topics7": "MAS: Multiagent Systems (General/other)",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Game Theory;GTEP: Equilibrium;GTEP: Imperfect Information;HCC: Game-theoretic mechanism design of incentives for motivation and honest reporting;MAS: E-Commerce;MAS: Mechanism Design;MAS: Multiagent Systems (General/other)"
  },
  {
    "Document Index (generated)": 190,
    "Number of Records": 1,
    "Abstract": "The spread of epidemics and malware is commonly modeled by diffusion processes\non networks. Protective interventions such as vaccinations or installing anti-virus software are used to contain their spread. Typically, each node in the network has to decide its own strategy of securing itself, and its benefit depends on which other nodes are secure, making this a natural game-theoretic setting. There has been a lot of work on network security game models, but most of the focus has been either on simplified epidemic models or homogeneous network structure.\n\nWe develop a new formulation for an epidemic containment game, which relies on the\ncharacterization of the SIS model in terms of the spectral radius of the network.\nWe show that, in this model, pure Nash equilibria (NE) always exist, and can be found by a best response strategy. We analyze the complexity of finding NE, and derive rigorous bounds on their costs and the Price of Anarchy or PoA (the ratio of the costs of the worst NE to the best NE) in general graphs as well as in random graph models. In particular, for arbitrary power-law graphs with exponent $\\beta>2$, we show that the PoA is bounded by $O(T^{2(\\beta-1)})$, where $T=\\gamma/\\alpha$ is the ratio of the recovery rate to the transmission rate in the SIS model.\nFor the Chung-Lu random power-law graph model, we prove this bound is tight for the PoA. We study the characteristics of Nash equilibria empirically in different real communication and infrastructure networks, and find that our analytical results can help explain some of the empirical observations.",
    "Authors1": "Sudip Saha",
    "Authors2": "Abhijin Adiga",
    "Authors3": "Anil Kumar S. Vullikanti",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Sudip Saha, Abhijin Adiga , Anil Kumar S. Vullikanti",
    "Groups1": "Applications (APP)",
    "Groups2": "Computational Sustainability and AI (CSAI)",
    "Groups3": "Game Theory and Economic Paradigms (GTEP)",
    "Groups4": "Multiagent Systems (MAS)",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Applications (APP);Computational Sustainability and AI (CSAI);Game Theory and Economic Paradigms (GTEP);Multiagent Systems (MAS)",
    "Keywords10": "game theory",
    "Keywords1": "network security game",
    "Keywords2": "nash equilibria",
    "Keywords3": "malware propagation",
    "Keywords4": "epidemic control",
    "Keywords5": "security",
    "Keywords6": "protection",
    "Keywords7": "network infection",
    "Keywords8": "immunization",
    "Keywords9": "graph theory",
    "Keywords": "network security game;nash equilibria;malware propagation;epidemic control;security;protection;network infection;immunization;graph theory;game theory;spectral radius",
    "Title": "Equilibria in Epidemic Containment Games",
    "Topics10": "",
    "Topics1": "APP: Security and Privacy",
    "Topics2": "CSAI: Modeling the interactions of agents with different and often conflicting interests",
    "Topics3": "GTEP: Game Theory",
    "Topics4": "GTEP: Equilibrium",
    "Topics5": "MAS: Evaluation and Analysis (Multiagent Systems)",
    "Topics6": "MAS: Multiagent Systems (General/other)",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "APP: Security and Privacy;CSAI: Modeling the interactions of agents with different and often conflicting interests;GTEP: Game Theory;GTEP: Equilibrium;MAS: Evaluation and Analysis (Multiagent Systems);MAS: Multiagent Systems (General/other)"
  },
  {
    "Document Index (generated)": 191,
    "Number of Records": 1,
    "Abstract": "Gambles in casinos are usually set up so that the casino makes a profit in expectation---as long as gamblers play honestly. However, some gamblers are able to cheat, reducing the casino's profit. How should the casino address this? A common strategy is to selectively kick gamblers out, possibly even without being sure that they were cheating. In this paper, we address the following question. Based solely on a gambler's track record, when is it optimal for the casino to kick the gambler out? Because cheaters will adapt to the casino's policy, this is a game-theoretic question. Specifically, we model the problem as a Bayesian game in which the casino is a Stackelberg leader that can commit to a (possibly randomized) policy for when to kick gamblers out, and provide efficient algorithms for computing the optimal policy.\nBesides being potentially useful to casinos, we imagine that similar techniques could be useful for addressing related problems---for example, illegal trades in financial markets.",
    "Authors1": "Troels Bjerre Sørensen",
    "Authors2": "Melissa Dalis",
    "Authors3": "Joshua Letchford",
    "Authors4": "Dmytro Korzhyk",
    "Authors5": "Vincent Conitzer",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Troels Bjerre Sørensen, Melissa Dalis, Joshua Letchford, Dmytro Korzhyk , Vincent Conitzer",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "Multiagent Systems (MAS)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP);Multiagent Systems (MAS)",
    "Keywords10": "",
    "Keywords1": "Security",
    "Keywords2": "Stackelberg",
    "Keywords3": "Gambling",
    "Keywords4": "Game Theory",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Security;Stackelberg;Gambling;Game Theory",
    "Title": "Beat the Cheater: Computing Game-Theoretic Strategies for When to Kick a Gambler out of a Casino",
    "Topics10": "",
    "Topics1": "GTEP: Game Theory",
    "Topics2": "GTEP: Equilibrium",
    "Topics3": "GTEP: Imperfect Information",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Game Theory;GTEP: Equilibrium;GTEP: Imperfect Information"
  },
  {
    "Document Index (generated)": 192,
    "Number of Records": 1,
    "Abstract": "We investigate elections that are simultaneously single-peaked and single-crossing\n(SPSC). We show that the domain of 1-dimensional Euclidean elections (where voters and candidates are points on the real line, and each voter prefers the candidates that are close to her to the ones that are further away) is a proper subdomain of the SPSC domain, by constructing an election that is single-peaked and single-crossing, but not 1-Euclidean. We then establish a connection between narcissistic elections (where each candidate is ranked first by at least one voter), single-peaked elections and single-crossing elections, by showing that an election is SPSC if and only if it can be obtained from a narcissistic single-crossing election by deleting voters. We use this characterization to show that the SPSC domain admits an efficient algorithm for a problem in fully proportional representation.",
    "Authors1": "Edith Elkind",
    "Authors2": "Piotr Faliszewski",
    "Authors3": "Piotr Skowron",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Edith Elkind, Piotr Faliszewski , Piotr Skowron",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "Multiagent Systems (MAS)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP);Multiagent Systems (MAS)",
    "Keywords10": "",
    "Keywords1": "elections",
    "Keywords2": "voting",
    "Keywords3": "single-peaked",
    "Keywords4": "single-crossing",
    "Keywords5": "1-Euclidean",
    "Keywords6": "proportional representation",
    "Keywords7": "Monroe",
    "Keywords8": "algorithms",
    "Keywords9": "",
    "Keywords": "elections;voting;single-peaked;single-crossing;1-Euclidean;proportional representation;Monroe;algorithms",
    "Title": "A Characterization of the Single-Peaked Single-Crossing Domain",
    "Topics10": "",
    "Topics1": "GTEP: Game Theory",
    "Topics2": "GTEP: Social Choice / Voting",
    "Topics3": "MAS: E-Commerce",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Game Theory;GTEP: Social Choice / Voting;MAS: E-Commerce"
  },
  {
    "Document Index (generated)": 193,
    "Number of Records": 1,
    "Abstract": "Bi-objective combinatorial optimization problems are ubiquitous in real-world applications and designing approaches to solve them efficiently is an important research area of Artificial Intelligence. In Constraint Programming, the recently introduced bi-objective Pareto constraint allows one to solve bi-objective combinatorial optimization problems exactly. Using this constraint, every non-dominated solution is collected in a single tree-search while pruning sub-trees that cannot lead to a non-dominated solution. This paper introduces a simpler and more efficient filtering algorithm for the bi-objective Pareto constraint. The efficiency of our algorithm is experimentally confirmed on classical bi-objective benchmarks.",
    "Authors1": "Renaud Hartert",
    "Authors2": "Pierre Schaus",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Renaud Hartert , Pierre Schaus",
    "Groups1": "Search and Constraint Satisfaction (SCS)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Search and Constraint Satisfaction (SCS)",
    "Keywords10": "",
    "Keywords1": "Constraint Programming",
    "Keywords2": "Bi-Objective Combinatorial Optimization",
    "Keywords3": "Global Constraint",
    "Keywords4": "Pareto Constraint",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Constraint Programming;Bi-Objective Combinatorial Optimization;Global Constraint;Pareto Constraint",
    "Title": "A Support-Based Algorithm for the Bi-Objective Pareto Constraint",
    "Topics10": "",
    "Topics1": "SCS: Constraint Satisfaction",
    "Topics2": "SCS: Constraint Optimization",
    "Topics3": "SCS: Global Constraints",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "SCS: Constraint Satisfaction;SCS: Constraint Optimization;SCS: Global Constraints"
  },
  {
    "Document Index (generated)": 194,
    "Number of Records": 1,
    "Abstract": "Multi-label learning concerns learning multiple, overlapping, and correlated classes. In this paper, we adapt a recent structured prediction framework called HC-Search for multi-label prediction problems. One of the main advantages of this framework is that its training is sensitive to the loss function, unlike the other multi-label approaches that either assume a specific loss function or require a manual adaptation to each loss function. We empirically evaluate our instantiation of the HC-Search framework along with many existing multi-label learning algorithms on a variety of benchmarks by employing diverse task loss functions. Our results demonstrate that the performance of existing algorithms tends to be very similar in most cases, and that the HC-Search approach is comparable and often better than all other algorithms across different loss functions.",
    "Authors1": "Janardhan Rao Doppa",
    "Authors2": "Jun Yu",
    "Authors3": "Chao Ma",
    "Authors4": "Alan Fern",
    "Authors5": "Prasad Tadepalli",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Janardhan Rao Doppa, Jun Yu, Chao Ma, Alan Fern , Prasad Tadepalli",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "Supervised Learning",
    "Keywords2": "Multi-Label Classification",
    "Keywords3": "Structured Prediction",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Supervised Learning;Multi-Label Classification;Structured Prediction",
    "Title": "HC-Search for Multi-Label Prediction: An Empirical Study",
    "Topics10": "",
    "Topics1": "NMLA: Supervised Learning (Other)",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Supervised Learning (Other)"
  },
  {
    "Document Index (generated)": 195,
    "Number of Records": 1,
    "Abstract": "Cross-lingual text classification is the task of assigning labels to a given document in a label-scarce target language by using a prediction model trained with labeled documents from a label-rich source language, which is popularly studied in the natural language processing area as it can largely decrease the expensive manual annotation effort in the target language. In this work, we proposed a novel semi-supervised representation learning approach to address this challenging task, which discovers interlingual features by simultaneously performing semi-supervised matrix completion. To evaluate the proposed learning technique, we conducted extensive experiments on eighteen cross language sentiment classification tasks with four different languages. The empirical results demonstrated the efficacy of our approach and outperformed the other comparison methods.",
    "Authors1": "Min Xiao",
    "Authors2": "Yuhong Guo",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Min Xiao , Yuhong Guo",
    "Groups1": "Machine Learning Applications (MLA)",
    "Groups2": "Novel Machine Learning Algorithms (NMLA)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Machine Learning Applications (MLA);Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "cross lingual classification",
    "Keywords2": "semi-supervised learning",
    "Keywords3": "matrix completion",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "cross lingual classification;semi-supervised learning;matrix completion",
    "Title": "Semi-supervised Matrix Completion for Cross-Lingual Text Classification",
    "Topics10": "",
    "Topics1": "MLA: Machine Learning Applications (General/other)",
    "Topics2": "NMLA: Classification",
    "Topics3": "NMLA: Semisupervised Learning",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "MLA: Machine Learning Applications (General/other);NMLA: Classification;NMLA: Semisupervised Learning"
  },
  {
    "Document Index (generated)": 196,
    "Number of Records": 1,
    "Abstract": "Many AI applications need to explicitly represent the relational structure as well as handle uncertainty. First order probabilistic models combine the power of logic and probability to deal with such domains. A naive approach to inference in these models is to propositionalize the whole theory and carry out the inference on the ground network. Lifted inference techniques (such as Lifted Belief Propagation; Singla & Domingos, 2008) provide a scalable approach to inference by combining together groups of objects which behave identically. In many cases, constructing the lifted network can itself be quite costly. In addition, the exact lifted network is often very close in size to the fully propositionalized model. To overcome these problems, we present approximate lifted inference, which groups together similar but distinguishable objects and treats them as if they were identical. Early stopping terminates the execution of the lifted network construction at an early stage resulting in a coarser network. Noise tolerant hypercubes allow for marginal errors in the representation of the lifted network itself. Both of our algorithms can significantly speed-up the process of lifted network construction as well as result in much smaller models. The coarseness of the approximation can be adjusted depending on the accuracy required, and we can bound the resulting error. Extensive evaluation on six domains demonstrates great efficiency gains with only minor (or no) loss in accuracy.",
    "Authors1": "Parag Singla",
    "Authors2": "Aniruddh Nath",
    "Authors3": "Pedro Domingos",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Parag Singla, Aniruddh Nath , Pedro Domingos",
    "Groups1": "Reasoning under Uncertainty (RU)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Reasoning under Uncertainty (RU)",
    "Keywords10": "",
    "Keywords1": "Lifted Inference",
    "Keywords2": "Belief Propagation",
    "Keywords3": "Graphical Models",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Lifted Inference;Belief Propagation;Graphical Models",
    "Title": "Approximate Lifting Techniques for Belief Propagation",
    "Topics10": "",
    "Topics1": "RU: Graphical Models (Other)",
    "Topics2": "RU: Probabilistic Inference",
    "Topics3": "RU: Relational Probabilistic Models",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "RU: Graphical Models (Other);RU: Probabilistic Inference;RU: Relational Probabilistic Models"
  },
  {
    "Document Index (generated)": 197,
    "Number of Records": 1,
    "Abstract": "The generation of high quality query plans is at the heart of query processing in traditional database management systems as well as in heterogeneous distributed data sources on corporate intranets and in the cloud. A diversity of techniques are employed for query plan generation and optimization, many of them proprietary. In this paper we revisit the problem of generating a query plan using AI automated planning. Characterizing query planning as AI planning enables us to leverage state-of-the-art planning techniques -- techniques which have proven to be highly effective for a diversity of dynamical reasoning tasks. While our long-term view is broad, here our efforts focus on the specific problem of cost-based join-order optimization, a central component of production-quality query optimizers. We characterize the general query planning problem as a delete-free planning problem, and query plan optimization as a context-sensitive cost-optimal planning problem. We propose algorithms that generate high quality query plans, guaranteeing optimality under certain conditions. Our approach is general, supporting the use of a broad suite of domain-independent and domain-specific optimization criteria. Experimental results demonstrate the effectiveness of AI planning techniques for query plan generation and optimization.",
    "Authors1": "Nathan Robinson",
    "Authors2": "Sheila Mcilraith",
    "Authors3": "David Toman",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Nathan Robinson, Sheila Mcilraith , David Toman",
    "Groups1": "Knowledge Representation and Reasoning (KRR)",
    "Groups2": "Planning and Scheduling (PS)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Knowledge Representation and Reasoning (KRR);Planning and Scheduling (PS)",
    "Keywords10": "",
    "Keywords1": "relational query optimization",
    "Keywords2": "delete-free planning",
    "Keywords3": "cost-optimal planning",
    "Keywords4": "heuristic search",
    "Keywords5": "applications of planning",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "relational query optimization;delete-free planning;cost-optimal planning;heuristic search;applications of planning",
    "Title": "Cost-Based Query Optimization via AI Planning",
    "Topics10": "",
    "Topics1": "KRR: Knowledge Representation (General/Other)",
    "Topics2": "PS: Deterministic Planning",
    "Topics3": "PS: Planning (General/Other)",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "KRR: Knowledge Representation (General/Other);PS: Deterministic Planning;PS: Planning (General/Other)"
  },
  {
    "Document Index (generated)": 198,
    "Number of Records": 1,
    "Abstract": "Current electricity tariffs do not reflect the real cost that customers incur to suppliers, as units are charged at the same rate, regardless of how predictable each customer's consumption is. A recent proposal to address this problem are prediction-of-use tariffs. In such tariffs, a customer is asked in advance to predict her future consumption, and is charged based both on her actual consumption and the deviation from her prediction. Prior work studied the cost game induced by a single such tariff, and showed consumers would have an incentive to minimize their risk, by joining together when buying electricity as a grand coalition. In this work we study the efficient (i.e. cost-minimizing) structure of buying groups for the more realistic setting when multiple, competing prediction-of-use tariffs are available. We propose a polynomial time algorithm to compute efficient buyer groups, and validate our approach experimentally, using a large-scale data set of domestic electricity consumers in the UK.",
    "Authors1": "Valentin Robu",
    "Authors2": "Meritxell Vinyals",
    "Authors3": "Alex Rogers",
    "Authors4": "Nick Jennings",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Valentin Robu, Meritxell Vinyals, Alex Rogers , Nick Jennings",
    "Groups1": "Computational Sustainability and AI (CSAI)",
    "Groups2": "Game Theory and Economic Paradigms (GTEP)",
    "Groups3": "Multiagent Systems (MAS)",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Computational Sustainability and AI (CSAI);Game Theory and Economic Paradigms (GTEP);Multiagent Systems (MAS)",
    "Keywords10": "",
    "Keywords1": "electricity tariff",
    "Keywords2": "group buying",
    "Keywords3": "smart grid",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "electricity tariff;group buying;smart grid",
    "Title": "Efficient buyer groups for prediction-of-use electricity tariffs",
    "Topics10": "",
    "Topics1": "CSAI: Modeling the interactions of agents with different and often conflicting interests",
    "Topics2": "CSAI: Support for public engagement and decision making by the public",
    "Topics3": "GTEP: Coordination and Collaboration",
    "Topics4": "MAS: Coordination and Collaboration",
    "Topics5": "MAS: Evaluation and Analysis (Multiagent Systems)",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "CSAI: Modeling the interactions of agents with different and often conflicting interests;CSAI: Support for public engagement and decision making by the public;GTEP: Coordination and Collaboration;MAS: Coordination and Collaboration;MAS: Evaluation and Analysis (Multiagent Systems)"
  },
  {
    "Document Index (generated)": 199,
    "Number of Records": 1,
    "Abstract": "Given a CNF formula and a weight for each assignment of values to\nvariables, two natural problems are weighted model counting and\ndistribution-aware sampling of satisfying assignments.  Both problems \nhave a wide variety of important applications.  Due to the inherent\ncomplexity of the exact versions of the problems, interest has focused\non solving them approximately.  Prior work in this area scaled only to\nsmall problems in practice, or failed to provide strong theoretical\nguarantees, or employed a computationally-expensive maximum a poste-\nriori probability (MAP) oracle that assumes prior knowledge of a\nfactored representation of the weight distribution.  We present a\nnovel approach that works with a black-box oracle for weights of\nassignments and requires only an {\\NP}-oracle to solve both the\ncounting and sampling problems.  Our approach works \nunder mild assumptions on the distribution of weights of satisfying\nassignments, provides strong theoretical guarantees, and scales to\nproblems involving several thousand variables. We also show that the\nassumptions can be significantly relaxed if a factored representation \nof the weights is known.",
    "Authors1": "Supratik Chakraborty",
    "Authors2": "Daniel J. Fremont",
    "Authors3": "Kuldeep S. Meel",
    "Authors4": "Sanjit A. Seshia",
    "Authors5": "Moshe Vardi",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Supratik Chakraborty, Daniel J. Fremont, Kuldeep S. Meel, Sanjit A. Seshia , Moshe Vardi",
    "Groups1": "Search and Constraint Satisfaction (SCS)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Search and Constraint Satisfaction (SCS)",
    "Keywords10": "",
    "Keywords1": "Weighted Model Counting",
    "Keywords2": "Weight Generation",
    "Keywords3": "SAT",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Weighted Model Counting;Weight Generation;SAT",
    "Title": "Distribution-Aware Sampling and Weighted Model Counting for SAT",
    "Topics10": "",
    "Topics1": "SCS: SAT and CSP: Evaluation and Analysis",
    "Topics2": "SCS: SAT and CSP: Solvers and Tools",
    "Topics3": "SCS: Satisfiability (General/Other)",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "SCS: SAT and CSP: Evaluation and Analysis;SCS: SAT and CSP: Solvers and Tools;SCS: Satisfiability (General/Other)"
  },
  {
    "Document Index (generated)": 200,
    "Number of Records": 1,
    "Abstract": "Sequential learning for classification tasks is an effective tool in the machine learning community. In sequential learning settings, algorithms sometimes make incorrect predictions on data that were correctly classified in the past. This paper explicitly deals with such inconsistent prediction behavior. Our main contributions are 1) to experimentally show its effect for user utilities as a human cognitive bias, 2) to formalize a new framework by internalizing this bias into the optimization problem, 3) to develop new algorithms without memorization of the past prediction history, and 4) to show some theoretical guarantees of our derived algorithm for both online and stochastic learning settings. Our experimental results show the superiority of the derived algorithm for problems involving human cognition.",
    "Authors1": "Hidekazu Oiwa",
    "Authors2": "Hiroshi Nakagawa",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Hidekazu Oiwa , Hiroshi Nakagawa",
    "Groups1": "Human-Computation and Crowd Sourcing (HCC)",
    "Groups2": "Novel Machine Learning Algorithms (NMLA)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Human-Computation and Crowd Sourcing (HCC);Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "Machine Learning",
    "Keywords2": "Human Cognitive Bias",
    "Keywords3": "Online Learning",
    "Keywords4": "Stochastic Learning",
    "Keywords5": "Endowment effect",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Machine Learning;Human Cognitive Bias;Online Learning;Stochastic Learning;Endowment effect",
    "Title": "Online and Stochastic Learning with a Human Cognitive Bias",
    "Topics10": "",
    "Topics1": "HCC: Optimality in the context of human computation",
    "Topics2": "NMLA: Classification",
    "Topics3": "NMLA: Online Learning",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "HCC: Optimality in the context of human computation;NMLA: Classification;NMLA: Online Learning"
  },
  {
    "Document Index (generated)": 201,
    "Number of Records": 1,
    "Abstract": "Singleton-based consistencies have been shown to dramatically\n   improve the performance of constraint solvers on some difficult\n   instances. However, they are in general too expensive to be applied\n   exhaustively during the whole search. In this paper, we focus on\n   partition-one-AC, a singleton-based consistency which, as opposed\n   to singleton arc consistency, is able to prune values on all\n   variables at each singleton test.\n   We propose adaptive variants of partition-one-AC that do not\n   necessarily run until having proved the fixpoint. The pruning\n   can be weaker than the full version but the computational effort\n   can be significantly reduced. Our experiments\n   show that adaptive Partition-one-AC can obtain significant speedups over arc\n   consistency and over the full version of partition-one-AC.",
    "Authors1": "Amine Balafrej",
    "Authors2": "Christian Bessiere",
    "Authors3": "Gilles Trombettoni",
    "Authors4": "El Houssine Bouyakhf",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Amine Balafrej, Christian Bessiere, Gilles Trombettoni , El Houssine Bouyakhf",
    "Groups1": "Search and Constraint Satisfaction (SCS)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Search and Constraint Satisfaction (SCS)",
    "Keywords10": "",
    "Keywords1": "CSP",
    "Keywords2": "Singleton-based Consistencies",
    "Keywords3": "Adaptive Consistencies",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "CSP;Singleton-based Consistencies;Adaptive Consistencies",
    "Title": "Adaptive Singleton-based Consistencies",
    "Topics10": "",
    "Topics1": "SCS: Constraint Satisfaction",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "SCS: Constraint Satisfaction"
  },
  {
    "Document Index (generated)": 202,
    "Number of Records": 1,
    "Abstract": "In pickup and delivery problems (PDPs), vehicles pick up and deliver a set of items under various constraints. We extend the well-studied PDP by allowing vehicles to transfer items to and from one another. By scheduling transfers, the fleet of vehicles can deliver the items faster and at lower cost. We introduce the Very Large Neighborhood Search with Transfers (VLNS-T) algorithm to form schedules for PDPs with transfers. We show that VLNS-T algorithm makes use of transfers to improve upon the best known solutions for selected benchmark problems, and demonstrate its effectiveness on real world taxi data in New York City.",
    "Authors1": "Brian Coltin",
    "Authors2": "Manuela Veloso",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Brian Coltin , Manuela Veloso",
    "Groups1": "Planning and Scheduling (PS)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Planning and Scheduling (PS)",
    "Keywords10": "",
    "Keywords1": "scheduling",
    "Keywords2": "transfers",
    "Keywords3": "PDP",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "scheduling;transfers;PDP",
    "Title": "Scheduling for Transfers in Pickup and Delivery Problems with Very Large Neighborhood Search",
    "Topics10": "",
    "Topics1": "HSO: Heuristic Search",
    "Topics2": "HSO: Metareasoning and Metaheuristics",
    "Topics3": "PS: Scheduling",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "HSO: Heuristic Search;HSO: Metareasoning and Metaheuristics;PS: Scheduling"
  },
  {
    "Document Index (generated)": 203,
    "Number of Records": 1,
    "Abstract": "We propose an unsupervised learning algorithm for automatically inferring the mappings between English nouns and corresponding video objects. Given a sequence of natural language instructions and an unaligned video recording, we simultaneously align each instruction to its corresponding video segment, and also align nouns in each instruction to their corresponding objects in video. While existing grounded language acquisition algorithms rely on pre-aligned supervised data (each sentence paired with corresponding image frame or video segment), our algorithm aims to automatically infer the alignment from the temporal structure of the video and parallel text instructions. We propose two generative models that are closely related to the HMM and IBM 1 word alignment models used in statistical machine translation. We evaluate our algorithm on videos of biological experiments performed in wetlabs, and demonstrate its capability of aligning video segments to text instructions and matching video objects to nouns in the absence of any direct supervision.",
    "Authors1": "Iftekhar Naim",
    "Authors2": "Young Song",
    "Authors3": "Qiguang Liu",
    "Authors4": "Henry Kautz",
    "Authors5": "Jiebo Luo",
    "Authors6": "Daniel Gildea",
    "Authors7": "",
    "Authors": "Iftekhar Naim, Young Song, Qiguang Liu, Henry Kautz, Jiebo Luo , Daniel Gildea",
    "Groups1": "Machine Learning Applications (MLA)",
    "Groups2": "NLP and Machine Learning (NLPML)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Machine Learning Applications (MLA);NLP and Machine Learning (NLPML)",
    "Keywords10": "",
    "Keywords1": "Unsupervised Video Alignment",
    "Keywords2": "Grounded Language Acquisition",
    "Keywords3": "HMM",
    "Keywords4": "IBM Model 1",
    "Keywords5": "Language and Vision",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Unsupervised Video Alignment;Grounded Language Acquisition;HMM;IBM Model 1;Language and Vision",
    "Title": "Unsupervised Alignment of Natural Language Instructions with Video Segments",
    "Topics10": "",
    "Topics1": "MLA: Applications of Unsupervised Learning",
    "Topics2": "NLPML: Natural Language Processing (General/Other)",
    "Topics3": "VIS: Language and Vision",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "MLA: Applications of Unsupervised Learning;NLPML: Natural Language Processing (General/Other);VIS: Language and Vision"
  },
  {
    "Document Index (generated)": 204,
    "Number of Records": 1,
    "Abstract": "In this paper we introduce the task of identifying information-dense texts, which report important factual information in direct, succinct manner.  We describe a procedure that allows us to label automatically a large training corpus of New York Times texts. We train a classifier based on lexical, discourse and unlexicalized syntactic features and test its performance on a set of manually annotated articles from international relations, U.S. politics, sports and science domains. Our results indicate that the task is feasible and that  both syntactic and lexical features are highly predictive for the distinction. We observe considerable variation of prediction accuracy across domains and find that domain-specific models are more accurate.",
    "Authors1": "Yinfei Yang",
    "Authors2": "Ani Nenkova",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Yinfei Yang , Ani Nenkova",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "NLP and Knowledge Representation (NLPKR)",
    "Groups3": "NLP and Machine Learning (NLPML)",
    "Groups4": "NLP and Text Mining (NLPTM)",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW);NLP and Knowledge Representation (NLPKR);NLP and Machine Learning (NLPML);NLP and Text Mining (NLPTM)",
    "Keywords10": "",
    "Keywords1": "writing style",
    "Keywords2": "information-dense text",
    "Keywords3": "summarization",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "writing style;information-dense text;summarization",
    "Title": "Detecting information-dense texts in multiple news domains",
    "Topics10": "",
    "Topics1": "AIW: Human language technologies for web systems, including text summarization and machine translation",
    "Topics2": "NLPKR: Semantics and Summarization",
    "Topics3": "NLPML: Text Classification",
    "Topics4": "NLPTM: Natural Language Processing (General/Other)",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: Human language technologies for web systems, including text summarization and machine translation;NLPKR: Semantics and Summarization;NLPML: Text Classification;NLPTM: Natural Language Processing (General/Other)"
  },
  {
    "Document Index (generated)": 205,
    "Number of Records": 1,
    "Abstract": "This paper presents a method for automatically constructing a large comparative commonsense knowledge base from Big Data. The resulting knowledge base is semantically refined and organized. Our method is based on linear optimization methods to clean and consolidate the noisy input knowledge, while also inferring new information. Our method achieves a high precision while maintaining good coverage.",
    "Authors1": "Niket T",
    "Authors2": "on",
    "Authors3": "Gerard de Melo",
    "Authors4": "Gerhard Weikum",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Niket T,on, Gerard de Melo , Gerhard Weikum",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "NLP and Text Mining (NLPTM)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW);NLP and Text Mining (NLPTM)",
    "Keywords10": "",
    "Keywords1": "commonsense knowledge",
    "Keywords2": "information extraction",
    "Keywords3": "word sense disambiguation",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "commonsense knowledge;information extraction;word sense disambiguation",
    "Title": "Smarter Than You Think: Acquiring Comparative Commonsense from the Web",
    "Topics10": "",
    "Topics1": "AIW: Knowledge acquisition from the web",
    "Topics2": "NLPTM: Information Extraction",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: Knowledge acquisition from the web;NLPTM: Information Extraction"
  },
  {
    "Document Index (generated)": 206,
    "Number of Records": 1,
    "Abstract": "The problem of checking the consistency in qualitative calculi that contain both unknown and known entities (constants, i.e., real geometries) has recently appeared and has applications in many areas. Until now, all the approaches are theoretical and no implementation has been proposed. In this paper we present the first reasoner that takes as input RCC-5 or RCC-8 networks that involve entities with specific geometries and decides their consistency. We investigate the performance of the \nreasoner and contrary to lots of other works in this area we consider real datasets in our experimental analysis.",
    "Authors1": "Stella Giannakopoulou",
    "Authors2": "Charalampos Nikolaou",
    "Authors3": "Manolis Koubarakis",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Stella Giannakopoulou, Charalampos Nikolaou , Manolis Koubarakis",
    "Groups1": "Knowledge Representation and Reasoning (KRR)",
    "Groups2": "Reasoning under Uncertainty (RU)",
    "Groups3": "Search and Constraint Satisfaction (SCS)",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Knowledge Representation and Reasoning (KRR);Reasoning under Uncertainty (RU);Search and Constraint Satisfaction (SCS)",
    "Keywords10": "",
    "Keywords1": "Qualitative spatial reasoning",
    "Keywords2": "Constraint Satisfaction Problems",
    "Keywords3": "Landmarks",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Qualitative spatial reasoning;Constraint Satisfaction Problems;Landmarks",
    "Title": "A reasoner for the RCC-5 and RCC-8 calculi extended with constants",
    "Topics10": "",
    "Topics1": "KRR: Computational Complexity of Reasoning",
    "Topics2": "KRR: Geometric, Spatial, and Temporal Reasoning",
    "Topics3": "KRR: Qualitative Reasoning",
    "Topics4": "RU: Uncertainty in AI (General/Other)",
    "Topics5": "SCS: Constraint Satisfaction",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "KRR: Computational Complexity of Reasoning;KRR: Geometric, Spatial, and Temporal Reasoning;KRR: Qualitative Reasoning;RU: Uncertainty in AI (General/Other);SCS: Constraint Satisfaction"
  },
  {
    "Document Index (generated)": 207,
    "Number of Records": 1,
    "Abstract": "In this paper we address the planning problem of a robot searching for multiple residents in a retirement home in order to remind them of an upcoming multi-person recreational activity before a given deadline. We introduce a novel Multi-User Schedule Based (M-USB) Search approach which generates a high-level-plan to maximize the number of residents that are found within the given time frame. From the schedules of the residents, the layout of the retirement home environment as well as direct observations by the robot, we obtain spatio-temporal likelihood functions for the individual residents. The main contribution of our work is the development of a novel approach to compute a reward to find a search plan for the robot using: 1) the likelihood functions, 2) the availabilities of the residents, and 3) the order in which the residents should be found. Simulations were conducted on a floor of a real retirement home to compare our proposed M-USB Search approach to a Weighted Informed Walk and a Random Walk. Our results show that the proposed M-USB Search finds residents in a shorter amount of time by visiting fewer rooms when compared to the other approaches.",
    "Authors1": "Markus Schwenk",
    "Authors2": "Tiago Vaquero",
    "Authors3": "Goldie Nejat",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Markus Schwenk, Tiago Vaquero , Goldie Nejat",
    "Groups1": "Planning and Scheduling (PS)",
    "Groups2": "Reasoning under Uncertainty (RU)",
    "Groups3": "Robotics (ROB)",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Planning and Scheduling (PS);Reasoning under Uncertainty (RU);Robotics (ROB)",
    "Keywords10": "",
    "Keywords1": "Uncertainty in AI",
    "Keywords2": "Probabilistic Planning",
    "Keywords3": "Temporal Planning",
    "Keywords4": "Robotics",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Uncertainty in AI;Probabilistic Planning;Temporal Planning;Robotics",
    "Title": "Schedule-based Robotic Search for Multiple Residents in a Retirement Home Environment",
    "Topics10": "",
    "Topics1": "PS: Probabilistic Planning",
    "Topics2": "PS: Temporal Planning",
    "Topics3": "RU: Uncertainty in AI (General/Other)",
    "Topics4": "ROB: Robotics (General/Other)",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "PS: Probabilistic Planning;PS: Temporal Planning;RU: Uncertainty in AI (General/Other);ROB: Robotics (General/Other)"
  },
  {
    "Document Index (generated)": 208,
    "Number of Records": 1,
    "Abstract": "Automatically solving geometry questions is a long-standing AI\nproblem. A geometry question typically includes a textual description\naccompanied by a diagram.  The first step in solving geometry\nquestions is diagram understanding, which consists of identifying visual\nelements in the diagram, their location, their geometric properties,\nand aligning them to corresponding textual descriptions. In this\npaper, we present a method for diagram understanding that identifies\nvisual elements in a diagram while maximizing agreement between\ntextual and visual data. We show that the method's objective function\nis submodular; thus we are able to introduce an efficient method for\ndiagram understanding that is close to optimal.  To empirically\nevaluate our method, we compile a new dataset of geometry questions\n(textual descriptions and diagrams) and compare with baselines that\nutilize standard vision techniques.  Our experimental evaluation shows\nan F1 boost of more than 17\\% in identifying visual elements and 25\\% in\naligning visual elements with their textual descriptions.",
    "Authors1": "Min Joon Seo",
    "Authors2": "Hannaneh Hajishirzi",
    "Authors3": "Ali Farhadi",
    "Authors4": "Oren Etzioni",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Min Joon Seo, Hannaneh Hajishirzi, Ali Farhadi , Oren Etzioni",
    "Groups1": "Applications (APP)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Applications (APP)",
    "Keywords10": "",
    "Keywords1": "Diagram Understanding",
    "Keywords2": "Submodular Optimization",
    "Keywords3": "Language and Vision",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Diagram Understanding;Submodular Optimization;Language and Vision",
    "Title": "Diagram Understanding in Geometry Problems",
    "Topics10": "",
    "Topics1": "APP: Other Applications",
    "Topics2": "VIS: Language and Vision",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "APP: Other Applications;VIS: Language and Vision"
  },
  {
    "Document Index (generated)": 209,
    "Number of Records": 1,
    "Abstract": "To improve robustness to significant mismatches between\nsource domain and target domain - arising from changes such\nas illumination, pose and image quality - domain adaptation\nis increasingly popular in computer vision. But most of methods\nassume that the source data is from single domain, or that\nmulti-domain datasets provide the domain label for training\ninstances. In practice, most datasets are mixtures of multiple\nlatent domains, and difficult to manually provide the domain\nlabel of each data point. In this paper, we propose a model\nthat automatically discovers latent domains in visual datasets.\nWe first assume the visual images are sampled from multiple\nmanifolds, each of which represents different domain,\nand which are represented by different subspaces. Using the\nneighborhood structure estimated from images belonging to\nthe same category, we approximate the local linear invariant\nsubspace for each image based on its local structure, eliminating\nthe category-specific elements of the feature. Based\non the effectiveness of this representation, we then propose a\nsquared-loss mutual information based clustering model with\ncategory distribution prior in each domain to infer the domain\nassignment for images. In experiment, we test our approach\non two common image datasets, the results show that\nour method outperforms the existing state-of-the-art methods,\nand also show the superiority of multiple latent domain discovery",
    "Authors1": "Caiming Xiong",
    "Authors2": "Scott McCloskey",
    "Authors3": "Jason Corso",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Caiming Xiong, Scott McCloskey , Jason Corso",
    "Groups1": "Machine Learning Applications (MLA)",
    "Groups2": "Novel Machine Learning Algorithms (NMLA)",
    "Groups3": "Vision (VIS)",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Machine Learning Applications (MLA);Novel Machine Learning Algorithms (NMLA);Vision (VIS)",
    "Keywords10": "",
    "Keywords1": "latent model",
    "Keywords2": "local linear subspace",
    "Keywords3": "domain adaptation",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "latent model;local linear subspace;domain adaptation",
    "Title": "Latent Domains Modeling for Domain Adaptation",
    "Topics10": "",
    "Topics1": "MLA: Applications of Unsupervised Learning",
    "Topics2": "MLA: Machine Learning Applications (General/other)",
    "Topics3": "NMLA: Clustering",
    "Topics4": "NMLA: Feature Construction/Reformulation",
    "Topics5": "NMLA: Transfer, Adaptation, Multitask Learning",
    "Topics6": "NMLA: Semisupervised Learning",
    "Topics7": "VIS: Categorization",
    "Topics8": "VIS: Object Recognition",
    "Topics9": "VIS: Statistical Methods and Learning",
    "Topics": "MLA: Applications of Unsupervised Learning;MLA: Machine Learning Applications (General/other);NMLA: Clustering;NMLA: Feature Construction/Reformulation;NMLA: Transfer, Adaptation, Multitask Learning;NMLA: Semisupervised Learning;VIS: Categorization;VIS: Object Recognition;VIS: Statistical Methods and Learning"
  },
  {
    "Document Index (generated)": 210,
    "Number of Records": 1,
    "Abstract": "Automated speech recognition (ASR) technology has been developed to such a level that off-the-shelf distributed speech recognition services are available (free of cost) that allow researchers to integrate speech into their applications with little development effort or expert knowledge leading to better results compared with previously used open-source tools. Often, however, such services do not accept language models or grammars but process free speech from any domain. While results are very good given the enormous size of the search space, results frequently contain out-of-domain words or constructs that cannot be understood by subsequent domain-dependent natural language understanding (NLU) components. In this paper we present a versatile post-processing technique based on phonetic distance that integrates domain knowledge with open-domain ASR results, leading to improved ASR performance. Notably, our technique is able to make use of domain restrictions using various degrees of domain knowledge, ranging from pure vocabulary restrictions via grammars or N-grams to restrictions of the acceptable utterances. We present results for a variety of corpora (mainly from human-robot interaction) where our combined approach significantly outperforms Google ASR as well as a plain open-source ASR solution.",
    "Authors1": "Johannes Twiefel",
    "Authors2": "Timo Baumann",
    "Authors3": "Stefan Heinrich",
    "Authors4": "Stefan Wermter",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Johannes Twiefel, Timo Baumann, Stefan Heinrich , Stefan Wermter",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "Applications (APP)",
    "Groups3": "NLP and Knowledge Representation (NLPKR)",
    "Groups4": "Robotics (ROB)",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW);Applications (APP);NLP and Knowledge Representation (NLPKR);Robotics (ROB)",
    "Keywords10": "",
    "Keywords1": "speech recognition",
    "Keywords2": "phonetics",
    "Keywords3": "domain-dependent knowledge",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "speech recognition;phonetics;domain-dependent knowledge",
    "Title": "Improving Domain-independent Cloud-based Speech Recognition with Domain-dependent Phonetic Post-processing",
    "Topics10": "",
    "Topics1": "AIW: Human language technologies for web systems, including text summarization and machine translation",
    "Topics2": "APP: Intelligent User Interfaces",
    "Topics3": "NLPKR: Natural Language Processing (General/Other)",
    "Topics4": "ROB: Human-Robot Interaction",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: Human language technologies for web systems, including text summarization and machine translation;APP: Intelligent User Interfaces;NLPKR: Natural Language Processing (General/Other);ROB: Human-Robot Interaction"
  },
  {
    "Document Index (generated)": 211,
    "Number of Records": 1,
    "Abstract": "This paper introduces two novel algorithms, SABL and I-SABL, for learning behaviors from human-provided rewards. The primary novelty of these algorithms is that instead of treating the feedback as a numeric reward signal, they interpret feedback as a form of discrete communication that depends on both the behavior the trainer is trying to teach and the teaching strategy used by the trainer.  For example, some humans use a strategy where the lack of feedback may indicate whether the action was correct or incorrect, and interpreting this lack of feedback accurately can significantly improve learning speed. Results from user studies show that 1) humans use a variety of training strategies in practice, and 2) both algorithms can successfully learn a contextual bandit task faster than approaches that treat the feedback as numeric. Additionally, simulated trainers are employed to evaluate the algorithms in both contextual bandit and sequential decision-making domains with similar results.",
    "Authors1": "Robert Loftin",
    "Authors2": "James MacGlashan",
    "Authors3": "Bei Peng",
    "Authors4": "Michael Littman",
    "Authors5": "Matthew E. Taylor",
    "Authors6": "Jeff Huang",
    "Authors7": "David Roberts",
    "Authors": "Robert Loftin, James MacGlashan, Bei Peng, Michael Littman, Matthew E. Taylor, Jeff Huang , David Roberts",
    "Groups1": "Humans and AI (HAI)",
    "Groups2": "Novel Machine Learning Algorithms (NMLA)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Humans and AI (HAI);Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "Learning from Feedback",
    "Keywords2": "Human Computer Interaction",
    "Keywords3": "Reinforcement Learning",
    "Keywords4": "Canine Learning",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Learning from Feedback;Human Computer Interaction;Reinforcement Learning;Canine Learning",
    "Title": "A Strategy-Aware Technique for Learning Behaviors from Discrete Human Feedback",
    "Topics10": "",
    "Topics1": "APP: Philosophical and Ethical Issues",
    "Topics2": "CM: Bayesian Learning",
    "Topics3": "HCC: Active learning from imperfect human labelers",
    "Topics4": "HAI: Human-Computer Interaction",
    "Topics5": "NMLA: Bayesian Learning",
    "Topics6": "NMLA: Reinforcement Learning",
    "Topics7": "ROB: Human-Robot Interaction",
    "Topics8": "",
    "Topics9": "",
    "Topics": "APP: Philosophical and Ethical Issues;CM: Bayesian Learning;HCC: Active learning from imperfect human labelers;HAI: Human-Computer Interaction;NMLA: Bayesian Learning;NMLA: Reinforcement Learning;ROB: Human-Robot Interaction"
  },
  {
    "Document Index (generated)": 212,
    "Number of Records": 1,
    "Abstract": "We analyze and evaluate a generative process for multiple-instance learning (MIL) in which bags are distributions over instances. We show that our generative process contains as special cases generative models explored in prior work, while excluding scenarios known to be hard for MIL. Further, under the mild assumption that every negative instance is observed with nonzero probability in some negative bag, we show that it is possible to learn concepts that accurately label instances from MI data in this setting. Finally, we show that standard supervised approaches can learn concepts with low area-under-ROC error from MI data in this setting. We validate this surprising result with experiments using several real-world MI datasets that have been annotated with instance labels.",
    "Authors1": "Gary Doran",
    "Authors2": "Soumya Ray",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Gary Doran , Soumya Ray",
    "Groups1": "",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "",
    "Keywords10": "",
    "Keywords1": "multiple-instance learning",
    "Keywords2": "supervised learning",
    "Keywords3": "classification",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "multiple-instance learning;supervised learning;classification",
    "Title": "Learning Instance Concepts from Multiple-Instance Data with Bags as Distributions",
    "Topics10": "",
    "Topics1": "NMLA: Evaluation and Analysis (Machine Learning)",
    "Topics2": "NMLA: Supervised Learning (Other)",
    "Topics3": "NMLA: Machine Learning (General/other)",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Evaluation and Analysis (Machine Learning);NMLA: Supervised Learning (Other);NMLA: Machine Learning (General/other)"
  },
  {
    "Document Index (generated)": 213,
    "Number of Records": 1,
    "Abstract": "Exchangeability is a central notion in statistics and probability theory. The assumption that an infinite sequence of data points is exchangeable is at the core of Bayesian statistics. However, finite exchangeability as a statistical property that renders probabilistic inference tractable is less well-understood. We develop a theory of finite exchangeability and its relation to tractable probabilistic inference. The theory is complementary to that of independence and conditional independence. We show that tractable inference in probabilistic models with high treewidth and millions of variables can be explained with the notion of finite (partial) exchangeability. We also show that existing lifted inference algorithms implicitly utilize a combination of conditional independence and partial exchangeability.",
    "Authors1": "Mathias Niepert",
    "Authors2": "Guy Van den Broeck",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Mathias Niepert , Guy Van den Broeck",
    "Groups1": "Reasoning under Uncertainty (RU)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Reasoning under Uncertainty (RU)",
    "Keywords10": "",
    "Keywords1": "efficient inference",
    "Keywords2": "lifted inference",
    "Keywords3": "probabilistic inference",
    "Keywords4": "exchangeability",
    "Keywords5": "statistical relational learning",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "efficient inference;lifted inference;probabilistic inference;exchangeability;statistical relational learning",
    "Title": "Tractability through Exchangeability: A New Perspective on Efficient Probabilistic Inference",
    "Topics10": "",
    "Topics1": "RU: Probabilistic Inference",
    "Topics2": "RU: Relational Probabilistic Models",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "RU: Probabilistic Inference;RU: Relational Probabilistic Models"
  },
  {
    "Document Index (generated)": 214,
    "Number of Records": 1,
    "Abstract": "In situated dialogue with artificial agents (e.g., robots), although a human and an agent are co-present, the agent's representation and the human's representation of the shared environment are significantly mismatched. Because of this misalignment, previous work has shown that when the agent applies traditional approaches to generate referring expressions to describe target objects, the intended objects often cannot be correctly identified by the human. To address this problem, motivated by collaborative behaviors in human referential communication, we have developed two collaborative models - an episodic model and an installment model - for referring expression generation. In both models, instead of generating a single referring expression to describe a target object as in the previous work, it generates multiple small expressions that lead to the target object with a goal to minimize the collaborative effort. In particular, our installment model incorporates human feedback in a reinforcement learning framework to learn the optimal generation strategies. Our empirical results have shown that the episodic model and the installment model outperform previous non-collaborative models with an absolute gain of 6% and 21% respectively.",
    "Authors1": "Rui Fang",
    "Authors2": "Malcolm Doering",
    "Authors3": "Joyce Chai",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Rui Fang, Malcolm Doering , Joyce Chai",
    "Groups1": "NLP and Machine Learning (NLPML)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "NLP and Machine Learning (NLPML)",
    "Keywords10": "",
    "Keywords1": "referring expression generation",
    "Keywords2": "collaborative models",
    "Keywords3": "situated dialogue",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "referring expression generation;collaborative models;situated dialogue",
    "Title": "Collaborative Models for Referring Expression Generation in Situated Dialogue",
    "Topics10": "",
    "Topics1": "NLPML: Discourse and Dialogue",
    "Topics2": "NLPML: Natural Language Processing (General/Other)",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NLPML: Discourse and Dialogue;NLPML: Natural Language Processing (General/Other)"
  },
  {
    "Document Index (generated)": 215,
    "Number of Records": 1,
    "Abstract": "Manipulating irregular natural objects, such as rocks, is an essential capability of robots operating in outdoor environments. Previous studies have shown that stable grasps for known, man-made, objects can usually be planned by using physics-based simulators. However, planning is an expensive process that requires simulation of hand and object trajectories in different configurations, and evaluating the outcome of each trajectory. This problem is particularly concerning when the objects are irregular and cluttered, because the space of stable grasps is significantly smaller, and more configurations need to be evaluated before finding a good one. We present a learning approach, based on template matching, for fast detection of a small initial set of potentially stable grasps in a cluttered scene, using depth features. The predicted best grasps are further optimized by fine-tunning the configuration of the hand in simulation. To reduce the computational cost of this last operation, we model the predicted outcomes of the grasps as a Gaussian Process, and use an entropy-search method in order to focus the optimization on regions where the best grasp configuration is most likely to be. This approach is tested on the challenging task of clearing piles of real, unknown, rock debris using an autonomous robot. Empirical results show a clear advantage of this approach.",
    "Authors1": "Abdeslam Boularias",
    "Authors2": "J. Andrew Bagnell",
    "Authors3": "Anthony Stentz",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Abdeslam Boularias, J. Andrew Bagnell , Anthony Stentz",
    "Groups1": "Machine Learning Applications (MLA)",
    "Groups2": "Robotics (ROB)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Machine Learning Applications (MLA);Robotics (ROB)",
    "Keywords10": "",
    "Keywords1": "Robotic grasping",
    "Keywords2": "Planning",
    "Keywords3": "Bayesian optimization",
    "Keywords4": "Gaussian Processes",
    "Keywords5": "Anytime optimization",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Robotic grasping;Planning;Bayesian optimization;Gaussian Processes;Anytime optimization",
    "Title": "Efficient Optimization for Autonomous Manipulation of Natural Objects",
    "Topics10": "",
    "Topics1": "MLA: Machine Learning Applications (General/other)",
    "Topics2": "ROB: Behavior and Control",
    "Topics3": "ROB: Robotics (General/Other)",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "MLA: Machine Learning Applications (General/other);ROB: Behavior and Control;ROB: Robotics (General/Other)"
  },
  {
    "Document Index (generated)": 216,
    "Number of Records": 1,
    "Abstract": "The growing Electric Vehicles' (EVs) popularity among commuters creates new challenges for the smart grid. The most important of them is the uncoordinated EV charging that substantially increases the energy demand peaks, putting the smart grid under constant strain. In order to cope with these peaks the grid needs extra infrastructure, a costly solution. We propose an Adaptive Management of EV Storage (AMEVS) algorithm, implemented through a learning agent that acts on behalf of individual EV owners and schedules EV charging over a weekly horizon. It accounts for individual preferences so that mobility service is not violated but also individual benefit is maximized. We observe that it reshapes the energy demand making it less volatile so that fewer resources are needed to cover peaks. It assumes Vehicle-to-Grid discharging when the customer has excess capacity. Our agent uses Reinforcement Learning trained on real world data to learn individual household consumption behavior and to schedule EV charging. Unlike previous work, AMEVS is a fully distributed approach. We show that AMEVS achieves significant reshaping of the energy demand curve and peak reduction, which is correlated with customer preferences regarding perceived utility of energy availability. Additionally, we show that the average and peak energy prices are reduced as a result of smarter energy use.",
    "Authors1": "Konstantina Valogianni",
    "Authors2": "Wolfgang Ketter",
    "Authors3": "John Collins",
    "Authors4": "Dmitry Zhdanov",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Konstantina Valogianni, Wolfgang Ketter, John Collins , Dmitry Zhdanov",
    "Groups1": "Computational Sustainability and AI (CSAI)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Computational Sustainability and AI (CSAI)",
    "Keywords10": "",
    "Keywords1": "Electric Vehicles",
    "Keywords2": "Smart Grid",
    "Keywords3": "Optimization",
    "Keywords4": "Reinforcement Learning",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Electric Vehicles;Smart Grid;Optimization;Reinforcement Learning",
    "Title": "Effective Management of Electric Vehicle Storage using Smart Charging",
    "Topics10": "",
    "Topics1": "CSAI: Control and optimization of dynamic and spatiotemporal systems",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "CSAI: Control and optimization of dynamic and spatiotemporal systems"
  },
  {
    "Document Index (generated)": 217,
    "Number of Records": 1,
    "Abstract": "In this paper, we discuss a computational approach to the cognitive \ntask of social planning. First, we specify a class of planning \nproblems that involve an agent who attempts to achieve its goals \nby altering other agents' mental states. Next, we describe SFPS, \na flexible problem solver that generates social plans of this sort, \nincluding ones that include deception and reasoning about other \nagents' beliefs. We report the results for experiments on social \nscenarios that involve different levels of sophistication and that \ndemonstrate both SFPS' capabilities and the sources of its power. \nFinally, we discuss how our approach to social planning has been \ninformed by earlier work in the area and propose directions for \nadditional research on the topic.",
    "Authors1": "Chris Pearce",
    "Authors2": "Ben Meadows",
    "Authors3": "Pat Langley",
    "Authors4": "Mike Barley",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Chris Pearce, Ben Meadows, Pat Langley , Mike Barley",
    "Groups1": "Cognitive Systems (CS)",
    "Groups2": "Planning and Scheduling (PS)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Cognitive Systems (CS);Planning and Scheduling (PS)",
    "Keywords10": "",
    "Keywords1": "Cognitive Systems",
    "Keywords2": "Social Planning",
    "Keywords3": "Deception",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Cognitive Systems;Social Planning;Deception",
    "Title": "Social Planning: Achieving Goals by Altering Others' Mental States",
    "Topics10": "",
    "Topics1": "CS: Conceptual inference and reasoning",
    "Topics2": "CS: Social cognition and interaction",
    "Topics3": "CS: Problem solving and decision making",
    "Topics4": "KRR: Reasoning with Beliefs",
    "Topics5": "PS: Planning (General/Other)",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "CS: Conceptual inference and reasoning;CS: Social cognition and interaction;CS: Problem solving and decision making;KRR: Reasoning with Beliefs;PS: Planning (General/Other)"
  },
  {
    "Document Index (generated)": 218,
    "Number of Records": 1,
    "Abstract": "During the past decade, machine learning algorithms have become commonplace in large-scale real-world industrial applications. In these settings, the computation time to train and test machine learning algorithms is a key consideration. At training-time the algorithms must scale to very large data set sizes. At testing-time, the cost of feature extraction can dominate the CPU runtime. Recently, a promising method was proposed to account for the feature extraction cost at testing time, called Cost-sensitive Tree of Classifiers (CSTC). Although the CSTC problem is NP-hard, the authors suggest an approximation through a mixed-norm relaxation across many classifiers. This relaxation is slow to train and requires involved optimization hyperparameter tuning. We propose a different relaxation using approximate submodularity, called Approximately Submodular Tree of Classifiers (ASTC). ASTC is much simpler to implement, yields equivalent results but requires no optimization hyperparameter tuning and is up to two orders of magnitude faster to train.",
    "Authors1": "Matt Kusner",
    "Authors2": "Wenlin Chen",
    "Authors3": "Quan Zhou",
    "Authors4": "Eddie Xu",
    "Authors5": "Kilian Weinberger",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Matt Kusner, Wenlin Chen, Quan Zhou, Eddie Xu , Kilian Weinberger",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "submodular optimization",
    "Keywords2": "feature-cost sensitive learning",
    "Keywords3": "tree-based learning",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "submodular optimization;feature-cost sensitive learning;tree-based learning",
    "Title": "Feature-Cost Sensitive Learning with Submodular Trees of Classifiers",
    "Topics10": "",
    "Topics1": "NMLA: Classification",
    "Topics2": "NMLA: Supervised Learning (Other)",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Classification;NMLA: Supervised Learning (Other)"
  },
  {
    "Document Index (generated)": 219,
    "Number of Records": 1,
    "Abstract": "We formulate an approach to multiagent metareasoning that uses organizational design to focus each agent's reasoning on the aspects of their respective local problems to which they can make the most worthwhile contributions to joint behavior.  By employing the decentralized Markov decision process framework, we characterize an organizational design problem that explicitly considers the quantitative impact that a design has on both the quality of the agents' behaviors and their reasoning costs.  We describe an automated organizational design process that can approximately solve our organizational design problem via incremental search, and present techniques that efficiently estimate the incremental impact of a candidate organizational influence.  Our empirical evaluation confirms that our process generates organizational designs that impart a desired metareasoning regime upon the agents.",
    "Authors1": "Jason Sleight",
    "Authors2": "Ed Durfee",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Jason Sleight , Ed Durfee",
    "Groups1": "Multiagent Systems (MAS)",
    "Groups2": "Planning and Scheduling (PS)",
    "Groups3": "Reasoning under Uncertainty (RU)",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Multiagent Systems (MAS);Planning and Scheduling (PS);Reasoning under Uncertainty (RU)",
    "Keywords10": "",
    "Keywords1": "organizational design",
    "Keywords2": "Dec-MDP",
    "Keywords3": "multiagent metareasoning",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "organizational design;Dec-MDP;multiagent metareasoning",
    "Title": "Multiagent Metareasoning Through Organizational Design",
    "Topics10": "",
    "Topics1": "MAS: Coordination and Collaboration",
    "Topics2": "MAS: Multiagent Planning",
    "Topics3": "MAS: Multiagent Systems (General/other)",
    "Topics4": "PS: Markov Models of Environments",
    "Topics5": "PS: Model-Based Reasoning",
    "Topics6": "PS: Probabilistic Planning",
    "Topics7": "RU: Decision/Utility Theory",
    "Topics8": "RU: Sequential Decision Making",
    "Topics9": "",
    "Topics": "MAS: Coordination and Collaboration;MAS: Multiagent Planning;MAS: Multiagent Systems (General/other);PS: Markov Models of Environments;PS: Model-Based Reasoning;PS: Probabilistic Planning;RU: Decision/Utility Theory;RU: Sequential Decision Making"
  },
  {
    "Document Index (generated)": 220,
    "Number of Records": 1,
    "Abstract": "We present a series of visual information extraction experiments\nusing the Faces ofWikipedia database - a new resource\nthat we release into the public domain for both recognition\nand extraction research containing over 50,000 identities and\n60,000 disambiguated images of faces. We compare different\ntechniques for automatically extracting the faces corresponding\nto the subject of a Wikipedia biography within the\nimages appearing on the page. Our top performing approach\nis based on probabilistic graphical models and uses the text\nof Wikipedia pages, similarities of faces as well as various\nother features of the document, meta-data and image files.\nOur method resolves the problem jointly for all detected faces\non a page. While our experiments focus on extracting faces\nfrom Wikipedia biographies, our approach is easily adapted\nto other types of documents and multiple documents. We focus\nonWikipedia because the content is a Creative Commons\nresource and we provide our database to the community including\nregistered faces, hand labeled and automated disambiguations,\nprocessed captions, meta data and evaluation protocols.\nOur best probabilistic extraction pipeline yields an expected\naverage accuracy of 77% compared to image only and\ntext only baselines which yield 66% and 63% respectively.",
    "Authors1": "Md. Kamrul Hasan",
    "Authors2": "Christopher Pal",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Md. Kamrul Hasan , Christopher Pal",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "Vision (VIS)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW);Vision (VIS)",
    "Keywords10": "",
    "Keywords1": "Web mining",
    "Keywords2": "Information extraction",
    "Keywords3": "Text processing",
    "Keywords4": "Face verification",
    "Keywords5": "Identity resolution",
    "Keywords6": "Face recognition",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Web mining;Information extraction;Text processing;Face verification;Identity resolution;Face recognition",
    "Title": "Experiments on Visual Information Extraction with the Faces of Wikipedia",
    "Topics10": "",
    "Topics1": "AIW: Knowledge acquisition from the web",
    "Topics2": "VIS: Face and Gesture Recognition",
    "Topics3": "VIS: Image and Video Retrieval",
    "Topics4": "VIS: Language and Vision",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: Knowledge acquisition from the web;VIS: Face and Gesture Recognition;VIS: Image and Video Retrieval;VIS: Language and Vision"
  },
  {
    "Document Index (generated)": 221,
    "Number of Records": 1,
    "Abstract": "We study the opportunity to exploit the absence of signals as informative observations in the context of providing task recommendations in crowdsourcing. Workers on crowdsourcing platform do not provide explicit ratings about tasks. We present methods that enable a system to leverage implicit signals about task preferences. These signals include types of tasks that have been available and have been displayed, and the number of tasks workers select and complete. In distinction to previous work, we present a general model that can represent both positive and negative implicit signals.  We introduce algorithms that can learn these models without exceeding the computational complexity of existing approaches. Finally, using data from a large-scale, high throughput crowdsourcing platform, we show that reasoning about both positive and negative implicit feedback can improve the quality of task recommendations provided to workers.",
    "Authors1": "Christopher Lin",
    "Authors2": "Ece Kamar",
    "Authors3": "Eric Horvitz",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Christopher Lin, Ece Kamar , Eric Horvitz",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "Applications (APP)",
    "Groups3": "Human-Computation and Crowd Sourcing (HCC)",
    "Groups4": "Machine Learning Applications (MLA)",
    "Groups5": "Novel Machine Learning Algorithms (NMLA)",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW);Applications (APP);Human-Computation and Crowd Sourcing (HCC);Machine Learning Applications (MLA);Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "Crowdsourcing",
    "Keywords2": "Recommendation Systems",
    "Keywords3": "Implicit Feedback",
    "Keywords4": "Matrix Factorization",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Crowdsourcing;Recommendation Systems;Implicit Feedback;Matrix Factorization",
    "Title": "Signals in the Silence: Models of Implicit Feedback in a Recommender System for Crowdsourcing",
    "Topics10": "",
    "Topics1": "AIW: Crowdsourcing techniques and methodologies",
    "Topics2": "AIW: Web-based recommendation systems",
    "Topics3": "APP: Other Applications",
    "Topics4": "HCC: Programming languages, tools and platforms to support human computation",
    "Topics5": "MLA: Machine Learning Applications (General/other)",
    "Topics6": "NMLA: Recommender Systems",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: Crowdsourcing techniques and methodologies;AIW: Web-based recommendation systems;APP: Other Applications;HCC: Programming languages, tools and platforms to support human computation;MLA: Machine Learning Applications (General/other);NMLA: Recommender Systems"
  },
  {
    "Document Index (generated)": 222,
    "Number of Records": 1,
    "Abstract": "Explosive growth of multimedia data has brought challenge of how to efficiently browse, retrieve and organize these data. Under this circumstance, different approaches have been proposed to facilitate multimedia analysis. Several semi-supervised feature selection algorithms have been proposed to exploit both labeled and unlabeled data. However, they are implemented based on graphs, such that they cannot handle large-scale datasets. How to conduct semi-supervised feature selection on large-scale datasets has become a challenging research problem. Moreover, existing multi-label feature selection algorithms rely on eigen-decomposition with heavy computational burden, which further prevent current feature selection algorithms from being applied for big data. In this paper, we propose a novel semi-supervised multi-label feature selection for large-scale\nmultimedia analysis. We evaluate performance of the proposed algorithm over five benchmark datasets and compare the results with state-of-the-art supervised and\nsemi-supervised feature selection algorithms as well as baseline using all features. The experimental results demonstrate that our proposed algorithm consistently achieve superiors performances.",
    "Authors1": "Xiaojun Chang",
    "Authors2": "Feiping Nie",
    "Authors3": "Yi Yang",
    "Authors4": "Heng Huang",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Xiaojun Chang, Feiping Nie, Yi Yang , Heng Huang",
    "Groups1": "Machine Learning Applications (MLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Machine Learning Applications (MLA)",
    "Keywords10": "",
    "Keywords1": "Semi-supervised Learning",
    "Keywords2": "Multi-Label Feature Selection",
    "Keywords3": "Convex Algorithm",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Semi-supervised Learning;Multi-Label Feature Selection;Convex Algorithm",
    "Title": "A Convex Formulation for Semi-supervised Multi-Label Feature Selection",
    "Topics10": "",
    "Topics1": "NMLA: Classification",
    "Topics2": "NMLA: Dimension Reduction/Feature Selection",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Classification;NMLA: Dimension Reduction/Feature Selection"
  },
  {
    "Document Index (generated)": 223,
    "Number of Records": 1,
    "Abstract": "This paper introduces a novel framework for performing machine learning on longitudinal neuroimaging datasets. These datasets are characterized by their size, particularly their width (millions of features per input). \n\nSpecifically, we address the problem of detecting subtle, short-term changes in neural structure that are indicative of cognitive decline and correlate with risk factors for Alzheimer's disease. We introduce a new spatially-sensitive kernel that allows us to reason about individuals, as opposed to populations. \n\nIn doing so, this paper presents the first evidence demonstrating that very small changes in white matter structure over a two year period can predict change in cognitive function in healthy adults.",
    "Authors1": "Hidayath Ansari",
    "Authors2": "Michael Coen",
    "Authors3": "Barbara Bendlin",
    "Authors4": "Mark Sager",
    "Authors5": "Sterling Johnson",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Hidayath Ansari, Michael Coen, Barbara Bendlin, Mark Sager , Sterling Johnson",
    "Groups1": "Machine Learning Applications (MLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Machine Learning Applications (MLA)",
    "Keywords10": "",
    "Keywords1": "Machine Learning",
    "Keywords2": "Neuroimaging",
    "Keywords3": "Kernel Methods",
    "Keywords4": "Wide Data",
    "Keywords5": "Alzheimer's Disease",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Machine Learning;Neuroimaging;Kernel Methods;Wide Data;Alzheimer's Disease",
    "Title": "A Spatially Sensitive Kernel to Predict Cognitive Performance from Short-Term Changes in Neural Structure",
    "Topics10": "",
    "Topics1": "APP: Biomedical / Bioinformatics",
    "Topics2": "MLA: Bio/Medicine",
    "Topics3": "MLA: Applications of Supervised Learning",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "APP: Biomedical / Bioinformatics;MLA: Bio/Medicine;MLA: Applications of Supervised Learning"
  },
  {
    "Document Index (generated)": 224,
    "Number of Records": 1,
    "Abstract": "Central to robot exploration and mapping is the task of persistent localization in environmental fields characterized by spatially correlated measurements.\nThis paper presents a novel Gaussian process localization (GP-Localize) algorithm that, in contrast to existing works, can exploit the spatially correlated field measurements taken during a robot's exploration (instead of relying on prior training data) for efficiently and scalably learning the GP observation model online.\nAs a result, GP-Localize is capable of achieving constant time and memory in the size of the data per filtering step, which demonstrates the practical feasibility of using GPs for persistent robot localization.\nEmpirical evaluation via simulated experiments with real-world datasets and a real robot experiment shows that GP-Localize outperforms existing GP localization algorithms.",
    "Authors1": "Nuo Xu",
    "Authors2": "Bryan Kian Hsiang Low",
    "Authors3": "Jie Chen",
    "Authors4": "Keng Kiat Lim",
    "Authors5": "Etkin Ozgul",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Nuo Xu, Bryan Kian Hsiang Low, Jie Chen, Keng Kiat Lim , Etkin Ozgul",
    "Groups1": "Robotics (ROB)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Robotics (ROB)",
    "Keywords10": "",
    "Keywords1": "Robot localization",
    "Keywords2": "Gaussian process",
    "Keywords3": "Online learning",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Robot localization;Gaussian process;Online learning",
    "Title": "GP-Localize: Persistent Mobile Robot Localization using Online Sparse Gaussian Process Observation Model",
    "Topics10": "",
    "Topics1": "MLA: Applications of Supervised Learning",
    "Topics2": "NMLA: Online Learning",
    "Topics3": "ROB: Localization, Mapping, and Navigation",
    "Topics4": "ROB: State Estimation",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "MLA: Applications of Supervised Learning;NMLA: Online Learning;ROB: Localization, Mapping, and Navigation;ROB: State Estimation"
  },
  {
    "Document Index (generated)": 225,
    "Number of Records": 1,
    "Abstract": "Structured preference domains, such as, e.g., the domains of single-peaked and single-crossing preferences, are known to admit efficient algorithms for many problems in computational social choice. Some of these algorithms extend to preferences that are close to having the respective structural property, i.e., can be made to enjoy this property by making minor changes to voters’ preferences, such as deleting a small number of voters or candidates. However, it has recently been shown that finding the optimal number of voters or candidates to delete in order to achieve the desired structural property is NP-hard for many such domains. In this paper, we show that these problems admit efficient approximation algorithms. Our results apply to all domains that can be characterized in terms of forbidden configurations; this includes, in particular, single-peaked and single-crossing elections. For a large range of scenarios, our approximation results are optimal under a plausible complexity-theoretic assumption. We also provide parameterized complexity results for this class of problems.",
    "Authors1": "Martin Lackner",
    "Authors2": "Edith Elkind",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Martin Lackner , Edith Elkind",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "Multiagent Systems (MAS)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP);Multiagent Systems (MAS)",
    "Keywords10": "",
    "Keywords1": "single-peaked preferences",
    "Keywords2": "single-crossing preferences",
    "Keywords3": "approximation algorithms",
    "Keywords4": "forbidden configurations",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "single-peaked preferences;single-crossing preferences;approximation algorithms;forbidden configurations",
    "Title": "On Detecting Nearly Structured Preference Profiles",
    "Topics10": "",
    "Topics1": "GTEP: Social Choice / Voting",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Social Choice / Voting"
  },
  {
    "Document Index (generated)": 226,
    "Number of Records": 1,
    "Abstract": "One-class classification approaches have been proposed in literature to learn classifiers from examples of only one class. But these approaches are not directly applicable to relational domains due to their reliance on feature vectors or  distance measure. We propose a non-parametric relational one-class classification approach based on first-order trees. We learn a tree-based distance measure that iteratively introduces new relational features to differentiate relational examples. We update the distance measure so as to maximize the one-class classification performance of our model. We also relate our model definition to existing work on combination functions and density estimation. We also experimentally show that our approach can discover relevant features for this task and outperform three  baseline approaches.",
    "Authors1": "Tushar Khot",
    "Authors2": "Sriraam Natarajan",
    "Authors3": "Jude Shavlik",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Tushar Khot, Sriraam Natarajan , Jude Shavlik",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "Reasoning under Uncertainty (RU)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA);Reasoning under Uncertainty (RU)",
    "Keywords10": "",
    "Keywords1": "One-class classification",
    "Keywords2": "Statistical Relational Learning",
    "Keywords3": "Ensemble learning",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "One-class classification;Statistical Relational Learning;Ensemble learning",
    "Title": "Relational One-Class Classification: A Non-Parametric Approach",
    "Topics10": "",
    "Topics1": "NMLA: Ensemble Methods",
    "Topics2": "NMLA: Relational/Graph-Based Learning",
    "Topics3": "RU: Relational Probabilistic Models",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Ensemble Methods;NMLA: Relational/Graph-Based Learning;RU: Relational Probabilistic Models"
  },
  {
    "Document Index (generated)": 227,
    "Number of Records": 1,
    "Abstract": "Understanding natural language about the continuous world is an important problem for cognitive systems. The naturalness of qualitative reasoning suggests that qualitative representations might be an important component of the semantics of natural language.  Prior work showed that frame-based representations of qualitative process theory constructs could indeed be extracted from natural language texts. That technique relied on the parser recognizing specific syntactic constructions, which had limited coverage. This paper describes a new approach, using narrative function to represent the higher-order relationships between the constituents of a sentence and between sentences in a discourse.  We outline how narrative function combined with query-driven abduction enables the same kinds of information to be extracted from natural language texts.  Moreover, we also show how the same technique can be used to extract type-level qualitative representations from text, and used to improve performance in playing a strategy game.",
    "Authors1": "Clifton McFate",
    "Authors2": "Kenneth Forbus",
    "Authors3": "Thomas Hinrichs",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Clifton McFate, Kenneth Forbus , Thomas Hinrichs",
    "Groups1": "Cognitive Systems (CS)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Cognitive Systems (CS)",
    "Keywords10": "",
    "Keywords1": "Cognitive Systems",
    "Keywords2": "Qualitative Representation",
    "Keywords3": "Natural Language Understanding",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Cognitive Systems;Qualitative Representation;Natural Language Understanding",
    "Title": "Using Narrative Function to Extract Qualitative Information from Natural Language Texts",
    "Topics10": "",
    "Topics1": "CS: Natural language understanding and dialogue",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "CS: Natural language understanding and dialogue"
  },
  {
    "Document Index (generated)": 228,
    "Number of Records": 1,
    "Abstract": "Mesoscale ocean eddies are a critical component of the Earth System as they dominate the ocean's kinetic energy and impact the global distribution of oceanic heat, salinity, momentum, and nutrients. Thus, accurately representing these dynamic features is critical for our planet's sustainability. The majority of methods that identify eddies from satellite observations analyze the data in a frame-by-frame basis despite the fact that eddies are dynamic objects that propagate across space and time. We introduce the notion of spatio-temporal consistency to identify eddies in a continuous spatio-temporal field, to simultaneously ensure that the features detected are both spatially consistent and temporally persistent. Our spatio-temporal consistency approach allows us to remove most of the expert criteria used in traditional methods and enables us to better render eddy dynamics by identifying smaller and longer lived eddies than existing methods.",
    "Authors1": "James Faghmous",
    "Authors2": "Hung Nguyen",
    "Authors3": "Matthew Le",
    "Authors4": "Vipin Kumar",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "James Faghmous, Hung Nguyen, Matthew Le , Vipin Kumar",
    "Groups1": "Computational Sustainability and AI (CSAI)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Computational Sustainability and AI (CSAI)",
    "Keywords10": "",
    "Keywords1": "spatio-temporal data mining",
    "Keywords2": "oceanography",
    "Keywords3": "pattern mining",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "spatio-temporal data mining;oceanography;pattern mining",
    "Title": "A spatio-temporal pattern mining algorithm to identify objects in a continuous field: A global oceanography perspective",
    "Topics10": "",
    "Topics1": "CSAI: Modeling and prediction of dynamic and spatiotemporal phenomena and systems",
    "Topics2": "CSAI: Control and optimization of dynamic and spatiotemporal systems",
    "Topics3": "CSAI: Modeling and control of complex high-dimensional systems",
    "Topics4": "CSAI: Sensor networks for monitoring environments",
    "Topics5": "NMLA: Data Mining and Knowledge Discovery",
    "Topics6": "NMLA: Time-Series/Data Streams",
    "Topics7": "NMLA: Unsupervised Learning (Other)",
    "Topics8": "",
    "Topics9": "",
    "Topics": "CSAI: Modeling and prediction of dynamic and spatiotemporal phenomena and systems;CSAI: Control and optimization of dynamic and spatiotemporal systems;CSAI: Modeling and control of complex high-dimensional systems;CSAI: Sensor networks for monitoring environments;NMLA: Data Mining and Knowledge Discovery;NMLA: Time-Series/Data Streams;NMLA: Unsupervised Learning (Other)"
  },
  {
    "Document Index (generated)": 229,
    "Number of Records": 1,
    "Abstract": "Efficient codes have been used effectively in both computer science and neuroscience to better understand the information processing in visual and auditory encoding and discrimination tasks. In this paper, we explore the use of efficient codes for representing information relevant to human movements during locomotion. Specifically, we apply motion capture data to a physical model of the human skeleton to compute joint angles (inverse kinematics) and joint torques (inverse dynamics); then, by treating the resulting data as a regression problem, we investigate the effect of sparsity in mapping from angles to torques. The results of our investigation suggest that sparse codes can indeed represent salient features of both the kinematic and dynamic views of locomotion movements in humans. However, sparsity appears to be only one parameter in building a model of inverse dynamics; we also show that the \"encoding\" process benefits significantly by integrating with the \"regression\" process for this task. Finally, we use our results to argue that representations of movement are critical to modeling and understanding these movements.",
    "Authors1": "Leif Johnson",
    "Authors2": "Dana Ballard",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Leif Johnson , Dana Ballard",
    "Groups1": "Cognitive Modeling (CM)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Cognitive Modeling (CM)",
    "Keywords10": "",
    "Keywords1": "machine learning",
    "Keywords2": "inverse dynamics",
    "Keywords3": "movement",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "machine learning;inverse dynamics;movement",
    "Title": "Efficient codes for inverse dynamics during walking",
    "Topics10": "",
    "Topics1": "CM: Simulating Humans",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "CM: Simulating Humans"
  },
  {
    "Document Index (generated)": 230,
    "Number of Records": 1,
    "Abstract": "A common bottleneck in deploying supervised learning systems is collecting human-annotated examples. In many domains, annotators form an opinion about the label of an example incrementally --- e.g., each additional word read from a document or each additional minute spent inspecting a video helps inform the annotation.  In this paper, we investigate whether we can train learning systems more efficiently by requesting an annotation before inspection is fully complete --- e.g., after reading only 25 words of a document. While doing so may reduce the overall annotation time, it also introduces the risk that the annotator might not be able to provide a label if interrupted too early. We propose an anytime active learning approach that optimizes the annotation time and response rate simultaneously.  We conduct user studies on subsets of two document classification datasets and develop simulated annotators that mimic the users. Our simulated experiments show that anytime active learning outperforms several baselines on these two datasets. For example, with an annotation budget of one hour, training a classifier by annotating the first 25 words of each document reduces classification error by 17% over annotating the first 100 words of each document.",
    "Authors1": "Maria E. Ramirez-Loaiza",
    "Authors2": "Aron Culotta",
    "Authors3": "Mustafa Bilgic",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Maria E. Ramirez-Loaiza, Aron Culotta , Mustafa Bilgic",
    "Groups1": "Human-Computation and Crowd Sourcing (HCC)",
    "Groups2": "Machine Learning Applications (MLA)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Human-Computation and Crowd Sourcing (HCC);Machine Learning Applications (MLA)",
    "Keywords10": "",
    "Keywords1": "active learning",
    "Keywords2": "non-uniform labeling costs",
    "Keywords3": "document classification",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "active learning;non-uniform labeling costs;document classification",
    "Title": "Anytime Active Learning",
    "Topics10": "",
    "Topics1": "HCC: Cost, reliability, and skill of labelers",
    "Topics2": "NLPML: Text Classification",
    "Topics3": "NMLA: Active Learning",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "HCC: Cost, reliability, and skill of labelers;NLPML: Text Classification;NMLA: Active Learning"
  },
  {
    "Document Index (generated)": 231,
    "Number of Records": 1,
    "Abstract": "Various representations and inference methods have been proposed for lifted probabilistic inference in relational models. Many of these methods choose an order to eliminate (or branch on) the parametrized random variables. Similar to such methods for non-relational probabilistic inference, the order of elimination has a significant role in the performance of the algorithm. Since finding the best order is NP-complete even for non-relational models, heuristics have been proposed to find good orderings in the non-relational models. We show that these heuristics are inefficient for relational models, because they fail to consider the population sizes associated with logical variables in the parametrized random variable. In this paper, we extend existing heuristics for non-relational models and propose new heuristics for relational models. We evaluate the existing and new heuristics on a range of generated relational graphs.",
    "Authors1": "Seyed Mehran Kazemi",
    "Authors2": "David Poole",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Seyed Mehran Kazemi , David Poole",
    "Groups1": "Reasoning under Uncertainty (RU)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Reasoning under Uncertainty (RU)",
    "Keywords10": "",
    "Keywords1": "Lifted inference",
    "Keywords2": "Elimination orderings",
    "Keywords3": "Probabilistic inference",
    "Keywords4": "Statistical relational AI",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Lifted inference;Elimination orderings;Probabilistic inference;Statistical relational AI",
    "Title": "Elimination Ordering in Lifted First-Order Probabilistic Inference",
    "Topics10": "",
    "Topics1": "RU: Probabilistic Inference",
    "Topics2": "RU: Relational Probabilistic Models",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "RU: Probabilistic Inference;RU: Relational Probabilistic Models"
  },
  {
    "Document Index (generated)": 232,
    "Number of Records": 1,
    "Abstract": "Postoperative atrial fibrillation (PAF) occurs in 10\\% to 65\\% of the patients undergoing cardiac surgery. It is associated with increased postoperative mortality and morbidity, and also results in longer and more expensive hospital stays. Accurately stratifying patients for PAF allows for the selective use of prophylactic therapies (e.g., amiodarone) to reduce this burden. Our proposed work addresses this need through the development of novel electrocardiographic (ECG) markers that can be easily deployed in a clinical setting to identify patients at risk of PAF. Specifically, we explore a novel eigen-decomposition approach that first partitions ECG signals into atrial and ventricular components by exploiting knowledge of the underlying cardiac cycle. We then quantify cardiac instability manifesting as probabilistic variations in atrial ECG morphology to assess the risk of PAF. When evaluated on a cohort of 385 patients undergoing cardiac surgery, our proposed approach based on an analysis of decoupled ECG components demonstrated substantial promise in identifying patients at risk of PAF and improved clinical models (both in terms of discrimination and reclassification) relative to the use of existing clinical metrics.",
    "Authors1": "Chih-Chun Chia",
    "Authors2": "James Blum",
    "Authors3": "Zahi Karam",
    "Authors4": "Satinder Singh",
    "Authors5": "Zeeshan Syed",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Chih-Chun Chia, James Blum, Zahi Karam, Satinder Singh , Zeeshan Syed",
    "Groups1": "Applications (APP)",
    "Groups2": "Machine Learning Applications (MLA)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Applications (APP);Machine Learning Applications (MLA)",
    "Keywords10": "",
    "Keywords1": "atrial fibrillation",
    "Keywords2": "independent components",
    "Keywords3": "medicine",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "atrial fibrillation;independent components;medicine",
    "Title": "Predicting Postoperative Atrial Fibrillation from Independent ECG Components",
    "Topics10": "",
    "Topics1": "APP: Biomedical / Bioinformatics",
    "Topics2": "MLA: Bio/Medicine",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "APP: Biomedical / Bioinformatics;MLA: Bio/Medicine"
  },
  {
    "Document Index (generated)": 233,
    "Number of Records": 1,
    "Abstract": "This paper develops an efficient online algorithm for learning multiple consecutive tasks based on the K-SVD algorithm for sparse dictionary optimization.  We first derive a batch multi-task learning method that builds upon K-SVD, and then extend the batch algorithm to train models online in a lifelong learning setting.  The resulting method has lower computational complexity than other current lifelong learning algorithms while maintaining nearly identical performance.  Additionally, the proposed method offers an alternate formulation for lifelong learning that supports both task and feature similarity matrices.",
    "Authors1": "Paul Ruvolo",
    "Authors2": "Eric Eaton",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Paul Ruvolo , Eric Eaton",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "multi-task learning",
    "Keywords2": "transfer learning",
    "Keywords3": "lifelong learning",
    "Keywords4": "sparse coding",
    "Keywords5": "k-svd",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "multi-task learning;transfer learning;lifelong learning;sparse coding;k-svd",
    "Title": "Online Multi-Task Learning via Sparse Dictionary Optimization",
    "Topics10": "",
    "Topics1": "NMLA: Online Learning",
    "Topics2": "NMLA: Transfer, Adaptation, Multitask Learning",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Online Learning;NMLA: Transfer, Adaptation, Multitask Learning"
  },
  {
    "Document Index (generated)": 234,
    "Number of Records": 1,
    "Abstract": "We investigate the limiting behavior of trader wealth and  prices in a simple prediction market with a finite set of participants having heterogeneous beliefs. Traders bet repeatedly on the outcome of a binary event with fixed Bernoulli success probability. A class of strategies, including (fractional) Kelly betting and constant relative risk aversion (CRRA) are considered. We show that when traders are willing to risk only a small fraction of their wealth in any period, belief heterogeneity can persist indefinitely; if bets are large in proportion to wealth then only the most accurate belief type survives. The market price is more accurate in the long run when traders with less accurate {beliefs} also survive. That is, the survival of traders with heterogeneous beliefs, some less accurate than others, allows the market price to better reflect the objective probability of the event in the long run.",
    "Authors1": "Willemien Kets",
    "Authors2": "David Pennock",
    "Authors3": "Rajiv Sethi",
    "Authors4": "Nisarg Shah",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Willemien Kets, David Pennock, Rajiv Sethi , Nisarg Shah",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP)",
    "Keywords10": "",
    "Keywords1": "Prediction market",
    "Keywords2": "Market selection",
    "Keywords3": "Kelly betting",
    "Keywords4": "CRRA utilities",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Prediction market;Market selection;Kelly betting;CRRA utilities",
    "Title": "Betting Strategies, Market Selection, and the Wisdom of Crowds",
    "Topics10": "",
    "Topics1": "GTEP: Auctions and Market-Based Systems",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Auctions and Market-Based Systems"
  },
  {
    "Document Index (generated)": 235,
    "Number of Records": 1,
    "Abstract": "The emergence of location based social network (LBSN) services makes it possible to study individuals’ mobility patterns at a fine-grained level and to see how they are impacted by social factors. In this study we analyze the check-in patterns in LBSN and observe significant temporal clustering of check-in activities. We explore how self-reinforcing behaviors, social factors, and exogenous effects contribute to this clustering and introduce a framework to distinguish these effects at the level of individual check-ins for both users and venues. Using check-in data from three major cities, we show not only that our model can improve prediction of future check-ins, but also that disentangling of different factors allows us to infer meaningful properties of different venues.",
    "Authors1": "Yoon-Sik Cho",
    "Authors2": "Greg Ver Steeg",
    "Authors3": "Aram Galstyan",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Yoon-Sik Cho, Greg Ver Steeg , Aram Galstyan",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "Applications (APP)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW);Applications (APP)",
    "Keywords10": "",
    "Keywords1": "Location Based Social Network",
    "Keywords2": "Point Processes",
    "Keywords3": "Temporal Clustering",
    "Keywords4": "Social Network Analysis",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Location Based Social Network;Point Processes;Temporal Clustering;Social Network Analysis",
    "Title": "Where and Why Users \"Check In",
    "Topics10": "",
    "Topics1": "AIW: Social networking and community identification",
    "Topics2": "APP: Computational Social Science",
    "Topics3": "APP: Social Networks",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: Social networking and community identification;APP: Computational Social Science;APP: Social Networks"
  },
  {
    "Document Index (generated)": 236,
    "Number of Records": 1,
    "Abstract": "Markov Chains are a fundamental tool for the analysis of real world\nphenomena and randomized algorithms. Given a graph with some specified\nsink nodes and an initial probability distribution,\nwe consider the problem of designing an absorbing Markov\nChain that minimizes the time required to reach a sink node, by\nselecting transition probabilities subject to some natural regularity\nconstraints. By exploiting the Markovian structure, we obtain closed\nform expressions for the objective function as well as its gradient,\nwhich can be thus evaluated efficiently without any simulation of the\nunderlying process and fed to a gradient-based optimization\npackage. For the special case of designing reversible Markov Chains,\nwe show that global optimum can be efficiently computed by exploiting\nconvexity. We demonstrate how our method can be used to\nevaluate and design local search methods tailored for certain\ndomains.",
    "Authors1": "Stefano Ermon",
    "Authors2": "Carla Gomes",
    "Authors3": "Ashish Sabharwal",
    "Authors4": "Bart Selman",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Stefano Ermon, Carla Gomes, Ashish Sabharwal , Bart Selman",
    "Groups1": "Heuristic Search and Optimization (HSO)",
    "Groups2": "Novel Machine Learning Algorithms (NMLA)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Heuristic Search and Optimization (HSO);Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "MCMC",
    "Keywords2": "Markov Chain",
    "Keywords3": "Absorption time",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "MCMC;Markov Chain;Absorption time",
    "Title": "Designing Fast Absorbing Markov Chains",
    "Topics10": "",
    "Topics1": "HSO: Evaluation and Analysis (Search and Optimization)",
    "Topics2": "HSO: Search (General/Other)",
    "Topics3": "NMLA: Machine Learning (General/other)",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "HSO: Evaluation and Analysis (Search and Optimization);HSO: Search (General/Other);NMLA: Machine Learning (General/other)"
  },
  {
    "Document Index (generated)": 237,
    "Number of Records": 1,
    "Abstract": "This paper presents a symbolic BDD-based model checking algorithm for an epistemic strategy logic with observational semantics. The logic has been shown to be more expressive than several variants of ATEL and therefore the algorithm can also be used for ATEL model checking. We implement the algorithm in a model checker and apply it to several applications. The performance of the algorithm is also reported, with a comparison with a partially symbolic approach for ATEL model checking.",
    "Authors1": "Xiaowei Huang",
    "Authors2": "Ron van der Meyden",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Xiaowei Huang , Ron van der Meyden",
    "Groups1": "Multiagent Systems (MAS)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Multiagent Systems (MAS)",
    "Keywords10": "",
    "Keywords1": "Logic of Knowledge",
    "Keywords2": "Strategic Reasoning",
    "Keywords3": "Model Checking",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Logic of Knowledge;Strategic Reasoning;Model Checking",
    "Title": "Symbolic Model Checking Epistemic Strategy Logic",
    "Topics10": "",
    "Topics1": "MAS: Coordination and Collaboration",
    "Topics2": "MAS: Evaluation and Analysis (Multiagent Systems)",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "MAS: Coordination and Collaboration;MAS: Evaluation and Analysis (Multiagent Systems)"
  },
  {
    "Document Index (generated)": 238,
    "Number of Records": 1,
    "Abstract": "A wide range of robotic missions contain actions that exhibit looping behavior. Examples of these actions include picking fruit in agriculture, pick-and-place tasks in manufacturing, or even search patterns in robotic search or survey missions. These looping actions often have a range of acceptable values for the number of loops and a preference function over them. For example, during robotic survey missions, the information gain is expected to increase with the number of loops in a search pattern. Since these looping actions also take time, which is typically bounded, there is a challenge of maximizing utility while respecting time constraints. \n\nIn this paper, we introduce the Looping Temporal Problem with Preference (LTPP) as a formalism for encoding scheduling problems that contain looping actions. In addition, we introduce a scheduling algorithm for LTPPs, which leverages the structure of the problem to find the optimal solution efficiently.",
    "Authors1": "James Paterson",
    "Authors2": "Brian Williams",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "James Paterson , Brian Williams",
    "Groups1": "Planning and Scheduling (PS)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Planning and Scheduling (PS)",
    "Keywords10": "",
    "Keywords1": "Scheduling",
    "Keywords2": "Loops",
    "Keywords3": "Preference",
    "Keywords4": "Optimization",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Scheduling;Loops;Preference;Optimization",
    "Title": "A Scheduler for Actions with Iterated Durations",
    "Topics10": "",
    "Topics1": "PS: Scheduling",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "PS: Scheduling"
  },
  {
    "Document Index (generated)": 239,
    "Number of Records": 1,
    "Abstract": "Newly-discovered materials have been central to recent technological advances. They have contributed significantly to breakthroughs in electronics, renewable energy and green buildings, and overall, have promoted the advancement of global human welfare. Yet, only a fraction of all possible materials have been explored. Accelerating the pace of discovery of materials would foster technological innovations, and would potentially address pressing issues in sustainability, such as energy production or consumption.\n\nThe bottleneck of this discovery cycle lies, however, in the analysis of the materials data. As materials scientists have recently devised techniques to efficiently create thousands of materials and experimentalists have developed new methods and tools to characterize these materials, the limiting factor has become the data analysis itself. Hence, the goal of this paper is to stimulate the development of new computational techniques for the analysis of materials data, by bringing together the complimentary expertise of materials scientists and computer scientists.\n\nIn collaboration with two major research laboratories in materials science, we provide the first publicly available dataset for the phase map identification problem. In addition, we provide a parameterized synthetic data generator to assess the quality of proposed approaches, as well as tools for data visualization and solution evaluation.",
    "Authors1": "John M. Gregoire",
    "Authors2": "Santosh Suram",
    "Authors3": "Ronan Le Bras",
    "Authors4": "Richard Bernstein",
    "Authors5": "Carla Gomes",
    "Authors6": "Bart Selman",
    "Authors7": "R. Bruce Van Dover",
    "Authors": "John M. Gregoire, Santosh Suram, Ronan Le Bras, Richard Bernstein, Carla Gomes, Bart Selman , R. Bruce Van Dover",
    "Groups1": "Computational Sustainability and AI (CSAI)",
    "Groups2": "Heuristic Search and Optimization (HSO)",
    "Groups3": "Machine Learning Applications (MLA)",
    "Groups4": "Search and Constraint Satisfaction (SCS)",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Computational Sustainability and AI (CSAI);Heuristic Search and Optimization (HSO);Machine Learning Applications (MLA);Search and Constraint Satisfaction (SCS)",
    "Keywords10": "",
    "Keywords1": "Materials discovery",
    "Keywords2": "Dataset",
    "Keywords3": "Phase-map identification problem",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Materials discovery;Dataset;Phase-map identification problem",
    "Title": "Materials Discovery - Synthetic and Real World Datasets",
    "Topics10": "",
    "Topics1": "CSAI: Modeling and control of complex high-dimensional systems",
    "Topics2": "MLA: Applications of Unsupervised Learning",
    "Topics3": "SCS: Constraint Optimization",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "CSAI: Modeling and control of complex high-dimensional systems;MLA: Applications of Unsupervised Learning;SCS: Constraint Optimization"
  },
  {
    "Document Index (generated)": 240,
    "Number of Records": 1,
    "Abstract": "This paper presents an intelligent tutoring system, GeoTutor, for Euclidean Geometry that is automatically able to synthesize proof problems and their respective solutions given a geometric figure together with a set of properties true of it. GeoTutor can provide personalized practice problems that address student deficiencies in the subject matter.",
    "Authors1": "Christopher Alvin",
    "Authors2": "Sumit Gulwani",
    "Authors3": "Rupak Majumdar",
    "Authors4": "Supratik Mukhopadhyay",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Christopher Alvin, Sumit Gulwani, Rupak Majumdar , Supratik Mukhopadhyay",
    "Groups1": "Applications (APP)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Applications (APP)",
    "Keywords10": "",
    "Keywords1": "Problem Synthesis",
    "Keywords2": "Automated Reasoning",
    "Keywords3": "Computer-Aided Education",
    "Keywords4": "Intelligent Tutor",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Problem Synthesis;Automated Reasoning;Computer-Aided Education;Intelligent Tutor",
    "Title": "Automatic Synthesis of Geometry Problems for an Intelligent Tutoring System",
    "Topics10": "",
    "Topics1": "APP: Computer-Aided Education",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "APP: Computer-Aided Education"
  },
  {
    "Document Index (generated)": 241,
    "Number of Records": 1,
    "Abstract": "In this paper we computationally examine how subjective experience may help or harm the decision maker's learning under uncertain outcomes, frames and their interactions. To model subjective experience, we propose the ``experienced-utility function'' based on a prospect theory (PT)-based parameterized subjective value function. Our analysis and simulations of two-armed bandit tasks present that the task domain (underlying outcome distributions) and framing (reference point selection) influence experienced utilities and in turn, the ``subjective discriminability'' of choices under uncertainty.  Experiments demonstrate that subjective discriminability improves on objective discriminability by the use of the experienced-utility function with appropriate framing for a domain, and that bigger subjective discriminability leads to more optimal decisions in learning under uncertainty.",
    "Authors1": "Hyung-Il Ahn",
    "Authors2": "Rosalind Picard",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Hyung-Il Ahn , Rosalind Picard",
    "Groups1": "Cognitive Modeling (CM)",
    "Groups2": "Novel Machine Learning Algorithms (NMLA)",
    "Groups3": "Reasoning under Uncertainty (RU)",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Cognitive Modeling (CM);Novel Machine Learning Algorithms (NMLA);Reasoning under Uncertainty (RU)",
    "Keywords10": "",
    "Keywords1": "subjective experience-based learning",
    "Keywords2": "subjective value function",
    "Keywords3": "prospect theory",
    "Keywords4": "subjective discriminability",
    "Keywords5": "experienced utility",
    "Keywords6": "decision utility",
    "Keywords7": "gain frame",
    "Keywords8": "loss frame",
    "Keywords9": "",
    "Keywords": "subjective experience-based learning;subjective value function;prospect theory;subjective discriminability;experienced utility;decision utility;gain frame;loss frame",
    "Title": "Modeling Subjective Experience-based Learning under Uncertainty and Frames",
    "Topics10": "",
    "Topics1": "CM: Adaptive Behavior",
    "Topics2": "CM: Simulating Humans",
    "Topics3": "NMLA: Reinforcement Learning",
    "Topics4": "RU: Decision/Utility Theory",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "CM: Adaptive Behavior;CM: Simulating Humans;NMLA: Reinforcement Learning;RU: Decision/Utility Theory"
  },
  {
    "Document Index (generated)": 242,
    "Number of Records": 1,
    "Abstract": "Existing approaches to pronoun resolution are monolingual, training and testing a pronoun resolver on the data from original language. In contrast, we propose a bilingual approach to pronoun resolution, aiming to improve the resolution of pronouns by leveraging both the publicly available dictionaries and coreference annotations from a second language. Experiments on the OntoNotes corpus demonstrate that our bilingual approach to pronoun resolution significantly surpasses the performance of state-of-the-art monolingual approaches.",
    "Authors1": "Chen Chen",
    "Authors2": "Vincent Ng",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Chen Chen , Vincent Ng",
    "Groups1": "NLP and Text Mining (NLPTM)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "NLP and Text Mining (NLPTM)",
    "Keywords10": "",
    "Keywords1": "Pronouns",
    "Keywords2": "Text Mining",
    "Keywords3": "Natural Language Processing",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Pronouns;Text Mining;Natural Language Processing",
    "Title": "Resolving Pronouns by Leveraging English Resources",
    "Topics10": "",
    "Topics1": "NLPML: Evaluation and Analysis",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NLPML: Evaluation and Analysis"
  },
  {
    "Document Index (generated)": 243,
    "Number of Records": 1,
    "Abstract": "Bagging (Breiman 1996) and its variants is one of the most popular methods\nin aggregating classifiers and regressors. Originally, its analysis assumed that the bootstraps are built from an unlimited, independent source of samples, therefore we call this form of bagging \\emph{ideal-bagging}. However in the real world, base predictors are trained on data subsampled from a limited number of training samples and thus they behave very differently. We analyze the effect of intersections between bootstraps (obtained by subsampling) to train different base predictors. Most importantly, we provide an alternative subsampling method called \\emph{design-bagging} based on a new construction of combinatorial designs, and prove it universally better than bagging. Methodologically, we succeed at this level of generality because we compare the bagging and design-bagging on their prediction accuracy each relative to the accuracy ideal-bagging.This can possibly find applications in more involved bagging-based ensemble methods. Our analytical results are backed up by experiments on classification and regression settings.",
    "Authors1": "Cao Zhu",
    "Authors2": "Periklis Papakonstantinou",
    "Authors3": "Jia Xu",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Cao Zhu, Periklis Papakonstantinou , Jia Xu",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "bagging",
    "Keywords2": "bootstrapping",
    "Keywords3": "combinatorial design",
    "Keywords4": "noise stability",
    "Keywords5": "correlation",
    "Keywords6": "dependent sampling",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "bagging;bootstrapping;combinatorial design;noise stability;correlation;dependent sampling",
    "Title": "Bagging by design (on the sub-optimality of bagging)",
    "Topics10": "",
    "Topics1": "NMLA: Classification",
    "Topics2": "NMLA: Ensemble Methods",
    "Topics3": "NMLA: Supervised Learning (Other)",
    "Topics4": "NMLA: Machine Learning (General/other)",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Classification;NMLA: Ensemble Methods;NMLA: Supervised Learning (Other);NMLA: Machine Learning (General/other)"
  },
  {
    "Document Index (generated)": 244,
    "Number of Records": 1,
    "Abstract": "In this paper, we present an approach to learn structured models of gesture performances that allow for a compressed representation and robust recognition of natural iconic gestures. We analyze a dataset of iconic gestures and show how the proposed hybrid grammar formalism can generalize over both structural and feature-based variations among different gesture performances.",
    "Authors1": "Amir Sadeghipour",
    "Authors2": "Stefan Kopp",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Amir Sadeghipour , Stefan Kopp",
    "Groups1": "Machine Learning Applications (MLA)",
    "Groups2": "Novel Machine Learning Algorithms (NMLA)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Machine Learning Applications (MLA);Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "Iconic Hand Gestures",
    "Keywords2": "Stochastic Context-Free Grammar",
    "Keywords3": "Machine learning",
    "Keywords4": "Classification",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Iconic Hand Gestures;Stochastic Context-Free Grammar;Machine learning;Classification",
    "Title": "A Hybrid Grammar-Based Approach for Learning and Recognizing Natural Hand Gestures",
    "Topics10": "",
    "Topics1": "MLA: Applications of Supervised Learning",
    "Topics2": "NMLA: Classification",
    "Topics3": "NMLA: Graphical Model Learning",
    "Topics4": "NMLA: Supervised Learning (Other)",
    "Topics5": "NMLA: Machine Learning (General/other)",
    "Topics6": "VIS: Face and Gesture Recognition",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "MLA: Applications of Supervised Learning;NMLA: Classification;NMLA: Graphical Model Learning;NMLA: Supervised Learning (Other);NMLA: Machine Learning (General/other);VIS: Face and Gesture Recognition"
  },
  {
    "Document Index (generated)": 245,
    "Number of Records": 1,
    "Abstract": "With the rapid growth of event-based social services (EBSSs) like \\emph{Meetup}, the demand for event recommendation becomes increasingly urgent. In EBSSs, event recommendation plays a central role in recommending the most relevant events to users who are likely to participate in. Different from traditional recommendation problems, event recommendation encounters three new types of information, \\emph{i.e.}, heterogeneous online+offline social relationships, geographical information of events and implicit feedback data from users. Yet combining the three types of data for event recommendation has not been considered. Therefore, we present a Bayesian probability model that can unify these data for event recommendation. Experimental results on real-world data sets show the performance of our method.",
    "Authors1": "Zhi Qiao",
    "Authors2": "Peng Zhang",
    "Authors3": "Yanan Cao",
    "Authors4": "Chuan Zhou",
    "Authors5": "Li Guo",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Zhi Qiao, Peng Zhang, Yanan Cao, Chuan Zhou , Li Guo",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "Novel Machine Learning Algorithms (NMLA)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW);Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "heterogeneous social networks",
    "Keywords2": "event recommendation",
    "Keywords3": "geographical features",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "heterogeneous social networks;event recommendation;geographical features",
    "Title": "Combining Heterogenous Social and Geographical Information for Event Recommendation",
    "Topics10": "",
    "Topics1": "AIW: Web-based recommendation systems",
    "Topics2": "NMLA: Recommender Systems",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: Web-based recommendation systems;NMLA: Recommender Systems"
  },
  {
    "Document Index (generated)": 246,
    "Number of Records": 1,
    "Abstract": "This paper explores whether the addition of costly, imperfect, and exploitable advisors to Berg's investment game enhances or detracts from investor performance in both one-shot and multi-round interactions.\nWe then leverage our findings to develop an automated investor agent that performs as well as or better than humans in these games.\nTo gather this data, we extended Berg's game and conducted a series of experiments using Amazon's Mechanical Turk to determine how humans behave in these potentially adversarial conditions.\nOur results indicate that, in games of short duration, advisors do not stimulate positive behavior and are not useful in providing actionable advice.\nIn long-term interactions, however, advisors do stimulate positive behavior with significantly increased investments and returns.\nBy modeling human behavior across several hundred participants, we were then able to develop agent strategies that maximized return on investment and performed as well as or significantly better than humans.\nIn one-shot games, we identified an ideal investment value that, on average, resulted in positive returns as long as advisor exploitation was not allowed.\nFor the multi-round games, our agents relied on the corrective presence of advisors to stimulate positive returns on maximum investment.",
    "Authors1": "Cody Buntain",
    "Authors2": "Sarit Kraus",
    "Authors3": "Amos Azaria",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Cody Buntain, Sarit Kraus , Amos Azaria",
    "Groups1": "Humans and AI (HAI)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Humans and AI (HAI)",
    "Keywords10": "",
    "Keywords1": "advisors",
    "Keywords2": "trust games",
    "Keywords3": "investment game",
    "Keywords4": "bribery",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "advisors;trust games;investment game;bribery",
    "Title": "Leveraging Fee-Based, Imperfect Advisors in Human-Agent Games of Trust",
    "Topics10": "",
    "Topics1": "HAI: Human-Computer Interaction",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "HAI: Human-Computer Interaction"
  },
  {
    "Document Index (generated)": 247,
    "Number of Records": 1,
    "Abstract": "We contend that ethically significant behavior of autonomous systems should be guided by explicit ethical principles determined through a consensus of ethicists. As it is likely that in many particular cases of ethical dilemmas ethicists agree on the ethically relevant features and the right course of action, generalization of such cases can be used to help discover principles needed for ethical guidance of the behavior of autonomous systems. Such principles help ensure the ethical behavior of complex and dynamic systems and further serve as a basis for justification of their actions as well as a control abstraction for managing unanticipated behavior. To provide assistance in developing ethical principles, we have developed GENETH, a general ethical dilemma analyzer that, through a dialog with ethicists, codifies ethical principles in any given domain.  GENETH has been used to codify principles in a number of domains pertinent to the behavior of autonomous systems and these principles have been verified using an Ethical Turing Test.",
    "Authors1": "Michael Anderson",
    "Authors2": "Susan Leigh Anderson",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Michael Anderson , Susan Leigh Anderson",
    "Groups1": "Applications (APP)",
    "Groups2": "Humans and AI (HAI)",
    "Groups3": "Machine Learning Applications (MLA)",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Applications (APP);Humans and AI (HAI);Machine Learning Applications (MLA)",
    "Keywords10": "",
    "Keywords1": "machine ethics",
    "Keywords2": "concept learning",
    "Keywords3": "application",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "machine ethics;concept learning;application",
    "Title": "GenEth: A General Ethical Dilemma Analyzer",
    "Topics10": "",
    "Topics1": "APP: Philosophical and Ethical Issues",
    "Topics2": "HAI: Human-Computer Interaction",
    "Topics3": "HAI: Understanding People, Theories, Concepts and Methods",
    "Topics4": "KRR: Logic Programming",
    "Topics5": "MLA: Applications of Supervised Learning",
    "Topics6": "MLA: Machine Learning Applications (General/other)",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "APP: Philosophical and Ethical Issues;HAI: Human-Computer Interaction;HAI: Understanding People, Theories, Concepts and Methods;KRR: Logic Programming;MLA: Applications of Supervised Learning;MLA: Machine Learning Applications (General/other)"
  },
  {
    "Document Index (generated)": 248,
    "Number of Records": 1,
    "Abstract": "The Traveling Tournament Problem (TTP) is a complex problem in sports scheduling whose solution is a schedule of home and away games meeting specific feasibility requirements, while minimizing the total distance traveled by all the teams.  A recently-developed \"hybrid\" algorithm, combining local search and integer programming, has resulted in best-known solutions for many TTP instances.  In this paper, we tackle the TTP from a graph-theoretic perspective, by generating a new \"canonical\" schedule in which each team's three-game road trips match up with the underlying graph's minimum-weight P_3-packing.  By using this new schedule as the initial input for the hybrid algorithm, we develop tournament schedules for five benchmark TTP instances that beat all previously-known solutions.",
    "Authors1": "Richard Hoshino",
    "Authors2": "Ken-Ichi Kawarabayashi",
    "Authors3": "Marc Goerigk",
    "Authors4": "Stephan Westphal",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Richard Hoshino, Ken-Ichi Kawarabayashi, Marc Goerigk , Stephan Westphal",
    "Groups1": "Heuristic Search and Optimization (HSO)",
    "Groups2": "Planning and Scheduling (PS)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Heuristic Search and Optimization (HSO);Planning and Scheduling (PS)",
    "Keywords10": "",
    "Keywords1": "traveling tournament problem",
    "Keywords2": "sports scheduling",
    "Keywords3": "scheduling optimization",
    "Keywords4": "graph theory",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "traveling tournament problem;sports scheduling;scheduling optimization;graph theory",
    "Title": "Solving the Traveling Tournament Problem by Packing Three-Vertex Paths",
    "Topics10": "",
    "Topics1": "HSO: Heuristic Search",
    "Topics2": "HSO: Optimization",
    "Topics3": "PS: Scheduling",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "HSO: Heuristic Search;HSO: Optimization;PS: Scheduling"
  },
  {
    "Document Index (generated)": 249,
    "Number of Records": 1,
    "Abstract": "Sparse modeling has been highly successful on high-dimensional data. While a lot of interests have been on convex regularization, recent studies show that nonconvex regularizers can outperform their convex counterparts in many situations. However, the resulting nonconvex optimization problems are often challenging, especially for composite regularizers such as the nonconvex overlapping group lasso. In this paper,  by using a recent tool known as the proximal average, we propose a novel proximal gradient descent method for a wide class of composite and nonconvex problems. Instead of directly solving the proximal step with a composite regularizer, we average the solutions from the proximal problems of the individual regularizers. This simple strategy has similar convergence guarantee as existing nonconvex optimization approaches,but its per-iteration complexity is much lower. Experimental results on synthetic and real-world data sets demonstrate the effectiveness and efficiency of the proposed optimization algorithm, and also the improved prediction performance resulting from the nonconvex regularizers.",
    "Authors1": "Wenliang Zhong",
    "Authors2": "James Kwok",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Wenliang Zhong , James Kwok",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "non-convex optimization",
    "Keywords2": "composite regularization",
    "Keywords3": "proximal average",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "non-convex optimization;composite regularization;proximal average",
    "Title": "Gradient Descent Method with Proximal Average for Nonconvex and Composite Regularization",
    "Topics10": "",
    "Topics1": "NMLA: Big Data / Scalability",
    "Topics2": "NMLA: Dimension Reduction/Feature Selection",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Big Data / Scalability;NMLA: Dimension Reduction/Feature Selection"
  },
  {
    "Document Index (generated)": 250,
    "Number of Records": 1,
    "Abstract": "Many real-world applications involve multilabel classification, in which the labels can have strong inter-dependencies and some of them may even be missing. Existing multilabel algorithms are unable to deal with both issues simultaneously. In this paper, we propose a probabilistic model that can automatically learn and exploit multilabel correlations. By integrating out the missing information, it also provides a disciplined approach to the handling of missing labels. The inference procedure is simple, and the optimization subproblems are convex. Experiments on a number of real-world data sets with both complete and missing labels demonstrate that the proposed algorithm can consistently outperform the state-of-the-art multilabel classification algorithms.",
    "Authors1": "Wei Bi",
    "Authors2": "James Kwok",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Wei Bi , James Kwok",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "multilabel classification",
    "Keywords2": "label correlation",
    "Keywords3": "missing label",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "multilabel classification;label correlation;missing label",
    "Title": "Multilabel Classification with Label Correlations and Missing Labels",
    "Topics10": "",
    "Topics1": "NMLA: Classification",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Classification"
  },
  {
    "Document Index (generated)": 251,
    "Number of Records": 1,
    "Abstract": "Stochastic local search (SLS) algorithms have shown effectiveness on satisfiable instances of the Boolean satisfiability (SAT) problem. However, their performance is still unsatisfactory on random k-SAT at the phase transition, which is of significance and is one of the most empirically hardest distributions of SAT instances. In this paper, we propose a new heuristic called DCCA, which combines two configuration checking (CC) strategies with different definitions of configuration in a novel way. We use the DCCA heuristic to design an efficient SLS solver for SAT dubbed DCCASat. The experiments show that the DCCASat solver significantly outperforms a number of state-of-the-art solvers on extensive random k-SAT benchmarks at the phase transition. Moreover, further empirical analyses on structured benchmarks indicate the robustness of DCCASat.",
    "Authors1": "Chuan Luo",
    "Authors2": "Shaowei Cai",
    "Authors3": "Wei Wu",
    "Authors4": "Kaile Su",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Chuan Luo, Shaowei Cai, Wei Wu , Kaile Su",
    "Groups1": "Heuristic Search and Optimization (HSO)",
    "Groups2": "Search and Constraint Satisfaction (SCS)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Heuristic Search and Optimization (HSO);Search and Constraint Satisfaction (SCS)",
    "Keywords10": "",
    "Keywords1": "Double Configuration Checking",
    "Keywords2": "Stochastic Local Search",
    "Keywords3": "Satisfiability",
    "Keywords4": "Phase Transition",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Double Configuration Checking;Stochastic Local Search;Satisfiability;Phase Transition",
    "Title": "Double Configuration Checking in Stochastic Local Search for Satisfiability",
    "Topics10": "",
    "Topics1": "HSO: Heuristic Search",
    "Topics2": "SCS: Constraint Satisfaction",
    "Topics3": "SCS: SAT and CSP: Solvers and Tools",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "HSO: Heuristic Search;SCS: Constraint Satisfaction;SCS: SAT and CSP: Solvers and Tools"
  },
  {
    "Document Index (generated)": 252,
    "Number of Records": 1,
    "Abstract": "This paper presents a direct semantic analysis method for learning the correlation matrix between visual and textual words from socially tagged images. In the literature, to improve the traditional visual bag-of-words (BOW) representation, latent semantic analysis has been studied extensively for learning a compact visual representation, where each visual word may be related to multiple latent topics. However, these latent topics do not convey any true semantic information which can be understood by human. In fact, it remains a challenging problem how to recover the relationships between visual and textual words. Motivated by the recent advances in dealing with socially tagged images, we develop a direct semantic analysis method which can explicitly learn the correlation matrix between visual and textual words for social image classification. To this end, we formulate our direct semantic analysis from a graph-based learning viewpoint. Once the correlation matrix is learnt, we can readily first obtain a semantically refined visual BOW representation and then apply it to social image classification. Experimental results on two benchmark image datasets show the promising performance of the proposed method.",
    "Authors1": "Zhiwu Lu",
    "Authors2": "Liwei Wang",
    "Authors3": "Ji-Rong Wen",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Zhiwu Lu, Liwei Wang , Ji-Rong Wen",
    "Groups1": "Machine Learning Applications (MLA)",
    "Groups2": "Vision (VIS)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Machine Learning Applications (MLA);Vision (VIS)",
    "Keywords10": "",
    "Keywords1": "social image classification",
    "Keywords2": "latent semantic analysis",
    "Keywords3": "graph-based learning",
    "Keywords4": "bag-of-words",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "social image classification;latent semantic analysis;graph-based learning;bag-of-words",
    "Title": "Direct Semantic Analysis for Social Image Classification",
    "Topics10": "",
    "Topics1": "MLA: Machine Learning Applications (General/other)",
    "Topics2": "VIS: Image and Video Retrieval",
    "Topics3": "VIS: Statistical Methods and Learning",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "MLA: Machine Learning Applications (General/other);VIS: Image and Video Retrieval;VIS: Statistical Methods and Learning"
  },
  {
    "Document Index (generated)": 253,
    "Number of Records": 1,
    "Abstract": "We investigate synergy, or lack thereof, between agents in cooperative games, building on the popular notion of Shapley value. We think of a pair of agents as synergistic (resp., antagonistic) if the Shapley value of one agent when the other agent participates in a joint effort is higher (resp. lower) than when the other agent does not participate. Our main theoretical result is that any graph specifying synergistic and antagonistic pairs can arise even from a restricted class of cooperative games. We also study the computational complexity of determining whether a given pair of agents is synergistic. Finally, we use the concepts developed in the paper to uncover the structure of synergies in two real-world organizations, the European Union and the International Monetary Fund.",
    "Authors1": "Ariel Procaccia",
    "Authors2": "Nisarg Shah",
    "Authors3": "Max Tucker",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Ariel Procaccia, Nisarg Shah , Max Tucker",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP)",
    "Keywords10": "",
    "Keywords1": "Cooperative game theory",
    "Keywords2": "Shapley value",
    "Keywords3": "Weighted voting games",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Cooperative game theory;Shapley value;Weighted voting games",
    "Title": "On the Structure of Synergies in Cooperative Games",
    "Topics10": "",
    "Topics1": "GTEP: Game Theory",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Game Theory"
  },
  {
    "Document Index (generated)": 254,
    "Number of Records": 1,
    "Abstract": "Linear subspace is an important representation for many kinds of real-world data in computer vision and pattern recognition, e.g. faces, motion videos, speech. In this paper, first we define pairwise angular similarity and angular distance for linear subspaces. The angular distance satisfies non-negativity, identity of indiscernibles, symmetry and triangle inequality, and thus it is a metric. Then we propose a method to compress linear subspaces into compact similarity-preserving binary signatures, between which the normalized Hamming distance is an unbiased estimator of the angular distance. We provide a lower bound on the length of binary signatures which suffices to guarantee a uniform distance-preservation within a set of subspaces. Experiments on face recognition demonstrate the effectiveness of this binary signature in terms of recognition accuracy, speed and storage requirement. The results show that, compared with the exact method, the approximation with binary signatures achieves an order of magnitude speed-up, while requiring significantly smaller amount of storage space, yet it still accurately preserves the similarity, and achieves high recognition accuracy comparable to the exact method in face recognition.",
    "Authors1": "Jianqiu Ji",
    "Authors2": "Jianmin Li",
    "Authors3": "Shuicheng Yan",
    "Authors4": "Qi Tian",
    "Authors5": "Bo Zhang",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Jianqiu Ji, Jianmin Li, Shuicheng Yan, Qi Tian , Bo Zhang",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "linear subspace",
    "Keywords2": "angular distance",
    "Keywords3": "binary signature",
    "Keywords4": "Hamming distance",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "linear subspace;angular distance;binary signature;Hamming distance",
    "Title": "Similarity-preserving binary signature for linear subspace",
    "Topics10": "",
    "Topics1": "NMLA: Data Mining and Knowledge Discovery",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Data Mining and Knowledge Discovery"
  },
  {
    "Document Index (generated)": 255,
    "Number of Records": 1,
    "Abstract": "Existing multiple kernel learning (MKL) algorithms indiscriminately apply a same set of kernel combination weights to all samples. However, the utility of base kernels could vary across samples and a base kernel useful for one sample could become noisy for another. In this case, rigidly applying a same set of kernel combination weights could adversely affect the learning performance. To improve this situation, we propose a sample-adaptive MKL algorithm, in which base kernels are allowed to be adaptively switched on/off with respect to each sample. We achieve this goal by assigning a latent binary variable to each base kernel when it is applied to a sample. The kernel combination weights and the latent variables are jointly optimized via margin maximization principle. As demonstrated on five benchmark data sets, the proposed algorithm consistently outperforms the comparable ones in the literature.",
    "Authors1": "Xinwang Liu",
    "Authors2": "Lei Wang",
    "Authors3": "Jian Zhang",
    "Authors4": "Jianping Yin",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Xinwang Liu, Lei Wang, Jian Zhang , Jianping Yin",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "Latent Support Vector Machine",
    "Keywords2": "Multiple Kernel Learning",
    "Keywords3": "Inference",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Latent Support Vector Machine;Multiple Kernel Learning;Inference",
    "Title": "Sample-Adaptive Multiple Kernel Learning",
    "Topics10": "",
    "Topics1": "NMLA: Classification",
    "Topics2": "NMLA: Ensemble Methods",
    "Topics3": "NMLA: Kernel Methods",
    "Topics4": "NMLA: Supervised Learning (Other)",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Classification;NMLA: Ensemble Methods;NMLA: Kernel Methods;NMLA: Supervised Learning (Other)"
  },
  {
    "Document Index (generated)": 256,
    "Number of Records": 1,
    "Abstract": "Social influence has been widely accepted to explain people's cascade behaviors and further utilized to benefit many applications. However, few of existing work studied the direct, microscopic and temporal impact of social influence on people's behaviors in detail. In this paper we engage in the investigation of behavior propagation based on social influence and its temporal dynamics over continuous time. We formalize the static behavior models including BP and IBP, and the discrete DBP and DIBP models. We introduce continuous-temporal functions (CTFs) to model the fully-continuous dynamic variance of social influence over time. Upon that we propose the continuous-temporal interest-aware behavior propagation model, called CIBP, and present effective inference algorithm. Experimental studies on real-world datasets evaluated the family of behavior propagation models (BPMs) and demonstrated the effectiveness of our proposed models.",
    "Authors1": "Jun Zhang",
    "Authors2": "Chaokun Wang",
    "Authors3": "Jianmin Wang",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Jun Zhang, Chaokun Wang , Jianmin Wang",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "Applications (APP)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW);Applications (APP)",
    "Keywords10": "",
    "Keywords1": "Temporal Dynamics",
    "Keywords2": "Social Influence",
    "Keywords3": "Behavior Propagation",
    "Keywords4": "Behavior Prediction",
    "Keywords5": "Social Networks",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Temporal Dynamics;Social Influence;Behavior Propagation;Behavior Prediction;Social Networks",
    "Title": "Learning Temporal Dynamics of Behavior Propagation in Social Networks",
    "Topics10": "",
    "Topics1": "AIW: Exploiting Linked Open Data",
    "Topics2": "AIW: Social networking and community identification",
    "Topics3": "AIW: Web personalization and user modeling",
    "Topics4": "AIW: Web-based recommendation systems",
    "Topics5": "APP: Computational Social Science",
    "Topics6": "APP: Social Networks",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: Exploiting Linked Open Data;AIW: Social networking and community identification;AIW: Web personalization and user modeling;AIW: Web-based recommendation systems;APP: Computational Social Science;APP: Social Networks"
  },
  {
    "Document Index (generated)": 257,
    "Number of Records": 1,
    "Abstract": "We propose a new idea in the allocation and serving of online advertising.  We show that by using predetermined fixed-length streams of ads (which we call patterns) to\nserve advertising, we can incorporate a variety of interesting features into the ad allocation optimization problem.  In particular, our formulation optimizes for representativeness as well as user-level diversity and pacing of ads, under\nreach and frequency requirements.  We show how the problem can be solved efficiently using a column generation scheme in which only a small set of best patterns are kept in the optimization problem.  Our numerical tests show that with parallelization of the pattern generation process, the algorithm has a promising run time and memory usage.",
    "Authors1": "Ali Hojjat",
    "Authors2": "John Turner",
    "Authors3": "Suleyman Cetintas",
    "Authors4": "Jian Yang",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Ali Hojjat, John Turner, Suleyman Cetintas , Jian Yang",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "Applications (APP)",
    "Groups3": "Heuristic Search and Optimization (HSO)",
    "Groups4": "Planning and Scheduling (PS)",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW);Applications (APP);Heuristic Search and Optimization (HSO);Planning and Scheduling (PS)",
    "Keywords10": "",
    "Keywords1": "Online Advertising",
    "Keywords2": "Math programming",
    "Keywords3": "Optimization",
    "Keywords4": "Column Generation",
    "Keywords5": "Guaranteed Targeted Display Advertising",
    "Keywords6": "Reach",
    "Keywords7": "Frequency",
    "Keywords8": "Uniform Delivery",
    "Keywords9": "",
    "Keywords": "Online Advertising;Math programming;Optimization;Column Generation;Guaranteed Targeted Display Advertising;Reach;Frequency;Uniform Delivery",
    "Title": "Delivering Guaranteed Display Ads under Reach and Frequency Requirements",
    "Topics10": "",
    "Topics1": "AIW: AI for web services: semantic descriptions, planning, matching, and coordination",
    "Topics2": "APP: Other Applications",
    "Topics3": "HSO: Optimization",
    "Topics4": "PS: Deterministic Planning",
    "Topics5": "PS: Planning (General/Other)",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: AI for web services: semantic descriptions, planning, matching, and coordination;APP: Other Applications;HSO: Optimization;PS: Deterministic Planning;PS: Planning (General/Other)"
  },
  {
    "Document Index (generated)": 258,
    "Number of Records": 1,
    "Abstract": "Video completion is a computer vision technique to recover the missing values in video sequences by filling the unknown regions with the known information. In recent research, tensor completion, a generalization of matrix completion for higher order data, emerges as a new solution to estimate the missing information in video with the assumption that the video frames are homogenous and correlated. However, each video clip often stores the heterogeneous episodes and the correlations among all video frames are not high. Thus, the regular tenor completion methods are not suitable to recover the video missing values in practical applications.\n\nTo solve this problem, we propose a novel spatially-temporally consistent tensor completion method for recovering the video missing data. Instead of minimizing the average of the trace norms of all matrices unfolded along each mode in a tensor data, we introduce a new smoothness regularization along video time direction to utilize the temporal information between consecutive video frames. Meanwhile, we also minimize the trace norm of each individual video frame to employ the spatial correlations among pixels. Different to previous tensor completion approaches, our new method can keep the spatio-temporal consistency in video and do not assume the global correlation in video frames. Thus, the proposed method can be applied to the general and practical video completion applications. Our method shows promising results in all evaluations on 3D biomedical image sequence and video benchmark data sets.",
    "Authors1": "Hua Wang",
    "Authors2": "Feiping Nie",
    "Authors3": "Heng Huang",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Hua Wang, Feiping Nie , Heng Huang",
    "Groups1": "Vision (VIS)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Vision (VIS)",
    "Keywords10": "",
    "Keywords1": "Video completion",
    "Keywords2": "Tensor completion",
    "Keywords3": "Augmented Langrange Multiplier Method",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Video completion;Tensor completion;Augmented Langrange Multiplier Method",
    "Title": "Video Recovery via Low-Rank Tensor Completion with Spatio-Temporal Consistency",
    "Topics10": "",
    "Topics1": "VIS: Videos",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "VIS: Videos"
  },
  {
    "Document Index (generated)": 259,
    "Number of Records": 1,
    "Abstract": "Multi-view clustering, which seeks a partition of the data in\nmultiple views that often provide complementary information to each\nother, has received considerable attention in recent years. In real\nlife clustering problems, the data in each view may have\nconsiderable noise. However, existing clustering methods blindly\ncombine the information from multi-view data with possibly\nconsiderable noise, which often degrades their performance. In this\npaper, we propose a novel Markov chain method for \\textit{Robust\nMulti-view Spectral Clustering} (RMSC). Our method has a flavor of\nlow-rank and sparse decomposition, where we firstly construct a\ntransition probability matrix from each single view, and then use\nthese matrices to recover a shared low-rank transition probability\nmatrix as a crucial input to the standard Markov chain method\nfor clustering. The optimization problem of RMSC has a low-rank\nconstraint on the transition probability matrix, and simultaneously\na probabilistic simplex constraint on each of its rows. To solve\nthis challenging optimization problem, we propose an optimization procedure\nbased on the Augmented Lagrangian Multiplier scheme. Experimental\nresults on various real world datasets show that the\nproposed method has superior performance over several\nstate-of-the-art methods for multi-view clustering.",
    "Authors1": "Rongkai Xia",
    "Authors2": "Yan Pan",
    "Authors3": "Lei Du",
    "Authors4": "Jian Yin",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Rongkai Xia, Yan Pan, Lei Du , Jian Yin",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "multi-view clustering",
    "Keywords2": "spectral clustering",
    "Keywords3": "low-rank matrices",
    "Keywords4": "Markov chains",
    "Keywords5": "Augmented Lagrangian Multiplier method",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "multi-view clustering;spectral clustering;low-rank matrices;Markov chains;Augmented Lagrangian Multiplier method",
    "Title": "Robust Multi-View Spectral Clustering via Low-Rank and Sparse Decomposition",
    "Topics10": "",
    "Topics1": "NMLA: Clustering",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Clustering"
  },
  {
    "Document Index (generated)": 260,
    "Number of Records": 1,
    "Abstract": "Tweets ranking is important for information acquisition in Microblog. Due to the content sparsity and lack of labeled data, it is better to employ semi-supervised learning methods to utilize the unlabeled data. However, most of previous semi-supervised learning methods do not consider the pair conflict problem, which means that the new selected unlabeled data may conflict with the labeled and previously selected data. It will hurt the learning performance a lot, if the training data contains many conflict pairs. In this paper, we propose a new collaborative semi-supervised SVM ranking model (CSR-TC) with consideration of the order conflict. The unlabeled data is selected based on a dynamically maintained transitive closure graph to avoid pair conflict. We also investigate the two views of features, intrinsic and content-relevant features, for the proposed model. Extensive experiments are conducted on TREC Microblogging corpus. The results demonstrate that our proposed method achieves significant improvement, compared to several state-of-the-art models.",
    "Authors1": "Shenghua Liu",
    "Authors2": "Xueqi Cheng",
    "Authors3": "Fangtao Li",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Shenghua Liu, Xueqi Cheng , Fangtao Li",
    "Groups1": "Heuristic Search and Optimization (HSO)",
    "Groups2": "Machine Learning Applications (MLA)",
    "Groups3": "NLP and Machine Learning (NLPML)",
    "Groups4": "Novel Machine Learning Algorithms (NMLA)",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Heuristic Search and Optimization (HSO);Machine Learning Applications (MLA);NLP and Machine Learning (NLPML);Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "Microblog search",
    "Keywords2": "semi-supervised learning",
    "Keywords3": "transitive closure",
    "Keywords4": "learning to rank",
    "Keywords5": "SVM",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Microblog search;semi-supervised learning;transitive closure;learning to rank;SVM",
    "Title": "Ranking Tweets by Labeled and Collaboratively Selected Pairs with Transitive Closure",
    "Topics10": "",
    "Topics1": "APP: Social Networks",
    "Topics2": "NMLA: Semisupervised Learning",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "APP: Social Networks;NMLA: Semisupervised Learning"
  },
  {
    "Document Index (generated)": 261,
    "Number of Records": 1,
    "Abstract": "In this paper, we propose an unsupervised projection method for feature extraction to preserve both global and local consistencies of the input data in the projected space. Traditional unsupervised feature extraction methods, such as principal component analysis and locality preserving projections, can only explore either the global or local geometric structures of the input data, but not the both. In our new method, we introduce a new measurement using the neighborhood data variances to assess the data locality, by which we propose to learn an optimal projection by rewarding both the global and local structures of the input data. Moreover, to improve the robustness of the proposed learning model against outlier data samples and outlier features, which is of particular importance in unsupervised learning, we propose a new objective that simultaneously minimizes and maximizes (minmax) the L1-norm distances instead of the traditional squared L2-norm distances. Solving the formulated optimization problem is very challenging, because it minimizes and maximizes a number of non-smooth L1- norm terms at the same time. In this paper, as an important theoretical contribution, we propose a simple yet effective optimization method to solve the L1-norm minmax problem, and theoretically prove its convergence and correctness. To the best of our knowledge, our paper makes the first attempt to solve the general L1-norm minmax problem with orthogonal constraints. Extensive experiments have been performed on six benchmark data sets, where the promising results validate the proposed method.",
    "Authors1": "Hua Wang",
    "Authors2": "Feiping Nie",
    "Authors3": "Heng Huang",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Hua Wang, Feiping Nie , Heng Huang",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "Unsupervised learning",
    "Keywords2": "Dimension reduction",
    "Keywords3": "L1-norm minimization and maximization",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Unsupervised learning;Dimension reduction;L1-norm minimization and maximization",
    "Title": "Globally and Locally Consistent Unsupervised Projection",
    "Topics10": "",
    "Topics1": "NMLA: Unsupervised Learning (Other)",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Unsupervised Learning (Other)"
  },
  {
    "Document Index (generated)": 262,
    "Number of Records": 1,
    "Abstract": "Efficiency--no agent can be made better off without making another one worse off--and strategyproofness--no agent can obtain a more preferred outcome by misrepresenting his preferences--are two cornerstones of economics and ubiquitous in important areas such as voting, auctions, or matching markets. Within the context of randomized social choice, Bogomolnaia and Moulin have shown that two particular notions of efficiency and strategyproofness based on stochastic dominance are incompatible. However, there are various other possibilities of lifting preferences over alternatives to preferences over lotteries apart from stochastic dominance. In this paper, we give an overview of common preference extensions, propose two new ones, and show that the above-mentioned incompatibility can be extended to various other notions of strategyproofness and efficiency.",
    "Authors1": "Haris Aziz",
    "Authors2": "Florian Br",
    "Authors3": "l",
    "Authors4": "Felix Br",
    "Authors5": "t",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Haris Aziz, Florian Br,l , Felix Br,t",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP)",
    "Keywords10": "",
    "Keywords1": "social decision schemes",
    "Keywords2": "lotteries",
    "Keywords3": "efficiency",
    "Keywords4": "strategyproofness",
    "Keywords5": "randomized social choice",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "social decision schemes;lotteries;efficiency;strategyproofness;randomized social choice",
    "Title": "On the Incompatibility of Efficiency and Strategyproofness in Randomized Social Choice",
    "Topics10": "",
    "Topics1": "GTEP: Game Theory",
    "Topics2": "GTEP: Social Choice / Voting",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Game Theory;GTEP: Social Choice / Voting"
  },
  {
    "Document Index (generated)": 263,
    "Number of Records": 1,
    "Abstract": "Online social networking sites have become popular platforms on which users can link with each other and share information, not only basic rating information but also information such as contexts, social relationships, and item contents. However, as far as we know, no existing works systematically combine diverse types of information to build more accurate recommender systems. In this paper, we propose a novel context-aware hierarchical Bayesian method. First, we propose the use of spectral clustering for user-item subgrouping, so that users and items in similar contexts are grouped. We then propose a novel hierarchical Bayesian model that can make predictions for each user-item subgroup, our model incorporate not only topic modeling to mine item content but also social matrix factorization to handle ratings and social relationships. Experiments on an Epinions dataset show that our method significantly improves recommendation performance compared with six categories of state-of-the-art recommendation methods in terms of both prediction accuracy and recall. We have also conducted experiments to study the extent to which ratings, contexts, social relationships, and item contents contribute to recommendation performance in terms of prediction accuracy and recall.",
    "Authors1": "Chaochao Chen",
    "Authors2": "Xiaolin Zheng",
    "Authors3": "Yan Wang",
    "Authors4": "Fuxing Hong",
    "Authors5": "Zhen Lin",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Chaochao Chen, Xiaolin Zheng, Yan Wang, Fuxing Hong , Zhen Lin",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW)",
    "Keywords10": "",
    "Keywords1": "Context-awareness",
    "Keywords2": "Topic modeling",
    "Keywords3": "Matrix Factorization",
    "Keywords4": "Social Networks",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Context-awareness;Topic modeling;Matrix Factorization;Social Networks",
    "Title": "Context-aware Collaborative Topic Regression with Social Matrix Factorization for Recommender Systems",
    "Topics10": "",
    "Topics1": "AIW: Web-based recommendation systems",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: Web-based recommendation systems"
  },
  {
    "Document Index (generated)": 264,
    "Number of Records": 1,
    "Abstract": "Visual salience has been considered as an intriguing phenomenon observed in biologic neural systems. Numerous efforts have been made on mathematical modeling of visual salience using various feature contrasts, either locally or at global range. However, these algorithmic models treat this biologic phenomenon more like a mathematic problem and somehow ignores its biological instinct that visual salience arouses from the deep propagation of visual stimuli along the visual cortex. In this paper, we present a Deep Salience model that emulates this bio-inspired task, where a multi-layer successive Markov random fields (sMRF) is proposed to analyze the input image successively through its deep belief propagation. As its outcome, the foreground object can be automatically separated from the background in a fully unsupervised way. Experimental evaluation on benchmark datasets validated that our model can consistently outperform state-of-the-art salience models, yielding the highest recall rates, precision and F-measure scores in object detection. With this experimental validation, it is shown that the proposed bio-plausible deep belief network as an emulation of successive visual signal propagation along human visual cortex can functionally work well on solving real-world computational problems.",
    "Authors1": "Richard Jiang",
    "Authors2": "",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Richard Jiang",
    "Groups1": "Robotics (ROB)",
    "Groups2": "Vision (VIS)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Robotics (ROB);Vision (VIS)",
    "Keywords10": "",
    "Keywords1": "Visual Salience",
    "Keywords2": "Gaze Modelling",
    "Keywords3": "Deep Belief Propagation",
    "Keywords4": "Random Field",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Visual Salience;Gaze Modelling;Deep Belief Propagation;Random Field",
    "Title": "Deep Salience: Visual Salience Modeling via Deep Belief Propagation",
    "Topics10": "",
    "Topics1": "CM: Cognitive Architectures",
    "Topics2": "ROB: Cognitive Robotics",
    "Topics3": "VIS: Object Detection",
    "Topics4": "VIS: Perception",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "CM: Cognitive Architectures;ROB: Cognitive Robotics;VIS: Object Detection;VIS: Perception"
  },
  {
    "Document Index (generated)": 265,
    "Number of Records": 1,
    "Abstract": "The local neighborhood  selection plays a crucial role for most representation based manifold learning algorithms. This paper reveals that an improper selection of neighborhood for learning representation will introduce negative components in the learnt representations. Importantly, the representations with negative components will affect the intrinsic manifold structure preservation. In this paper, a local non-negative pursuit (LNP) method is proposed for neighborhood selection and non-negative representations are learnt. Moreover, it is proved that the learnt representations are sparse and convex. Theoretical analysis and experimental results show that the proposed method achieves or outperforms the state-of-the-art results on various manifold learning problems.",
    "Authors1": "Dongdong Chen",
    "Authors2": "Jian Cheng Lv",
    "Authors3": "Yi Zhang",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Dongdong Chen, Jian Cheng Lv , Yi Zhang",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "neighborhood selection",
    "Keywords2": "non-negative representation learning",
    "Keywords3": "intrinsic manifold structure preservation",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "neighborhood selection;non-negative representation learning;intrinsic manifold structure preservation",
    "Title": "A Local Non-negative Pursuit Method for Intrinsic Manifold Structure Preservation",
    "Topics10": "",
    "Topics1": "NMLA: Clustering",
    "Topics2": "NMLA: Dimension Reduction/Feature Selection",
    "Topics3": "NMLA: Unsupervised Learning (Other)",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Clustering;NMLA: Dimension Reduction/Feature Selection;NMLA: Unsupervised Learning (Other)"
  },
  {
    "Document Index (generated)": 266,
    "Number of Records": 1,
    "Abstract": "Stackelberg security games (SSGs) have been deployed a number of real-world security domains. One key challenge in these applications is the assessment of attacker payoffs which may not be perfectly known. Previous work has studied SSGs with uncertain payoffs modeled by interval uncertainty and maximin-based robust optimization. In contrast, this paper is the first to propose the use of the less conservative minimax regret as a decision criterion for payoff-uncertain SSGs\nand to present several algorithms for computing minimax regret for such games. This paper also for the first time addresses the challenge of preference elicitation in SSGs, providing novel regret-based solution strategies. Experimental results validate the runtime performance and solution quality of our approaches.",
    "Authors1": "Thanh Nguyen",
    "Authors2": "Amulya Yadav",
    "Authors3": "Bo An",
    "Authors4": "Milind Tambe",
    "Authors5": "Craig Boutilier",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Thanh Nguyen, Amulya Yadav, Bo An, Milind Tambe , Craig Boutilier",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP)",
    "Keywords10": "",
    "Keywords1": "security game",
    "Keywords2": "robust optimization",
    "Keywords3": "minimax regret",
    "Keywords4": "preference elicitation",
    "Keywords5": "payoff uncertainty",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "security game;robust optimization;minimax regret;preference elicitation;payoff uncertainty",
    "Title": "Regret-based Optimization and Preference Elicitation for Stackelberg Security Games with Uncertainty",
    "Topics10": "",
    "Topics1": "GTEP: Game Theory",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Game Theory"
  },
  {
    "Document Index (generated)": 267,
    "Number of Records": 1,
    "Abstract": "Greedy Best-First Search (GBFS) is a powerful algorithm at the heart of many state of the art satisficing planners. One major weakness of GBFS is its behavior in so-called uninformative heuristic regions (UHR) - parts of the search space in which no heuristic provides guidance towards states with improved heuristic values. In such regions, GBFS degenerates into an inefficient breadth-first type search.\nThis work analyzes the problem of UHR in planning in detail, and proposes a two level search framework as a solution. In Greedy Best-First Search with Local Exploration (GBFS-LE), local exploration is started from within a global GBFS whenever the search seems stuck in UHRs.\n\nTwo different local exploration strategies are developed and evaluated experimentally: Local GBFS (LS) and Local Random Walk Search (LRW). The two new planners LAMA-LS and LAMA-LRW integrate these strategies into the GBFS component of LAMA-2011. Both are shown to yield clear improvements in terms of both coverage and search time on standard International Planning Competition benchmarks, especially for domains that are proven to have large or unbounded UHRs.",
    "Authors1": "Fan Xie",
    "Authors2": "Martin Mueller",
    "Authors3": "Robert Holte",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Fan Xie, Martin Mueller , Robert Holte",
    "Groups1": "Heuristic Search and Optimization (HSO)",
    "Groups2": "Planning and Scheduling (PS)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Heuristic Search and Optimization (HSO);Planning and Scheduling (PS)",
    "Keywords10": "",
    "Keywords1": "Heuristic Search",
    "Keywords2": "Satisficing Planning",
    "Keywords3": "Greedy Best First Search",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Heuristic Search;Satisficing Planning;Greedy Best First Search",
    "Title": "Adding Local Exploration to Greedy Best-First Search for Satisficing Planning",
    "Topics10": "",
    "Topics1": "HSO: Heuristic Search",
    "Topics2": "HSO: Search (General/Other)",
    "Topics3": "PS: Deterministic Planning",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "HSO: Heuristic Search;HSO: Search (General/Other);PS: Deterministic Planning"
  },
  {
    "Document Index (generated)": 268,
    "Number of Records": 1,
    "Abstract": "Word embedding aims to learn a continuous representation for each word. It attracts increasing attention due to its effectiveness in various tasks such as named entity recognition and language modeling. Most existing word embedding results are generally trained on one individual data source such as news pages or Wikipedia articles. However, when we apply them to other tasks such as web search, the performance suffers. To obtain a robust word embedding for different applications, multiple data sources could be leveraged. In this paper, we proposed a two-side multimodal neural network to learn a robust word embedding from multiple data sources including free text, user search queries and search click-through data. This framework takes the word embeddings learned from different data sources as pre-train, and then uses a two-side neural network to unify these embeddings. The pre-trained embeddings are obtained by adapting the recently proposed CBOW algorithm. Since the proposed neural network does not need to re-train word embeddings for a new task, it is highly scalable in real world problem solving. Besides, the network allows weighting different sources differently when applied to different application tasks. Experiments on two real-world applications including web search ranking and word similarity measuring show that our neural network with multiple sources outperforms state-of-the-art word embedding algorithm with each individual source. It also outperforms other competitive baselines using multiple sources.",
    "Authors1": "Yong Luo",
    "Authors2": "Jian Tang",
    "Authors3": "Jun Yan",
    "Authors4": "Chao Xu",
    "Authors5": "Zheng Chen",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Yong Luo, Jian Tang, Jun Yan, Chao Xu , Zheng Chen",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "Novel Machine Learning Algorithms (NMLA)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW);Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "word embedding",
    "Keywords2": "neural network",
    "Keywords3": "pre-train",
    "Keywords4": "multiple data sources",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "word embedding;neural network;pre-train;multiple data sources",
    "Title": "Pre-trained Multi-view Word Embedding using Two-side Neural Network",
    "Topics10": "",
    "Topics1": "AIW: Machine learning and the web",
    "Topics2": "NMLA: Neural Networks/Deep Learning",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: Machine learning and the web;NMLA: Neural Networks/Deep Learning"
  },
  {
    "Document Index (generated)": 269,
    "Number of Records": 1,
    "Abstract": "Online social networks have been used for a variety of rich activities in recent years, such as investigating potential employees or seeking recommendations of high quality services and service providers. In such activities trust is one of the most vital factors for users' decision-making. In the literature, the state-of-the-art trust prediction approaches either focus on dispositional bias and propagated trust value of the pair-wise trust relationship along a path or on the similarity of trust rating values.  However, another factor, the distribution of trust ratings, also affects the trust between users. In addition, bias, propagated trust and similarity are of different types,  but were treated the same. Therefore, how to utilize the factors needs further improvement. In this paper we propose a new trust prediction model based on trust decomposition and matrix factorization, considering all the above essential factors to predict the trust between two users who are not directly connected. In this model, we firstly decompose trust into biased trust and bias-reduced trust. Then based on bias-reduced trust ratings, matrix factorization with a similarity regularization term, which takes advantages of both users' rating habits and propagated trust, is proposed to predict missing trust values. In the end, the missing trust is recomposed with predicted trust values and bias. Experiments conducted on a real-world dataset illustrate significantly improved prediction accuracy over the state-of-the-art approaches.",
    "Authors1": "Xiaoming Zheng",
    "Authors2": "Yan Wang",
    "Authors3": "Mehmet Orgun",
    "Authors4": "Youliang Zhong",
    "Authors5": "Guanfeng Liu",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Xiaoming Zheng, Yan Wang, Mehmet Orgun, Youliang Zhong , Guanfeng Liu",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "Applications (APP)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW);Applications (APP)",
    "Keywords10": "",
    "Keywords1": "Trust prediction",
    "Keywords2": "Social network",
    "Keywords3": "Trust propagation",
    "Keywords4": "Trust tendency",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Trust prediction;Social network;Trust propagation;Trust tendency",
    "Title": "Trust Prediction with Propagation and Similarity Regularization",
    "Topics10": "",
    "Topics1": "AIW: Representing, reasoning, and using provenance, trust, privacy, and security on the web",
    "Topics2": "APP: Social Networks",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: Representing, reasoning, and using provenance, trust, privacy, and security on the web;APP: Social Networks"
  },
  {
    "Document Index (generated)": 270,
    "Number of Records": 1,
    "Abstract": "Recently, some recommendation methods try to improve the prediction results by integrating information from user’s multiple types of behaviors. How to model the dependence and independence between different behaviors is critical for them. In this paper, we propose a novel recommendation model, the Group-Sparse Matrix Factorization (GSMF), which factorizes the rating matrices for multiple behaviors into the user and item latent factor space with group sparsity regularization. It can (1) select out the different subsets of latent factors for different behaviors, addressing that users’ decisions on different behaviors are determined by different sets of factors; (2) model the dependence and independence between behaviors by learning the shared and private factors for multiple behaviors automatically; (3) allow the shared factors between different behaviors to be different, instead of all the behaviors sharing the same set of factors. Experiments on the real-world dataset demonstrate that our model can integrate users’multiple types of behaviors into recommendation better, compared with other state-of-the-arts.",
    "Authors1": "Ting Yuan",
    "Authors2": "Jian Cheng",
    "Authors3": "Xi Zhang",
    "Authors4": "Shuang Qiu",
    "Authors5": "Hanqing Lu",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Ting Yuan, Jian Cheng, Xi Zhang, Shuang Qiu , Hanqing Lu",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW)",
    "Keywords10": "",
    "Keywords1": "Recommender System",
    "Keywords2": "Collaborative Filtering",
    "Keywords3": "Matrix Factorization",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Recommender System;Collaborative Filtering;Matrix Factorization",
    "Title": "Recommendation by Mining Multiple User Behaviors with Group Sparsity",
    "Topics10": "",
    "Topics1": "AIW: Web-based recommendation systems",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: Web-based recommendation systems"
  },
  {
    "Document Index (generated)": 271,
    "Number of Records": 1,
    "Abstract": "Motivated by applications to crowdsourcing, we study voting rules that output a correct ranking of alternatives by quality from a large collection of noisy input rankings. We seek voting rules that are supremely robust to noise, in the sense of being correct in the face of any \"reasonable\" type of noise. We show that there is such a voting rule, which we call the modal ranking rule. Moreover, we establish that the modal ranking rule is the unique rule with the preceding robustness property within a large family of voting rules, which includes a slew of well-studied rules.",
    "Authors1": "Ioannis Caragiannis",
    "Authors2": "Ariel Procaccia",
    "Authors3": "Nisarg Shah",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Ioannis Caragiannis, Ariel Procaccia , Nisarg Shah",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP)",
    "Keywords10": "",
    "Keywords1": "Computational social choice",
    "Keywords2": "Crowdsourcing",
    "Keywords3": "Noise models",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Computational social choice;Crowdsourcing;Noise models",
    "Title": "Modal Ranking: A Uniquely Robust Voting Rule",
    "Topics10": "",
    "Topics1": "GTEP: Social Choice / Voting",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Social Choice / Voting"
  },
  {
    "Document Index (generated)": 272,
    "Number of Records": 1,
    "Abstract": "This paper proposes the Proximal Iteratively REweighted (PIRE) algorithm for solving a general problem, which involves a large body of nonconvex sparse and structured sparse related problems. Comparing with previous iterative solvers for nonconvex sparse problem, PIRE is much more general and efficient. The computational cost of PIRE in each iteration is usually as low as the state-of-the-art convex solvers. We further propose the PIRE algorithm with Parallel Splitting (PIRE-PS) and PIRE algorithm with Alternative Updating (PIRE-AU) to handle the multi-variable problems. In theory, we prove that our proposed methods converge and any limit solution is a stationary point. Extensive experiments on both synthesis and real data sets demonstrate that our methods achieve comparative learning performance, but are much more efficient, by comparing with previous nonconvex solvers.",
    "Authors1": "Canyi Lu",
    "Authors2": "Yunchao Wei",
    "Authors3": "Zhouchen Lin",
    "Authors4": "Shuicheng Yan",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Canyi Lu, Yunchao Wei, Zhouchen Lin , Shuicheng Yan",
    "Groups1": "Machine Learning Applications (MLA)",
    "Groups2": "Novel Machine Learning Algorithms (NMLA)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Machine Learning Applications (MLA);Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "Nonconvex Sparsity Optimization",
    "Keywords2": "General iterative solver",
    "Keywords3": "multiple splitting for multi-variable problem",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Nonconvex Sparsity Optimization;General iterative solver;multiple splitting for multi-variable problem",
    "Title": "Proximal Iteratively Reweighted Algorithm with Multiple Splitting for Nonconvex Sparsity Optimization",
    "Topics10": "",
    "Topics1": "NMLA: Machine Learning (General/other)",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Machine Learning (General/other)"
  },
  {
    "Document Index (generated)": 273,
    "Number of Records": 1,
    "Abstract": "An important subclass of social choice functions, so-called majoritarian (or C1) functions, only take into account the pairwise majority relation between alternatives. In the absence of majority ties--e.g., when there is an odd number of agents with linear preferences--the majority relation is antisymmetric and complete and can thus conveniently be represented by a tournament. Tournaments have a rich mathematical theory and many formal results for majoritarian functions assume that the majority relation constitutes a tournament. Moreover, most majoritarian functions have only been defined for tournaments and allow for a variety of generalizations to unrestricted preference profiles, none of which can be seen as the unequivocal extension of the original function. In this paper, we argue that restricting attention to tournaments is justified by the existence of a conservative extension, which inherits most of the commonly considered properties from its underlying tournament solution.",
    "Authors1": "Felix Br",
    "Authors2": "t",
    "Authors3": "Markus Brill",
    "Authors4": "Paul Harrenstein",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Felix Br,t, Markus Brill , Paul Harrenstein",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP)",
    "Keywords10": "",
    "Keywords1": "Social Choice Theory",
    "Keywords2": "Tournament Solutions",
    "Keywords3": "Possible Winners",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Social Choice Theory;Tournament Solutions;Possible Winners",
    "Title": "Extending Tournament Solutions",
    "Topics10": "",
    "Topics1": "GTEP: Social Choice / Voting",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Social Choice / Voting"
  },
  {
    "Document Index (generated)": 274,
    "Number of Records": 1,
    "Abstract": "We present a novel approach to low-dimensional neighbor embedding for visualization: we formulate an information retrieval based neighborhood preservation cost function as Maximum satisfiability on a discretized output display, and maximize the number of clauses preserved. The method has a rigorous interpretation as optimal visualization for neighbor retrieval. Unlike previous low-dimensional neighbor embedding methods, our satisfiability formulation is guaranteed to yield a global optimum and does so reasonably fast. Unlike previous manifold learning methods yielding global optima of their cost functions, our cost function and method are designed for low-dimensional visualization where evaluation and minimization of visualization errors are crucial. Our method performs well in experiments, yielding clean embeddings of data sets where a state-of-the-art comparison method yields poor arrangements. In a real-world case study for semi-supervised WLAN positioning in buildings we outperform state-of-the-art methods, especially when having few measurements.",
    "Authors1": "Kerstin Bunte",
    "Authors2": "Matti Järvisalo",
    "Authors3": "Jeremias Berg",
    "Authors4": "Petri Myllymäki",
    "Authors5": "Jaakko Peltonen",
    "Authors6": "Samuel Kaski",
    "Authors7": "",
    "Authors": "Kerstin Bunte, Matti Järvisalo, Jeremias Berg, Petri Myllymäki, Jaakko Peltonen , Samuel Kaski",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "Search and Constraint Satisfaction (SCS)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA);Search and Constraint Satisfaction (SCS)",
    "Keywords10": "",
    "Keywords1": "visualization",
    "Keywords2": "boolean optimization",
    "Keywords3": "maximum satisfiability",
    "Keywords4": "nonlinear dimensionality reduction",
    "Keywords5": "neighbor embedding",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "visualization;boolean optimization;maximum satisfiability;nonlinear dimensionality reduction;neighbor embedding",
    "Title": "Optimal Neighborhood Preserving Visualization by Maximum Satisfiability",
    "Topics10": "",
    "Topics1": "NMLA: Dimension Reduction/Feature Selection",
    "Topics2": "NMLA: Unsupervised Learning (Other)",
    "Topics3": "SCS: Constraint Optimization",
    "Topics4": "SCS: SAT and CSP: Modeling/Formulations",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Dimension Reduction/Feature Selection;NMLA: Unsupervised Learning (Other);SCS: Constraint Optimization;SCS: SAT and CSP: Modeling/Formulations"
  },
  {
    "Document Index (generated)": 275,
    "Number of Records": 1,
    "Abstract": "Collaborative filtering algorithms generally rely on the assumption that user preference patterns remain stationary. However, real-world relational data are seldom stationary. User preference patterns may change over time, giving rise to the requirement of designing collaborative filtering systems capable of detecting and adapting to preference pattern shifts. Motivated by this observation, in this paper we propose a dynamic Bayesian probabilistic matrix factorization model, designed for modeling time-varying distributions. Formulation of our model is based on imposition of a dynamic hierarchical Dirichlet process (dHDP) prior over the space of probabilistic matrix factorization models to capture the time-evolving statistical properties of modeled sequential relational datasets. We develop a simple Markov Chain Monte Carlo sampler to perform inference. We present experimental results to demonstrate the superiority of our temporal model.",
    "Authors1": "Sotirios Chatzis",
    "Authors2": "",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Sotirios Chatzis",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "Reasoning under Uncertainty (RU)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA);Reasoning under Uncertainty (RU)",
    "Keywords10": "",
    "Keywords1": "Probabilistic Matrix Factorization",
    "Keywords2": "Dynamic Hierarchical Dirichlet Process",
    "Keywords3": "Bayesian Nonparametrics",
    "Keywords4": "Collaborative Filtering",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Probabilistic Matrix Factorization;Dynamic Hierarchical Dirichlet Process;Bayesian Nonparametrics;Collaborative Filtering",
    "Title": "Dynamic Bayesian Probabilistic Matrix Factorization",
    "Topics10": "",
    "Topics1": "NMLA: Bayesian Learning",
    "Topics2": "NMLA: Preferences/Ranking Learning",
    "Topics3": "NMLA: Recommender Systems",
    "Topics4": "RU: Probabilistic Inference",
    "Topics5": "RU: Relational Probabilistic Models",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Bayesian Learning;NMLA: Preferences/Ranking Learning;NMLA: Recommender Systems;RU: Probabilistic Inference;RU: Relational Probabilistic Models"
  },
  {
    "Document Index (generated)": 276,
    "Number of Records": 1,
    "Abstract": "Restricted Boltzmann machines (RBMs) are a powerful generative modeling technique, based on a complex graphical model of hidden (latent) variables. Conditional RBMs (CRBMs) are an extension of RBMs tailored to modeling temporal data. A drawback of CRBMs is their consideration of linear temporal dependencies, which limits their capability to capture complex temporal structure. They also require many variables to model long temporal dependencies, a fact that might provoke overfitting proneness. To resolve these issues, in this paper we propose the echo-state CRBM (ES-CRBM): our model uses an echo-state network reservoir in the context of CRBMs to efficiently capture long and complex temporal dynamics, with much fewer trainable parameters compared to conventional CRBMs. In addition, we introduce an (implicit) mixture of ES-CRBM experts (im-ES-CRBM) to enhance even further the capabilities of our ES-CRBM model. The introduced im-ES-CRBM allows for better modeling temporal observations which might comprise a number of latent or observable subpatterns that alternate in a dynamic fashion. It also allows for performing sequence segmentation using our framework. We apply our methods to sequential data modeling and classification experiments using public datasets. As we show, our approach outperforms both existing RBM-based approaches as well as related state-of-the-art methods, such as conditional random fields.",
    "Authors1": "Sotirios Chatzis",
    "Authors2": "",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Sotirios Chatzis",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "Conditional Restricted Boltzmann Machine",
    "Keywords2": "Echo-State Network",
    "Keywords3": "Contrastive Divergence",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Conditional Restricted Boltzmann Machine;Echo-State Network;Contrastive Divergence",
    "Title": "Echo-State Conditional Restricted Boltzmann Machines",
    "Topics10": "",
    "Topics1": "NMLA: Neural Networks/Deep Learning",
    "Topics2": "NMLA: Time-Series/Data Streams",
    "Topics3": "NMLA: Structured Prediction",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Neural Networks/Deep Learning;NMLA: Time-Series/Data Streams;NMLA: Structured Prediction"
  },
  {
    "Document Index (generated)": 277,
    "Number of Records": 1,
    "Abstract": "As an effective technology for navigating a large number of images, image summarization is becoming a promising task with the rapid development of image sharing sites and social networks. Most existing summarization approaches use the visual-based features for image representation without considering tag information. In this paper, we propose a novel framework, named JOINT, which employs both image content and tag information to summarize images. Our model generates the summary images which can best reconstruct the original collection. Based on the assumption that an image with representative content should also have typical tags, we introduce a similarity-inducing regularizer to our model. Furthermore, we impose the lasso penalty on the objective function to yield a concise summary set. Extensive experiments demonstrate our model outperforms the state-of-the-art approaches.",
    "Authors1": "Hongliang Yu",
    "Authors2": "Zhi-Hong Deng",
    "Authors3": "Yunlun Yang",
    "Authors4": "Tao Xiong",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Hongliang Yu, Zhi-Hong Deng, Yunlun Yang , Tao Xiong",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "Machine Learning Applications (MLA)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW);Machine Learning Applications (MLA)",
    "Keywords10": "",
    "Keywords1": "image summarization",
    "Keywords2": "image tags",
    "Keywords3": "optimization model",
    "Keywords4": "similarity-inducing regularizer",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "image summarization;image tags;optimization model;similarity-inducing regularizer",
    "Title": "A Joint Optimization Model for Image Summarization Based on Image Content and Tags",
    "Topics10": "",
    "Topics1": "AIW: AI for multimedia and multimodal web applications",
    "Topics2": "MLA: Machine Learning Applications (General/other)",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: AI for multimedia and multimodal web applications;MLA: Machine Learning Applications (General/other)"
  },
  {
    "Document Index (generated)": 278,
    "Number of Records": 1,
    "Abstract": "MSS (Maximal Satisﬁable Subset) and CoMSS (also called Minimal Correction Subset) concepts play a key role in many A.I. approaches and techniques. In this paper, a novel algorithm for partitioning a Boolean CNF into one MSS and its corresponding CoMSS is introduced. Extensive empirical evaluation shows that it is more robust and more efﬁcient on most instances than currently available techniques.",
    "Authors1": "Jean Marie Lagniez",
    "Authors2": "Eric Gregoire",
    "Authors3": "Bertr",
    "Authors4": "Mazure",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Jean Marie Lagniez, Eric Gregoire , Bertr, Mazure",
    "Groups1": "Heuristic Search and Optimization (HSO)",
    "Groups2": "Search and Constraint Satisfaction (SCS)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Heuristic Search and Optimization (HSO);Search and Constraint Satisfaction (SCS)",
    "Keywords10": "",
    "Keywords1": "SAT",
    "Keywords2": "CoMSS",
    "Keywords3": "MSS",
    "Keywords4": "Maximal Satisﬁable Subset",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "SAT;CoMSS;MSS;Maximal Satisﬁable Subset",
    "Title": "A Computational Method for (MSS,CoMSS) Partitioning",
    "Topics10": "",
    "Topics1": "HSO: Search (General/Other)",
    "Topics2": "SCS: Constraint Satisfaction",
    "Topics3": "SCS: SAT and CSP: Solvers and Tools",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "HSO: Search (General/Other);SCS: Constraint Satisfaction;SCS: SAT and CSP: Solvers and Tools"
  },
  {
    "Document Index (generated)": 279,
    "Number of Records": 1,
    "Abstract": "Feature selection plays an important role in many machine\nlearning and data mining applications. In this paper,\nwe propose to use L2,p norm for feature selection\nwith emphasis on small p. As p appoaches 0, feature selection\nbecomes discrete feature selection problem.We provide\ntwo algorithms, proximal gradient algorithm and rank one\nupdate algorithm, which is more efficient at large\nregularization . Experiments on real life data sets show\nthat features selected at small p consistently outperform\nfeatures selected at p = 1, the standard L2,1 approach\nand other popular feature selection methods.",
    "Authors1": "Miao Zhang",
    "Authors2": "Chris Ding",
    "Authors3": "Ya Zhang",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Miao Zhang, Chris Ding , Ya Zhang",
    "Groups1": "Machine Learning Applications (MLA)",
    "Groups2": "Novel Machine Learning Algorithms (NMLA)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Machine Learning Applications (MLA);Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "feature selection",
    "Keywords2": "sparse",
    "Keywords3": "L2p norm",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "feature selection;sparse;L2p norm",
    "Title": "Feature Selection at the Discrete Limit",
    "Topics10": "",
    "Topics1": "NMLA: Dimension Reduction/Feature Selection",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Dimension Reduction/Feature Selection"
  },
  {
    "Document Index (generated)": 280,
    "Number of Records": 1,
    "Abstract": "This paper focuses on computing general first-order parallel and prioritized circumscription with varied constants. We propose polynomial translations from general first-order circumscription to first-order stable model semantics over arbitrary structures, including $Tr_v$ for parallel circumscription and $Tr^s_v$ for several parallel circumscriptions (further for prioritized circumscription). To improve the efficiency, we give an optimization, called $\\Gamma_{\\exists}$, to reduce auxiliary predicates in number and logic programs in size when eliminating existential quantifiers during the translations. Based on these results, a general first-order circumscription solver, named cfo2lp, is developed by calling answer set programming solvers. Using circuit diagnosis problem and extended stable marriage problem as benchmarks, we compare cfo2lp with a propositional circumscription solver circ2dlp on efficiency. Experimental results demonstrate that for problems represented by general first-order circumscription naturally and intuitively, cfo2lp can compute all solutions over finite structures. We also apply our approach to description logics with circumscription and repairs in inconsistent databases, which can be handled effectively.",
    "Authors1": "Hai Wan",
    "Authors2": "Zhanhao Xiao",
    "Authors3": "Yuan Zhenfeng",
    "Authors4": "Heng Zhang",
    "Authors5": "Yan Zhang",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Hai Wan, Zhanhao Xiao, Yuan Zhenfeng, Heng Zhang , Yan Zhang",
    "Groups1": "Knowledge Representation and Reasoning (KRR)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Knowledge Representation and Reasoning (KRR)",
    "Keywords10": "",
    "Keywords1": "first-order parallel and prioritized circumscription",
    "Keywords2": "first-order stable model semantics",
    "Keywords3": "translation",
    "Keywords4": "optimization",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "first-order parallel and prioritized circumscription;first-order stable model semantics;translation;optimization",
    "Title": "Computing General First-order Parallel and Prioritized Circumscription",
    "Topics10": "",
    "Topics1": "KRR: Common-Sense Reasoning",
    "Topics2": "KRR: Nonmonotonic Reasoning",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "KRR: Common-Sense Reasoning;KRR: Nonmonotonic Reasoning"
  },
  {
    "Document Index (generated)": 281,
    "Number of Records": 1,
    "Abstract": "Distributed representations of words (aka word embedding) have been proven helpful in solving NLP tasks. Training distributed representations of words with neural networks has received much attention of late. Especially, the most recent work on word embedding, the Continuous Bag-of-Words (CBOW) model and the Continuous Skip-gram (Skip-gram) model proposed by Google, shows very impressive results by significantly speeding up the training process to enable word representation learning from very large-scale data. However, both CBOW and Skip-gram do not pay enough attention to the word proximity in terms of model or the word ambiguity in terms of linguistics. In this paper, we propose Proximity-Ambiguity Sensitive (PAS) models (i.e. PAS CBOW and PAS Skip-gram) for producing high quality distributed representations of words considering both word proximity and ambiguity. From the model perspective, we introduce proximity weights as parameters to be learned in PAS CBOW and used in PAS Skip-gram. By better modeling word proximity, we reveal the real strength of the pooling-structured neural networks in word representation learning. The proximity-sensitive pooling layer can also be applied to other neural network applications that employ pooling layers. From the linguistics perspective, we train multiple representation vectors per word. Each representation vector corresponds to a particular sense of the word. By using PAS models, we achieved a maximum accuracy increase of 16.9% over the state-of-the-art models on the word representation test set.",
    "Authors1": "Lin Qiu",
    "Authors2": "Yong Cao",
    "Authors3": "Zaiqing Nie",
    "Authors4": "Yong Rui",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Lin Qiu, Yong Cao, Zaiqing Nie , Yong Rui",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "Machine Learning Applications (MLA)",
    "Groups3": "NLP and Knowledge Representation (NLPKR)",
    "Groups4": "NLP and Machine Learning (NLPML)",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW);Machine Learning Applications (MLA);NLP and Knowledge Representation (NLPKR);NLP and Machine Learning (NLPML)",
    "Keywords10": "",
    "Keywords1": "word proximity",
    "Keywords2": "word ambiguity",
    "Keywords3": "neural networks",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "word proximity;word ambiguity;neural networks",
    "Title": "Learning Word Representation Considering Proximity and Ambiguity",
    "Topics10": "",
    "Topics1": "AIW: Knowledge acquisition from the web",
    "Topics2": "AIW: Machine learning and the web",
    "Topics3": "MLA: Applications of Unsupervised Learning",
    "Topics4": "NLPKR: Natural Language Processing (General/Other)",
    "Topics5": "NLPML: Natural Language Processing (General/Other)",
    "Topics6": "NMLA: Neural Networks/Deep Learning",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: Knowledge acquisition from the web;AIW: Machine learning and the web;MLA: Applications of Unsupervised Learning;NLPKR: Natural Language Processing (General/Other);NLPML: Natural Language Processing (General/Other);NMLA: Neural Networks/Deep Learning"
  },
  {
    "Document Index (generated)": 282,
    "Number of Records": 1,
    "Abstract": "Planning in hybrid domains is an important and challenging task, and\nvarious planning algorithms have been proposed in the last years.\nFrom an abstract point of view, hybrid planning domains are based on\nhybrid automata, which have been studied intensively in the model\nchecking community. In particular, powerful model checking\nalgorithms and tools have emerged for this formalism. However,\ndespite the quest for more scalable planning approaches, model\nchecking algorithms have not been applied to planning in hybrid\ndomains so far.\n                                      \nIn this paper, we make a first step in bridging the gap between\nthese two worlds. We provide a formal translation scheme from PDDL+\nto the standard formalism of hybrid automata, as a solid basis for\nusing hybrid system model-checking tools for dealing with hybrid\nplanning domains. As a case study, we use the SpaceEx model checker,\nshowing how we can address PDDL+ domains that are out of the scope\nof state-of-the-art planners.",
    "Authors1": "Sergiy Bogomolov",
    "Authors2": "Daniele Magazzeni",
    "Authors3": "Andreas Podelski",
    "Authors4": "Martin Wehrle",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Sergiy Bogomolov, Daniele Magazzeni, Andreas Podelski , Martin Wehrle",
    "Groups1": "Planning and Scheduling (PS)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Planning and Scheduling (PS)",
    "Keywords10": "",
    "Keywords1": "Planning in Mixed Discrete-Continuous Domains",
    "Keywords2": "PDDL+",
    "Keywords3": "Model Checking",
    "Keywords4": "Hybrid Automata",
    "Keywords5": "Planning as Model Checking",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Planning in Mixed Discrete-Continuous Domains;PDDL+;Model Checking;Hybrid Automata;Planning as Model Checking",
    "Title": "Planning as Model Checking in Hybrid Domains",
    "Topics10": "",
    "Topics1": "PS: Mixed Discrete/Continuous Planning",
    "Topics2": "PS: Temporal Planning",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "PS: Mixed Discrete/Continuous Planning;PS: Temporal Planning"
  },
  {
    "Document Index (generated)": 283,
    "Number of Records": 1,
    "Abstract": "Density-based techniques seem promising for handling data\nuncertainty in uncertain data clustering. Nevertheless, some\nissues have not been addressed well in existing algorithms.\nIn this paper, we firstly propose a novel density-based uncertain\ndata clustering algorithm, which improves upon existing\nalgorithms from the following two aspects: (1) it employs\nan exact method to compute the probability that the distance\nbetween two uncertain objects is less than or equal to\na boundary value, instead of the sampling-based method in\nprevious work; (2) it introduces new definitions of core object\nprobability and direct reachability probability, thus reducing\nthe complexity and avoiding sampling. We then further improve\nthe algorithm by using a novel assignment strategy to\nensure that every object will be assigned to the most appropriate\ncluster. Experimental results show the superiority of\nour proposed algorithms over existing ones.",
    "Authors1": "Xianchao Zhang",
    "Authors2": "Han Liu",
    "Authors3": "Xiaotong Zhang",
    "Authors4": "Xinyue Liu",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Xianchao Zhang, Han Liu, Xiaotong Zhang , Xinyue Liu",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "Uncertain data",
    "Keywords2": "Clustering",
    "Keywords3": "Density-based algorithm",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Uncertain data;Clustering;Density-based algorithm",
    "Title": "Novel Density-based Clustering Algorithms for Uncertain Data",
    "Topics10": "",
    "Topics1": "NMLA: Clustering",
    "Topics2": "RU: Uncertainty in AI (General/Other)",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Clustering;RU: Uncertainty in AI (General/Other)"
  },
  {
    "Document Index (generated)": 284,
    "Number of Records": 1,
    "Abstract": "We consider the problem of parallelizing restarted backtrack search. With few notable exceptions, most commercial and academic constraint programming solvers do not learn no-goods during search. Depending on the branching heuristics used, this means that there are little to no side-effects between restarts, making them an excellent target for parallelization. We develop a simple technique for parallelizing restarted search deterministically and demonstrate experimentally that we can achieve near-linear speed-ups in practice.",
    "Authors1": "Andre Cire",
    "Authors2": "Serdar Kadioglu",
    "Authors3": "Meinolf Sellmann",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Andre Cire, Serdar Kadioglu , Meinolf Sellmann",
    "Groups1": "Heuristic Search and Optimization (HSO)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Heuristic Search and Optimization (HSO)",
    "Keywords10": "",
    "Keywords1": "Restarts",
    "Keywords2": "Parallel Search",
    "Keywords3": "Deterministic Parallelization",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Restarts;Parallel Search;Deterministic Parallelization",
    "Title": "Parallel Restarted Search",
    "Topics10": "",
    "Topics1": "HSO: Search (General/Other)",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "HSO: Search (General/Other)"
  },
  {
    "Document Index (generated)": 285,
    "Number of Records": 1,
    "Abstract": "Our objective is to boost the state-of-the-art performance in MaxSAT solving. To this end, we employ the instance-specific algorithm configurator ISAC and improve it by combining it with the latest in portfolio technology. Experimental results on SAT show that this combination marks a significant step forward in our ability to tune algorithms instance-specifically. We then apply the new methodology to a number of MaxSAT problem domains and show that the resulting solvers consistently outperform the best existing solvers on the respective problem families. In fact, the solvers presented here were independently evaluated at the 2013 MaxSAT Evaluation where they won six out of eleven categories.",
    "Authors1": "Carlos Ansotegui-Gil",
    "Authors2": "Yuri Malitsky",
    "Authors3": "Meinolf Sellmann",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Carlos Ansotegui-Gil, Yuri Malitsky , Meinolf Sellmann",
    "Groups1": "Search and Constraint Satisfaction (SCS)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Search and Constraint Satisfaction (SCS)",
    "Keywords10": "",
    "Keywords1": "MaxSAT",
    "Keywords2": "Algorithm Portfolios",
    "Keywords3": "Algorithm Tuning",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "MaxSAT;Algorithm Portfolios;Algorithm Tuning",
    "Title": "MaxSAT Portfolio",
    "Topics10": "",
    "Topics1": "SCS: Satisfiability (General/Other)",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "SCS: Satisfiability (General/Other)"
  },
  {
    "Document Index (generated)": 286,
    "Number of Records": 1,
    "Abstract": "Due to its low storage cost and fast query speed, hashing has been widely adopted for similarity search in multimedia data. In particular, more and more attentions have been payed to multimodal hashing for search in multimedia data with multiple modalities, such as images with tags. Typically, supervised information of semantic\nlabels is also available for the data points in many real applications. Hence, many supervised multimodal hashing~(SMH) methods have been proposed to utilize such semantic labels to further improve the search accuracy. However, the training time complexity of most existing SMH methods is too high, which makes them unscalable to large-scale datasets. In this paper, a novel SMH method, called semantic\ncorrelation maximization~(SCM), is proposed to seamlessly integrate semantic labels into the hashing learning procedure for large-scale data modeling. Experimental results on two real-world datasets show\nthat SCM can significantly outperform the state-of-the-art SMH methods, in terms of both accuracy and scalability.",
    "Authors1": "Dongqing Zhang",
    "Authors2": "Wu-Jun Li",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Dongqing Zhang , Wu-Jun Li",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "Vision (VIS)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA);Vision (VIS)",
    "Keywords10": "",
    "Keywords1": "Multimodal Hashing",
    "Keywords2": "Cross-view Similarity Search",
    "Keywords3": "Image Retrieval",
    "Keywords4": "Scalability",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Multimodal Hashing;Cross-view Similarity Search;Image Retrieval;Scalability",
    "Title": "Large-Scale Supervised Multimodal Hashing with Semantic Correlation Maximization",
    "Topics10": "",
    "Topics1": "NMLA: Big Data / Scalability",
    "Topics2": "NMLA: Supervised Learning (Other)",
    "Topics3": "VIS: Image and Video Retrieval",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Big Data / Scalability;NMLA: Supervised Learning (Other);VIS: Image and Video Retrieval"
  },
  {
    "Document Index (generated)": 287,
    "Number of Records": 1,
    "Abstract": "Conformity is the inclination of a person to be influenced by others. In this paper, we study how the conformity tendency of a person changes with her {\\em role}, as defined by her structural properties in a social network. We first formalize conformity using a utility function based on the conformity theory from social psychology, and validate the proposed utility function by proving the existence of Nash Equilibria when all users in a network behave according to it. We then extend and incorporate the utility function into a probabilistic topic model, called the Role-Conformity Model (RCM), for modeling user behaviors under the effect of conformity. We apply the proposed RCM to several academic research networks, and discover that people with higher degree and lower clustering coefficient are more likely to conform to others. We also evaluate RCM through the task of word usage prediction in academic publications, and show significant improvements over the performance of baselines.",
    "Authors1": "Jing Zhang",
    "Authors2": "Jie Tang",
    "Authors3": "Honglei Zhuang",
    "Authors4": "Cane Leung",
    "Authors5": "Juanzi Li",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Jing Zhang, Jie Tang, Honglei Zhuang, Cane Leung , Juanzi Li",
    "Groups1": "Applications (APP)",
    "Groups2": "Novel Machine Learning Algorithms (NMLA)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Applications (APP);Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "social conformity",
    "Keywords2": "role base conformity",
    "Keywords3": "probabilistic model",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "social conformity;role base conformity;probabilistic model",
    "Title": "Role-aware Conformity Modeling and Analysis in Social Networks",
    "Topics10": "",
    "Topics1": "APP: Computational Social Science",
    "Topics2": "NMLA: Data Mining and Knowledge Discovery",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "APP: Computational Social Science;NMLA: Data Mining and Knowledge Discovery"
  },
  {
    "Document Index (generated)": 288,
    "Number of Records": 1,
    "Abstract": "Ontology-based data access (OBDA) is a new paradigm aiming at\n  accessing and managing data by means of an ontology, i.e., a\n  conceptual representation of the domain of interest in the\n  underlying information system. In the last years, this new paradigm\n  has been used for providing users with abstract (independent from\n  technological and system-oriented aspects), effective, and\n  reasoning-intensive mechanisms for querying the data residing at the\n  information system sources. In this paper we argue that OBDA,\n  besides querying data, provides the right principles for devising a\n  formal approach to data quality. In particular, we concentrate on\n  one of the most important dimensions considered both in the\n  literature and in the practice of data quality, namely\n  consistency. We define a general framework for data consistency in\n  OBDA, and present algorithms and complexity analysis for several\n  relevant tasks related to the problem of checking data quality under\n  this dimension, both at the extensional level (content of the data\n  sources), and at the intensional level (schema of the data sources).",
    "Authors1": "Marco Console",
    "Authors2": "Maurizio Lenzerini",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Marco Console , Maurizio Lenzerini",
    "Groups1": "Knowledge Representation and Reasoning (KRR)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Knowledge Representation and Reasoning (KRR)",
    "Keywords10": "",
    "Keywords1": "Ontology-based data access",
    "Keywords2": "Description Logics",
    "Keywords3": "Data Quality",
    "Keywords4": "Data Management",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Ontology-based data access;Description Logics;Data Quality;Data Management",
    "Title": "Data Quality in Ontology-based Data Access: The Case of Consistency",
    "Topics10": "",
    "Topics1": "APP: Other Applications",
    "Topics2": "KRR: Ontologies",
    "Topics3": "KRR: Description Logics",
    "Topics4": "KRR: Knowledge Representation (General/Other)",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "APP: Other Applications;KRR: Ontologies;KRR: Description Logics;KRR: Knowledge Representation (General/Other)"
  },
  {
    "Document Index (generated)": 289,
    "Number of Records": 1,
    "Abstract": "We propose a new approach for metric learning by framing it as learning a sparse combination of locally discriminative metrics that are inexpensive to generate from the training data. This flexible framework allows us to naturally derive formulations for global, multi-task and local metric learning. These new algorithms have several advantages over existing methods in the literature: a much smaller number of parameters to be estimated and a principled way to generalize learned metrics to new testing data points. To analyze the approach theoretically, we derive a generalization bound that justifies the sparse combination. Empirically, we evaluate our algorithms on several datasets against state-of-the-art metric learning methods. The results are consistent with our theoretical findings and demonstrate the superiority of our approach in terms of classification performance and scalability.",
    "Authors1": "Yuan Shi",
    "Authors2": "Aurélien Bellet",
    "Authors3": "Fei Sha",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Yuan Shi, Aurélien Bellet , Fei Sha",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "Metric Learning",
    "Keywords2": "Sparse Methods",
    "Keywords3": "Local Metric Learning",
    "Keywords4": "Multi-task Learning",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Metric Learning;Sparse Methods;Local Metric Learning;Multi-task Learning",
    "Title": "Sparse Compositional Metric Learning",
    "Topics10": "",
    "Topics1": "NMLA: Classification",
    "Topics2": "NMLA: Dimension Reduction/Feature Selection",
    "Topics3": "NMLA: Transfer, Adaptation, Multitask Learning",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Classification;NMLA: Dimension Reduction/Feature Selection;NMLA: Transfer, Adaptation, Multitask Learning"
  },
  {
    "Document Index (generated)": 290,
    "Number of Records": 1,
    "Abstract": "Entity search is to retrieve a ranked list of named entities of target types to a given query. In this paper, we propose an approach of entity search by formalizing both context matching and category matching. In addition, we propose a result re-ranking strategy that can be easily adapted to achieve a hybrid of two context matching strategies. Experiments on the INEX 2009 entity ranking task show that the proposed approach achieves a significant improvement of the entity search performance (xinfAP from 0.27 to 0.39) over the existing solutions.",
    "Authors1": "Yueguo Chen",
    "Authors2": "Lexi Gao",
    "Authors3": "Shuming Shi",
    "Authors4": "Xiaoyong Du",
    "Authors5": "Ji-Rong Wen",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Yueguo Chen, Lexi Gao, Shuming Shi, Xiaoyong Du , Ji-Rong Wen",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW)",
    "Keywords10": "",
    "Keywords1": "entity search",
    "Keywords2": "language model",
    "Keywords3": "category matching",
    "Keywords4": "context matching",
    "Keywords5": "result re-ranking",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "entity search;language model;category matching;context matching;result re-ranking",
    "Title": "Improving Context and Category Matching for Entity Search",
    "Topics10": "",
    "Topics1": "AIW: Enhancing web search and information retrieval",
    "Topics2": "AIW: Question answering on the web",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: Enhancing web search and information retrieval;AIW: Question answering on the web"
  },
  {
    "Document Index (generated)": 291,
    "Number of Records": 1,
    "Abstract": "This paper studies the problem of instance alignment between knowledge bases (KBs). Existing approaches, exploiting the \"symmetry\" of structure and information across KBs, suffer in the presence of asymmetry, which is frequent as KBs are independently built. Specifically, we observe three types of asymmetry -- concept, feature, and structural asymmetry. The goal of this paper is to identify key techniques for overcoming each type of asymmetry, then build them into a framework that robustly aligns matches over asymmetry. In particular, we propose an Asymmetry-Resistant Instance Alignment framework (ARIA), implementing two-phased blocking methods considering concept and feature asymmetry, with a novel similarity measure overcoming structural asymmetry. Our evaluation results validate that this framework outperforms state-of-the-arts in terms of both response time and accuracy, by increasing 18% in precision and 2% in recall in matching large-scale real-life KBs.",
    "Authors1": "Sanghoon Lee",
    "Authors2": "Seung-Won Hwang",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Sanghoon Lee , Seung-Won Hwang",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW)",
    "Keywords10": "",
    "Keywords1": "instance alignment",
    "Keywords2": "entity matching",
    "Keywords3": "resolution",
    "Keywords4": "deduplication",
    "Keywords5": "linkage",
    "Keywords6": "linked data",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "instance alignment;entity matching;resolution;deduplication;linkage;linked data",
    "Title": "ARIA: Asymmetry Resistant Instance Alignment",
    "Topics10": "",
    "Topics1": "AIW: AI for web services: semantic descriptions, planning, matching, and coordination",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: AI for web services: semantic descriptions, planning, matching, and coordination"
  },
  {
    "Document Index (generated)": 292,
    "Number of Records": 1,
    "Abstract": "Fault diagnosis of analogue linear systems is a challenging task and no fully\nautomated solution exists. Two challenges in this diagnosis task are the size of the search space that much be explored and the possibility of simulation instabilities introduced by particular fault classes. We study a novel algorithm that addresses both problems. This algorithm dynamically modifies the simulation model during  diagnosis by pruning parametrized components that cause discontinuity in the model. We provide a theoretical framework for predicting the speedups, which depends on the topology of the model. We empirically validate the theoretical predictions through extensive experimentation on a benchmark of circuits.",
    "Authors1": "Alex",
    "Authors2": "er Feldman",
    "Authors3": "Gregory Provan",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Alex,er Feldman , Gregory Provan",
    "Groups1": "Knowledge Representation and Reasoning (KRR)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Knowledge Representation and Reasoning (KRR)",
    "Keywords10": "",
    "Keywords1": "model-based diagnosis",
    "Keywords2": "analogue systems",
    "Keywords3": "modeling and analysis",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "model-based diagnosis;analogue systems;modeling and analysis",
    "Title": "Diagnosing Analogue Linear Systems Using Dynamic Topological Reconfiguration",
    "Topics10": "",
    "Topics1": "KRR: Diagnosis and Abductive Reasoning",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "KRR: Diagnosis and Abductive Reasoning"
  },
  {
    "Document Index (generated)": 293,
    "Number of Records": 1,
    "Abstract": "It is commonly appreciated that solving search problems optimally can take too long. Bounded suboptimal search algorithms trade increased solution cost for reduced solving time.  Explicit Estimation Search (EES) is a recent state-of-the-art algorithm specifically designed for bounded suboptimal search.  Although it tends to expand fewer nodes than alternative algorithms, such as weighted A* (WA*), its per-node expansion overhead is much higher, causing it to sometimes take longer.  In this paper, we present simplified variants of EES (SEES) and an earlier algorithm, A*epsilon (SA*epsilon), that use different implementations of the same motivating ideas to significantly reduce search overhead and implementation complexity.  In an empirical evaluation, we find that SEES, like EES, outperforms classic bounded suboptimal search algorithms, such as WA*, on domains tested where distance-to-go estimates enable better search guidance.  We also confirm that, while SEES and SA*epsilon expand roughly the same number of nodes as their progenitors, they solve problems significantly faster and are much easier to implement.  This work widens the applicability of state-of the-art bounded suboptimal search by making it easier to deploy.",
    "Authors1": "Matthew Hatem",
    "Authors2": "Wheeler Ruml",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Matthew Hatem , Wheeler Ruml",
    "Groups1": "Heuristic Search and Optimization (HSO)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Heuristic Search and Optimization (HSO)",
    "Keywords10": "",
    "Keywords1": "bounded suboptimal search",
    "Keywords2": "distance estimates",
    "Keywords3": "additional heuristics",
    "Keywords4": "iterative deepening",
    "Keywords5": "implementation",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "bounded suboptimal search;distance estimates;additional heuristics;iterative deepening;implementation",
    "Title": "Simpler Bounded Suboptimal Search",
    "Topics10": "",
    "Topics1": "HSO: Heuristic Search",
    "Topics2": "HSO: Evaluation and Analysis (Search and Optimization)",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "HSO: Heuristic Search;HSO: Evaluation and Analysis (Search and Optimization)"
  },
  {
    "Document Index (generated)": 294,
    "Number of Records": 1,
    "Abstract": "We introduce the problem of PAC rank elicitation, which consists of sorting a given set of options based on adaptive sampling of stochastic pairwise preferences. More specifically, the goal is to predict a ranking that is sufficiently close to a target order with high probability. We instantiate this setting with combinations of two different distance measures and ranking procedures for determining the target order. For these instantiations, we devise efficient sampling strategies and analyze the corresponding sample complexity. We also present first experiments to illustrate the practical performance of our methods.",
    "Authors1": "Róbert Busa-Fekete",
    "Authors2": "Balazs Szorenyi",
    "Authors3": "Eyke Huellermeier",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Róbert Busa-Fekete, Balazs Szorenyi , Eyke Huellermeier",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "Preference learning",
    "Keywords2": "Online learning",
    "Keywords3": "Ranking models",
    "Keywords4": "Rank elicitation",
    "Keywords5": "Sample complexity",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Preference learning;Online learning;Ranking models;Rank elicitation;Sample complexity",
    "Title": "PAC Rank Elicitation through Adaptive Sampling of Stochastic Pairwise Preferences",
    "Topics10": "",
    "Topics1": "NMLA: Online Learning",
    "Topics2": "NMLA: Preferences/Ranking Learning",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Online Learning;NMLA: Preferences/Ranking Learning"
  },
  {
    "Document Index (generated)": 295,
    "Number of Records": 1,
    "Abstract": "The notions of loops and loop formulas play an important role in answer set computation. However, there would be an exponential number of loops in the worst case. Recently, Gebser and Schaub characterized a subclass elementary loops and showed that they are sufficient for selecting answer sets from models of a logic program. In this paper, we propose an alternative definition of elementary loops. Based on the new perspective, we identify a subclass of elementary loops, called proper loops, and show that, by applying a special form of their loop formulas, they are also sufficient for the SAT-based answer set computation. We also provide a polynomial algorithm to recognize a proper loop and show that for certain logic programs, identifying all proper loops of a program is more efficient than identifying all elementary loops. Furthermore, we prove that, by considering the structure of the positive body-head dependency graph of a program, a large number of loops could be ignored for identifying proper loops. Based on the observation, we provide another algorithm for identifying all proper loops of a program. The experiments show that, for certain programs whose dependency graphs consisting of sets of components that are densely connected inside and sparsely connected outside, the new algorithm is more efficient.",
    "Authors1": "Jianmin Ji",
    "Authors2": "Hai Wan",
    "Authors3": "Peng Xiao",
    "Authors4": "Ziwei Huo",
    "Authors5": "Zhanhao Xiao",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Jianmin Ji, Hai Wan, Peng Xiao, Ziwei Huo , Zhanhao Xiao",
    "Groups1": "Knowledge Representation and Reasoning (KRR)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Knowledge Representation and Reasoning (KRR)",
    "Keywords10": "",
    "Keywords1": "elementary loops",
    "Keywords2": "proper loops",
    "Keywords3": "positive body-head dependency graph",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "elementary loops;proper loops;positive body-head dependency graph",
    "Title": "Elementary Loops Revisited",
    "Topics10": "",
    "Topics1": "KRR: Logic Programming",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "KRR: Logic Programming"
  },
  {
    "Document Index (generated)": 296,
    "Number of Records": 1,
    "Abstract": "Open list proportional representation is an election mechanism used in many\nelections including the 2012 Hong Kong Legislative Council\nGeographical Constituencies election. In this paper, assuming that there\nare just two parties in the election, and that the number of votes that a\nlist would get is the sum of the numbers of votes\nthat the candidates in the list would get if each of them would go alone in the election,\nwe formulate the election as a mostly zero-sum game, and show that while the\ngame always has a pure Nash equilibrium, it is NP-hard to compute it.",
    "Authors1": "Ning Ding",
    "Authors2": "Fangzhen Lin",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Ning Ding , Fangzhen Lin",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "Multiagent Systems (MAS)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP);Multiagent Systems (MAS)",
    "Keywords10": "",
    "Keywords1": "pure Nash equilibrium",
    "Keywords2": "open list proportional representation",
    "Keywords3": "computational social choice",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "pure Nash equilibrium;open list proportional representation;computational social choice",
    "Title": "On Computing Optimal Strategies in Open List Proportional Representation: the Two Parties Case",
    "Topics10": "",
    "Topics1": "GTEP: Game Theory",
    "Topics2": "GTEP: Social Choice / Voting",
    "Topics3": "GTEP: Equilibrium",
    "Topics4": "MAS: Evaluation and Analysis (Multiagent Systems)",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Game Theory;GTEP: Social Choice / Voting;GTEP: Equilibrium;MAS: Evaluation and Analysis (Multiagent Systems)"
  },
  {
    "Document Index (generated)": 297,
    "Number of Records": 1,
    "Abstract": "There has been a growing interest in stochastic methods\nto natural language generation (NLG). While most NL-\nG pipelines separate morphological generation and syn-\ntactic linearization, the two tasks are closely related to\neach other. In this paper, we study joint morphological\ngeneration and linearization, making use of word order\nand inflections information for both tasks and reducing\nerror propagation. Our experiments show that the join-\nt method significantly outperforms a strong pipelined\nbaseline (by 1.0 BLEU points). It also achieves the\nbest reported result on the Generation Challenge 2011\nshared task.",
    "Authors1": "Linfeng Song",
    "Authors2": "Yue Zhang",
    "Authors3": "Kai Song",
    "Authors4": "Qun Liu",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Linfeng Song, Yue Zhang, Kai Song , Qun Liu",
    "Groups1": "NLP and Knowledge Representation (NLPKR)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "NLP and Knowledge Representation (NLPKR)",
    "Keywords10": "",
    "Keywords1": "joint method",
    "Keywords2": "natural language generation",
    "Keywords3": "meaning text theory",
    "Keywords4": "syntactic linearization",
    "Keywords5": "morphological generation",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "joint method;natural language generation;meaning text theory;syntactic linearization;morphological generation",
    "Title": "Joint Morphological Generation and Syntactic Linearization",
    "Topics10": "",
    "Topics1": "NLPKR: Natural Language Processing (General/Other)",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NLPKR: Natural Language Processing (General/Other)"
  },
  {
    "Document Index (generated)": 298,
    "Number of Records": 1,
    "Abstract": "Contemporary machine translation systems usually rely on offline data retrieved from the web for individual model training, such as translation models and language models. Distinct from existing methods, we propose a novel approach that treats machine translation as a web search task and utilizes the web on the fly to acquire translation knowledge. This end-to-end approach takes advantage of fresh web search results that are capable of leveraging tremendous web knowledge to obtain phrase-level candidates on demand and then compose sentence-level translations. Experimental results show that our web-based machine translation method demonstrates very promising performance in leveraging fresh translation knowledge and making translation decisions. Furthermore, when combined with offline models, it significantly outperforms a state-of-the-art phrase-based statistical machine translation system.",
    "Authors1": "Lei Cui",
    "Authors2": "Ming Zhou",
    "Authors3": "Qiming Chen",
    "Authors4": "Dongdong Zhang",
    "Authors5": "Mu Li",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Lei Cui, Ming Zhou, Qiming Chen, Dongdong Zhang , Mu Li",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW)",
    "Keywords10": "",
    "Keywords1": "machine translation",
    "Keywords2": "real-time web search",
    "Keywords3": "web-based machine translation",
    "Keywords4": "phrase-level translation",
    "Keywords5": "sentence-level translation",
    "Keywords6": "search snippets",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "machine translation;real-time web search;web-based machine translation;phrase-level translation;sentence-level translation;search snippets",
    "Title": "Machine Translation with Real-time Web Search",
    "Topics10": "",
    "Topics1": "AIW: Human language technologies for web systems, including text summarization and machine translation",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: Human language technologies for web systems, including text summarization and machine translation"
  },
  {
    "Document Index (generated)": 299,
    "Number of Records": 1,
    "Abstract": "We consider an interesting problem in this paper that using transfer learning in two directions to compensate missing knowledge from the target domain. Transfer learning is usually exploited as a powerful tool to mitigate the discrepancy between different databases for knowledge transfer; it can also be used for knowledge transfer between different modalities within one database. However, in either case, transfer learning will fail if the target data are missing. To overcome this, we consider knowledge transfer between different databases and modalities simultaneously in a single framework, where missing target data from one database are recovered to facilitate recognition task. We call this framework Latent Low-rank Bi-Directional Transfer Subspace Learning method (L2BTSL). First, we propose to use low-rank constraint as well as dictionary learning in a learned subspace to guide the knowledge transfer between and within different databases. Second, a latent factor is introduced to uncover the underlying structure of the missing target data. Third, bi-directional transfer learning is proposed to integrate auxiliary\ndatabase for transfer learning with missing target data. Experimental results of multi-modalities knowledge transfer with missing target data demonstrate that our method can successfully inherit knowledge from the auxiliary database to complete the target domain, and therefore enhance the performance when recognizing data from the modality without any training data.",
    "Authors1": "Zhengming Ding",
    "Authors2": "Ming Shao",
    "Authors3": "Yun Fu",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Zhengming Ding, Ming Shao , Yun Fu",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "transfer learning",
    "Keywords2": "latent low-rank",
    "Keywords3": "subspace learning",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "transfer learning;latent low-rank;subspace learning",
    "Title": "Latent Low-Rank Bi-Directional Transfer Subspace Learning",
    "Topics10": "",
    "Topics1": "NMLA: Classification",
    "Topics2": "NMLA: Dimension Reduction/Feature Selection",
    "Topics3": "NMLA: Transfer, Adaptation, Multitask Learning",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Classification;NMLA: Dimension Reduction/Feature Selection;NMLA: Transfer, Adaptation, Multitask Learning"
  },
  {
    "Document Index (generated)": 300,
    "Number of Records": 1,
    "Abstract": "Multiple Instance Learning (MIL) is a popular learning technique in various\nvision tasks including image classification.\nHowever, most existing MIL methods do not consider the problem of insufficient examples in the given target category. In this case, it is difficult for traditional MIL methods to build an accurate classifier due to the lack of training examples. Motivated by the empirical success of transfer learning, this paper proposes a novel approach of Adaptive Knowledge Transfer for Multiple Instance Learning (AKT-MIL) in image classification. The new method transfers cross-category knowledge from source categories under multiple instance setting for boosting the learning process. A unified learning framework with a data-dependent mixture model is designed to adaptively combine the transferred knowledge from sources with a weak classifier built in the target domain.\nBased on this framework, an iterative coordinate descent method with Constraint\nConcave-Convex Programming (CCCP) is proposed as the optimization procedure. An extensive set of experimental results demonstrate that the proposed AKT-MIL approach substantially outperforms several state-of-the-art algorithms on two benchmark datasets, especially in the scenario when very few training examples are available in the target domain.",
    "Authors1": "Qifan Wang",
    "Authors2": "Lingyun Ruan",
    "Authors3": "Luo Si",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Qifan Wang, Lingyun Ruan , Luo Si",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "Multiple Instance Learning",
    "Keywords2": "Image Classification",
    "Keywords3": "Transfer Learning",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Multiple Instance Learning;Image Classification;Transfer Learning",
    "Title": "Adaptive Knowledge Transfer for Multiple Instance Learning in Image Classification",
    "Topics10": "",
    "Topics1": "NMLA: Classification",
    "Topics2": "NMLA: Transfer, Adaptation, Multitask Learning",
    "Topics3": "VIS: Categorization",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Classification;NMLA: Transfer, Adaptation, Multitask Learning;VIS: Categorization"
  },
  {
    "Document Index (generated)": 301,
    "Number of Records": 1,
    "Abstract": "In this paper we develop an algorithm to find the k-best equivalence classes of Bayesian networks. Our algorithm is capable of finding much more best DAGs than the previous algorithm that directly finds the k-best DAGs (Tian, He and Ram 2010). We demonstrate our algorithm in the task of Bayesian model averaging. Empirical results show that our algorithm significantly outperforms the k-best DAG algorithm in both time and space to achieve the same quality of approximation. Our algorithm goes beyond the maximum-a-posteriori (MAP) model by listing the most likely network structures and their relative likelihood and therefore has important applications in causal structure discovery.",
    "Authors1": "Yetian Chen",
    "Authors2": "Jin Tian",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Yetian Chen , Jin Tian",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "Reasoning under Uncertainty (RU)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA);Reasoning under Uncertainty (RU)",
    "Keywords10": "",
    "Keywords1": "Bayesian network",
    "Keywords2": "Equivalence class",
    "Keywords3": "Model averaging",
    "Keywords4": "Dynamic programming",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Bayesian network;Equivalence class;Model averaging;Dynamic programming",
    "Title": "Finding the k-best Equivalence Classes of Bayesian Network Structures for Model Averaging",
    "Topics10": "",
    "Topics1": "NMLA: Bayesian Learning",
    "Topics2": "NMLA: Graphical Model Learning",
    "Topics3": "RU: Bayesian Networks",
    "Topics4": "RU: Graphical Models (Other)",
    "Topics5": "RU: Probabilistic Inference",
    "Topics6": "RU: Uncertainty Representations",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Bayesian Learning;NMLA: Graphical Model Learning;RU: Bayesian Networks;RU: Graphical Models (Other);RU: Probabilistic Inference;RU: Uncertainty Representations"
  },
  {
    "Document Index (generated)": 302,
    "Number of Records": 1,
    "Abstract": "Restricted Boltzmann machines (RBMs) are powerful machine learning models, but\nlearning and some kinds of inference in the model require sampling-based\napproximations, which, in classical digital computers, are implemented using\nexpensive MCMC.  Physical computation offers the opportunity to reduce the cost\nof sampling by building physical systems whose natural dynamics correspond to\ndrawing samples from the desired RBM distribution. Such a system avoids the\nburn-in and mixing cost of a Markov chain. However, hardware implementations of\nthis variety usually entail limitations such as low-precision and limited range\nof the parameters and restrictions on the size and topology of the RBM.  We\nconduct software simulations to determine how harmful each of these restrictions\nis. Our simulations are designed to reproduce aspects of the D-Wave Two\ncomputer, but the issues we investigate arise in most forms of physical\ncomputation.\nOur findings suggest that designers of new physical computing hardware and\nalgorithms for physical computers should concentrate their efforts on overcoming\nthe limitations imposed by the topology restrictions of currently existing\nphysical computers.",
    "Authors1": "Vincent Dumoulin",
    "Authors2": "Ian J. Goodfellow",
    "Authors3": "Aaron Courville",
    "Authors4": "Yoshua Bengio",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Vincent Dumoulin, Ian J. Goodfellow, Aaron Courville , Yoshua Bengio",
    "Groups1": "Machine Learning Applications (MLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Machine Learning Applications (MLA)",
    "Keywords10": "",
    "Keywords1": "Restricted Boltzmann Machine",
    "Keywords2": "RBM",
    "Keywords3": "Hardware",
    "Keywords4": "Neuromorphic",
    "Keywords5": "Empirical",
    "Keywords6": "Deep Learning",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Restricted Boltzmann Machine;RBM;Hardware;Neuromorphic;Empirical;Deep Learning",
    "Title": "On the Challenges of Physical Implementations of RBMs",
    "Topics10": "",
    "Topics1": "MLA: Applications of Unsupervised Learning",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "MLA: Applications of Unsupervised Learning"
  },
  {
    "Document Index (generated)": 303,
    "Number of Records": 1,
    "Abstract": "Manifold learning is a powerful tool for solving nonlinear dimension reduction problems. By assuming that the high-dimensional data usually lie on a low-dimensional manifold, many algorithms have been proposed. However, most algorithms simply adopt the traditional graph Laplacian to encode the data locality, so the discriminative ability is limited and the embedding results are not always suitable for the subsequent classification. Instead, this paper deploys the signed graph Laplacian and proposes Signed Laplacian Embedding (SLE) for supervised dimension reduction. By exploring the label information, SLE comprehensively transfers the discrimination carried by the original data to the embedded low-dimensional space. Without perturbing the discrimination structure, SLE also retains the locality. Theoretically, we prove the immersion property by computing the rank of projection, and relate SLE to existing algorithms in the frame of patch alignment. Thorough empirical studies on synthetic and real datasets demonstrate the effectiveness of SLE.",
    "Authors1": "Chen Gong",
    "Authors2": "Dacheng Tao",
    "Authors3": "Jie Yang",
    "Authors4": "Keren Fu",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Chen Gong, Dacheng Tao, Jie Yang , Keren Fu",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "Dimension reduction",
    "Keywords2": "Manifold learning",
    "Keywords3": "Signed graph Laplacian",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Dimension reduction;Manifold learning;Signed graph Laplacian",
    "Title": "SLE: Signed Laplacian Embedding for Supervised Dimension Reduction",
    "Topics10": "",
    "Topics1": "NMLA: Dimension Reduction/Feature Selection",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Dimension Reduction/Feature Selection"
  },
  {
    "Document Index (generated)": 304,
    "Number of Records": 1,
    "Abstract": "We study the envy-free allocation of indivisible goods between two players. Our novel setting includes an option to sell each good for a fraction of the minimum value any player has for the good. To rigorously quantify the efficiency gain from selling, we reason about the price of envy-freeness of allocations of sellable goods — the ratio between the maximum social welfare and the social welfare of the best envy-free allocation. We show that envy-free allocations of sellable goods are significantly more efficient than their unsellable counterparts.",
    "Authors1": "Jeremy Karp",
    "Authors2": "Aleks",
    "Authors3": "r Kazachkov",
    "Authors4": "Ariel Procaccia",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Jeremy Karp, Aleks,r Kazachkov , Ariel Procaccia",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP)",
    "Keywords10": "",
    "Keywords1": "Computational social choice",
    "Keywords2": "Fair division",
    "Keywords3": "Envy-free allocation",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Computational social choice;Fair division;Envy-free allocation",
    "Title": "Envy-Free Division of Sellable Goods",
    "Topics10": "",
    "Topics1": "GTEP: Auctions and Market-Based Systems",
    "Topics2": "GTEP: Social Choice / Voting",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Auctions and Market-Based Systems;GTEP: Social Choice / Voting"
  },
  {
    "Document Index (generated)": 305,
    "Number of Records": 1,
    "Abstract": "There is often a large disparity between the size of a game we wish to solve and the size of the largest instances solvable by the best algorithms; for example, a popular variant of poker has about $10^{165}$ nodes in its game tree, while the currently best approximate equilibrium-finding algorithms scale to games with around $10^{12}$ nodes. In order to approximate equilibrium strategies in these games, the leading approach is to create a sufficiently small strategic approximation of the full game, called an abstraction, and to solve that smaller game instead. The leading abstraction algorithm for imperfect-information games generates abstractions that have imperfect recall and are distribution aware, using $k$-means with the earth mover's distance metric to cluster similar states together. A distribution-aware abstraction groups states together at a given round if their full distributions over future strength are similar (as opposed to, for example, just the expectation of their strength). The leading algorithm considers distributions over future strength at the final round of the game.  However, one might benefit by considering the distribution over strength in all future rounds, not just the final round. An abstraction algorithm that takes all future rounds into account is called potential aware. We present the first algorithm for computing potential-aware imperfect-recall abstractions using earth mover's distance. Experiments on no-limit Texas Hold'em show that our algorithm improves performance over the previously best approach.",
    "Authors1": "Sam Ganzfried",
    "Authors2": "Tuomas S",
    "Authors3": "holm",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Sam Ganzfried , Tuomas S,holm",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP)",
    "Keywords10": "",
    "Keywords1": "Game Theory",
    "Keywords2": "Multiagent Systems",
    "Keywords3": "Game Solving",
    "Keywords4": "Game Abstraction",
    "Keywords5": "Imperfect Information",
    "Keywords6": "Poker",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Game Theory;Multiagent Systems;Game Solving;Game Abstraction;Imperfect Information;Poker",
    "Title": "Potential-Aware Imperfect-Recall Abstraction with Earth Mover's Distance in Imperfect-Information Games",
    "Topics10": "",
    "Topics1": "GTEP: Game Theory",
    "Topics2": "GTEP: Imperfect Information",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Game Theory;GTEP: Imperfect Information"
  },
  {
    "Document Index (generated)": 306,
    "Number of Records": 1,
    "Abstract": "Real data are often with multiple modalities or coming from multiple channels, while multi-view clustering provides a natural formulation for generating clusters from such data. Previous studies assumed that each example appears in all views, or at least there is one view containing all examples. In real tasks, however, it is often the case that every view suffers from the missing of some data and therefore results in many partial examples, i.e., examples with some views missing. In this paper, we present possibly the first study on partial multi-view clustering. Our proposed approach, PVC, works by establishing a latent subspace where the instances corresponding to the same example in different views are close to each other, and the instances (belonging to different examples) in the same view are gathering smoothly. Experiments demonstrate the advantages of our proposed approach.",
    "Authors1": "Shao-Yuan Li",
    "Authors2": "Yuan Jiang",
    "Authors3": "Zhi-Hua Zhou",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Shao-Yuan Li, Yuan Jiang , Zhi-Hua Zhou",
    "Groups1": "Machine Learning Applications (MLA)",
    "Groups2": "Novel Machine Learning Algorithms (NMLA)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Machine Learning Applications (MLA);Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "machine learning",
    "Keywords2": "unsupervised learning",
    "Keywords3": "multi-view clustering",
    "Keywords4": "partial view",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "machine learning;unsupervised learning;multi-view clustering;partial view",
    "Title": "Partial Multi-View Clustering",
    "Topics10": "",
    "Topics1": "MLA: Applications of Unsupervised Learning",
    "Topics2": "MLA: Machine Learning Applications (General/other)",
    "Topics3": "NMLA: Clustering",
    "Topics4": "NMLA: Unsupervised Learning (Other)",
    "Topics5": "NMLA: Machine Learning (General/other)",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "MLA: Applications of Unsupervised Learning;MLA: Machine Learning Applications (General/other);NMLA: Clustering;NMLA: Unsupervised Learning (Other);NMLA: Machine Learning (General/other)"
  },
  {
    "Document Index (generated)": 307,
    "Number of Records": 1,
    "Abstract": "Online discussions are growing as a popular, effective and reliable source of information for users because of their liveliness, flexibility and up-to-date information. Online discussions are usually developed and advanced by groups of users with various backgrounds and intents. However because of the diversities in topics and issues discussed by the users, supervised methods are not able to accurately model such dynamic conditions. In this paper, we propose a novel unsupervised generative model to derive aspect-action pairs from online discussions. The proposed method simultaneously captures and models these two features with their relationships that exist in each thread. We assume that each user post is generated by a mixture of aspect and action topics. Therefore, we design a model that captures the latent factors that incorporates the aspect types and intended actions, which describe how users develop a topic in a discussion. In order to demonstrate the effectiveness of our approach, we empirically compare our model against the state of the art methods on large-scale discussion dataset, crawled from apple discussions with over 3.3 million user posts from 340k discussion threads.",
    "Authors1": "Ghasem Heyrani Nobari",
    "Authors2": "Chua Tat Seng",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Ghasem Heyrani Nobari , Chua Tat Seng",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "NLP and Machine Learning (NLPML)",
    "Groups3": "NLP and Text Mining (NLPTM)",
    "Groups4": "Novel Machine Learning Algorithms (NMLA)",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW);NLP and Machine Learning (NLPML);NLP and Text Mining (NLPTM);Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "Web",
    "Keywords2": "Online Discussions",
    "Keywords3": "Joint Modeling",
    "Keywords4": "Topic Modeling",
    "Keywords5": "Information Extraction",
    "Keywords6": "AI",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Web;Online Discussions;Joint Modeling;Topic Modeling;Information Extraction;AI",
    "Title": "User Intent Identification from Online Discussions using a Joint Aspect-Action Topic Model",
    "Topics10": "",
    "Topics1": "AIW: Enhancing web search and information retrieval",
    "Topics2": "AIW: Knowledge acquisition from the web",
    "Topics3": "AIW: Machine learning and the web",
    "Topics4": "NLPTM: Information Extraction",
    "Topics5": "NMLA: Classification",
    "Topics6": "NMLA: Clustering",
    "Topics7": "NMLA: Data Mining and Knowledge Discovery",
    "Topics8": "NMLA: Unsupervised Learning (Other)",
    "Topics9": "",
    "Topics": "AIW: Enhancing web search and information retrieval;AIW: Knowledge acquisition from the web;AIW: Machine learning and the web;NLPTM: Information Extraction;NMLA: Classification;NMLA: Clustering;NMLA: Data Mining and Knowledge Discovery;NMLA: Unsupervised Learning (Other)"
  },
  {
    "Document Index (generated)": 308,
    "Number of Records": 1,
    "Abstract": "Positional scoring rules in voting compute the score of an alternative by summing the\nscores for the alternative induced by every vote.  This summation principle ensures that all\nvotes contribute equally to the score of an alternative.\nWe relax this assumption and, instead, aggregate scores by taking into account\nthe rank of a score in the ordered list of scores obtained from the votes.\nThis defines a new family of voting rules, rank-dependent scoring\nrules (RDSRs), based on ordered weighted average (OWA) operators, which include\nscoring rules, plurality, k-approval, and Olympic\naverages. We study some properties of these rules, and show,\nempirically, that certain RDSRs are less manipulable than Borda voting,\nacross a variety of statistical cultures.",
    "Authors1": "Judy Goldsmith",
    "Authors2": "Jerome Lang",
    "Authors3": "Nicholas Mattei",
    "Authors4": "Patrice Perny",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Judy Goldsmith, Jerome Lang, Nicholas Mattei , Patrice Perny",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP)",
    "Keywords10": "",
    "Keywords1": "Computational Social Choice",
    "Keywords2": "Voting",
    "Keywords3": "Order Weighted Averages",
    "Keywords4": "Multi-agent Systems",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Computational Social Choice;Voting;Order Weighted Averages;Multi-agent Systems",
    "Title": "Voting with Rank Dependent Scoring Rules",
    "Topics10": "",
    "Topics1": "GTEP: Auctions and Market-Based Systems",
    "Topics2": "GTEP: Social Choice / Voting",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Auctions and Market-Based Systems;GTEP: Social Choice / Voting"
  },
  {
    "Document Index (generated)": 309,
    "Number of Records": 1,
    "Abstract": "In this paper we investigate four different approaches to encoding domain-dependent control knowledge for Answer-Set Planning. Starting with a standard implementation of the answer-set planning language B, we add control knowledge expressed in the GOLOG logic programming language.  A naive encoding, following the original definitions of Reiter et al., is shown to scale poorly. We investigate three alternative codings based on the finite-state machine semantics of ConGOLOG. These perform better, although there is no clear winner. We discuss the pros and cons of each approach.",
    "Authors1": "Malcolm Ryan",
    "Authors2": "",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Malcolm Ryan",
    "Groups1": "Knowledge Representation and Reasoning (KRR)",
    "Groups2": "Planning and Scheduling (PS)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Knowledge Representation and Reasoning (KRR);Planning and Scheduling (PS)",
    "Keywords10": "",
    "Keywords1": "GOLOG",
    "Keywords2": "Answer Set Programming",
    "Keywords3": "Planning",
    "Keywords4": "Search Control",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "GOLOG;Answer Set Programming;Planning;Search Control",
    "Title": "Implementing GOLOG in Answer Set Programming",
    "Topics10": "",
    "Topics1": "KRR: Action, Change, and Causality",
    "Topics2": "KRR: Logic Programming",
    "Topics3": "PS: Planning (General/Other)",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "KRR: Action, Change, and Causality;KRR: Logic Programming;PS: Planning (General/Other)"
  },
  {
    "Document Index (generated)": 310,
    "Number of Records": 1,
    "Abstract": "Machine learning algorithms have been applied to predict agent behaviors in real-world dynamic systems, such as advertiser behaviors in sponsored search and worker behaviors in crowdsourcing, and the prediction models have been used for the optimization of these systems. Note that the behavior data in these systems are generated by \\emph{live} agents: once the systems change due to the adoption of the prediction models learnt from the behavior data, agents will observe (directly or indirectly) and respond to these changes by changing their own behaviors accordingly. As a result, the behavior data will evolve and will not be identically and independently distributed, which poses great challenges to the theoretical analysis on the machine learning algorithms for behavior prediction. To tackle this challenge, in this paper, we propose to use \\emph{Markov Chain in Random Environments} (MCRE) to describe the behavior data, and perform generalization analysis of the machine learning algorithms on its basis. However, since the one-step transition probability matrix of MCRE depends on both previous states and the random environment, conventional techniques for generalization analysis cannot be directly applied. To address this issue, we propose a novel technique that transforms the original MCRE into a higher-dimensional time-homogeneous Markov chain. The new Markov chain involves more variables but is more regular, and thus easier to deal with. We prove the convergence of the new Markov chain when time approaches infinity. Then we prove a generalization bound for the machine learning algorithms on the behavior data generated by the new Markov chain, which depends on both the Markovian parameters and the covering number of the function class compounded by the loss function for behavior prediction and the behavior prediction model. To the best of our knowledge, this is the first work that performs the generalization analysis on data generated by complex processes in real-world dynamic systems.",
    "Authors1": "Fei Tian",
    "Authors2": "Haifang Li",
    "Authors3": "Wei Chen",
    "Authors4": "Tao Qin",
    "Authors5": "Enhong Chen",
    "Authors6": "Tie-Yan Liu",
    "Authors7": "",
    "Authors": "Fei Tian, Haifang Li, Wei Chen, Tao Qin, Enhong Chen , Tie-Yan Liu",
    "Groups1": "Machine Learning Applications (MLA)",
    "Groups2": "Novel Machine Learning Algorithms (NMLA)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Machine Learning Applications (MLA);Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "generalization analysis",
    "Keywords2": "agent behavior model prediction",
    "Keywords3": "Markov Chain in Random Environments",
    "Keywords4": "empirical risk minimization algorithm",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "generalization analysis;agent behavior model prediction;Markov Chain in Random Environments;empirical risk minimization algorithm",
    "Title": "Agent Behavior Prediction and Its Generalization Analysis",
    "Topics10": "",
    "Topics1": "MLA: Environmental",
    "Topics2": "MLA: Humanities",
    "Topics3": "MLA: Applications of Supervised Learning",
    "Topics4": "NMLA: Learning Theory",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "MLA: Environmental;MLA: Humanities;MLA: Applications of Supervised Learning;NMLA: Learning Theory"
  },
  {
    "Document Index (generated)": 311,
    "Number of Records": 1,
    "Abstract": "In this paper, we focus on the Sparse Learning for Stochastic Composite Optimization (SCO). Many algorithms have been proposed for SCO, and they have reached the optimal convergence rate $\\mathcal{O}(1/T)$ recently. However, the sparsity of the solutions obtained by the existing methods is unsatisfactory due to mainly two reasons: (1) taking the average of the intermediate solutions as the final solution, (2) the reducing of the magnitude of the sparse regularizer in the iterations. In order to improve the sparse pattern of the solutions, we propose a simple but effective stochastic optimization scheme by adding a novel sparse online-to-batch conversion to the traditional algorithms for SCO. Two specific approaches are discussed in this paper to reveal the power of our scheme. The theoretical analysis shows that our scheme can find a solution with better sparse pattern without affecting the current optimal convergence rate. Experiment results on both synthetic and real-world data sets show that our proposed methods have obviously superior sparse recovery ability and have comparable convergence rate as the state-of-the-art algorithms for SCO.",
    "Authors1": "Weizhong Zhang",
    "Authors2": "Lijun Zhang",
    "Authors3": "Yao Hu",
    "Authors4": "Rong Jin",
    "Authors5": "Deng Cai",
    "Authors6": "Xiaofei He",
    "Authors7": "",
    "Authors": "Weizhong Zhang, Lijun Zhang, Yao Hu, Rong Jin, Deng Cai , Xiaofei He",
    "Groups1": "Heuristic Search and Optimization (HSO)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Heuristic Search and Optimization (HSO)",
    "Keywords10": "",
    "Keywords1": "Stochastic Optimization",
    "Keywords2": "Online Learning",
    "Keywords3": "Composite Gradient Mapping",
    "Keywords4": "Stochastic Gradient Descent",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Stochastic Optimization;Online Learning;Composite Gradient Mapping;Stochastic Gradient Descent",
    "Title": "Sparse Learning for Stochastic Composite Optimization",
    "Topics10": "",
    "Topics1": "HSO: Optimization",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "HSO: Optimization"
  },
  {
    "Document Index (generated)": 312,
    "Number of Records": 1,
    "Abstract": "Creating knowledge bases based on the crowd-sourced wikis, like Wikipedia, has attracted significant research interest in the field of intelligent Web. However, the derived taxonomies usually contain many mistakenly imported taxonomic relations due to the difference between the user-generated subsumption relations and the semantic taxonomic relations. Current approaches to solving the problem still suffer the following issues: (i) the heuristic-based methods strongly rely on specific language dependent rules. (ii) the corpus-based methods depend on a large-scale high-quality corpus, which is often unavailable.\n\nIn this paper, we formulate the cross-lingual taxonomy derivation problem as the problem of cross-lingual taxonomic relation prediction. We investigate different linguistic heuristics and language independent features, and propose a cross-lingual knowledge validation based dynamic adaptive boosting model to iteratively reinforce the performance of taxonomic relation prediction. The proposed approach successfully overcome the above issues, and experiments show that our approach significantly outperforms the designed state-of-the-art comparison methods.",
    "Authors1": "Zhigang Wang",
    "Authors2": "Juanzi Li",
    "Authors3": "Shuangjie Li",
    "Authors4": "Mingyang Li",
    "Authors5": "Jie Tang",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Zhigang Wang, Juanzi Li, Shuangjie Li, Mingyang Li , Jie Tang",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "Knowledge Representation and Reasoning (KRR)",
    "Groups3": "NLP and Knowledge Representation (NLPKR)",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW);Knowledge Representation and Reasoning (KRR);NLP and Knowledge Representation (NLPKR)",
    "Keywords10": "",
    "Keywords1": "Taxonomy Derivation",
    "Keywords2": "Knowledge Validation",
    "Keywords3": "Cross Lingual",
    "Keywords4": "Online Wikis",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Taxonomy Derivation;Knowledge Validation;Cross Lingual;Online Wikis",
    "Title": "Cross-lingual Knowledge Validation Based Taxonomy Derivation from Heterogeneous Online Wikis",
    "Topics10": "",
    "Topics1": "AIW: Knowledge acquisition from the web",
    "Topics2": "AIW: Languages, tools, and methodologies for representing, managing, and visualizing semantic web data",
    "Topics3": "AIW: Ontologies and the web: creation, extraction, evolution, mapping, merging, and alignment",
    "Topics4": "tags and folksonomies",
    "Topics5": "KRR: Knowledge Acquisition",
    "Topics6": "KRR: Ontologies",
    "Topics7": "NLPKR: Ontology Induction",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: Knowledge acquisition from the web;AIW: Languages, tools, and methodologies for representing, managing, and visualizing semantic web data;AIW: Ontologies and the web: creation, extraction, evolution, mapping, merging, and alignment; tags and folksonomies;KRR: Knowledge Acquisition;KRR: Ontologies;NLPKR: Ontology Induction"
  },
  {
    "Document Index (generated)": 313,
    "Number of Records": 1,
    "Abstract": "Conformant probabilistic planning (CPP) differs from conformant planning (CP) by two key elements: the initial belief state is probabilistic,\nand the conformant plan must achieve the goal with probability $\\geq\\theta$, for some $0<\\theta\\leq 1$. \nTaig and Brafman observed that one can reduce CPP to CP by finding a set of initial states whose probability $\\geq\\theta$, for which\na conformant plan exists. Previous solvers based on this idea used the underlying planner to select this set of states and to plan for them simultaneously.\nHere, we suggest an alternative approach: Our planner starts with a separate preprocessing relevance analysis phase that determines a promising set of initial states on which to focus, and then calls an off-the-shelf conformant planner to solve the resulting problem. \nThis approach has three major advantages. First, we can introduce specific and efficient relevance reasoning techniques for introducing the set of initial states, rather than depend on\nthe heuristic function used by the planner. Second, we can benefit from various optimizations used by existing conformant planners which are unsound if applied to the original \nCPP. Finally, we have the freedom to select among different existing CP solvers. Consequently, the new planner dominates previous solvers on almost all domains and scales to instances that were not solved before.",
    "Authors1": "Ran Taig",
    "Authors2": "Ronen I. Brafman",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Ran Taig , Ronen I. Brafman",
    "Groups1": "Planning and Scheduling (PS)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Planning and Scheduling (PS)",
    "Keywords10": "",
    "Keywords1": "Planning under uncertainty.",
    "Keywords2": "Conformant probabilistic planning.",
    "Keywords3": "Relevance based method.",
    "Keywords4": "compilation based approach.",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Planning under uncertainty.;Conformant probabilistic planning.;Relevance based method.;compilation based approach.",
    "Title": "A Relevance-Based Compilation Method for Conformant Probabilistic Planning",
    "Topics10": "",
    "Topics1": "PS: Probabilistic Planning",
    "Topics2": "PS: Planning (General/Other)",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "PS: Probabilistic Planning;PS: Planning (General/Other)"
  },
  {
    "Document Index (generated)": 314,
    "Number of Records": 1,
    "Abstract": "In this paper, we study the existence of pure Nash equilibrium (PNE) for the mechanisms used in Internet services (e.g., online reviews and question-answer websites) to incentivize users to generate high-quality content. Most existing work assumes that users are homogeneous and have the same ability. However, real-world users are heterogeneous and their abilities can be very different from each other due to their diverse background, culture, and profession. In this work, we consider heterogeneous users with the following framework: (1) the users are heterogeneous and each of them has a private type indicating the best quality of the content she can generate; (2) there is a fixed amount of reward to allocate to the participated users.  Under this framework, we study the existence of pure Nash equilibrium of several mechanisms composed by different allocation rules, action spaces, and information settings. We prove the existence of PNE for some mechanisms and the non-existence of PNE for some mechanisms. We also discuss how to find a PNE for those mechanisms with PNE either through a constructive way or a searching algorithm.",
    "Authors1": "Yingce Xia",
    "Authors2": "Tao Qin",
    "Authors3": "Tie-Yan Liu",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Yingce Xia, Tao Qin , Tie-Yan Liu",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "Multiagent Systems (MAS)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP);Multiagent Systems (MAS)",
    "Keywords10": "",
    "Keywords1": "User generated content",
    "Keywords2": "Heterogeneous users",
    "Keywords3": "Equilibrium analysis",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "User generated content;Heterogeneous users;Equilibrium analysis",
    "Title": "Incentivizing High-quality Content from Heterogeneous Users: On the Existence of Nash Equilibrium",
    "Topics10": "",
    "Topics1": "GTEP: Game Theory",
    "Topics2": "GTEP: Equilibrium",
    "Topics3": "GTEP: Imperfect Information",
    "Topics4": "MAS: Mechanism Design",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Game Theory;GTEP: Equilibrium;GTEP: Imperfect Information;MAS: Mechanism Design"
  },
  {
    "Document Index (generated)": 315,
    "Number of Records": 1,
    "Abstract": "In this paper we propose a novel DCOP algorithm, called DJAO, that is able to\nefficiently find a solution with low communication overhead; this algorithm can be used for optimal and bounded approximate solutions by appropriately setting the error bounds. Our approach builds\n on distributed junction trees used in Action-GDL to represent independence relations\namong variables. We construct an AND/OR search space based on these junction trees.\nThis new type of search space results in higher degrees for each OR node, consequently yielding a more efficient search graph in the distributed settings. DJAO uses a branch-and-bound search algorithm to distributedly find solutions within this search graph. We introduce a heuristics to compute the upper and lower bound estimates that the search starts with, which is integral to our approach for reducing communication overhead. We empirically evaluate our approach in various settings.",
    "Authors1": "Yoonheui Kim",
    "Authors2": "Victor Lesser",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Yoonheui Kim , Victor Lesser",
    "Groups1": "Heuristic Search and Optimization (HSO)",
    "Groups2": "Search and Constraint Satisfaction (SCS)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Heuristic Search and Optimization (HSO);Search and Constraint Satisfaction (SCS)",
    "Keywords10": "",
    "Keywords1": "Distributed Problem Solving",
    "Keywords2": "DCOP",
    "Keywords3": "AND/OR search",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Distributed Problem Solving;DCOP;AND/OR search",
    "Title": "DJAO: A Communication-Constrained DCOP algorithm that combines features of ADOPT and Action-GDL",
    "Topics10": "",
    "Topics1": "HSO: Heuristic Search",
    "Topics2": "HSO: Optimization",
    "Topics3": "HSO: Distributed Search",
    "Topics4": "MAS: Coordination and Collaboration",
    "Topics5": "MAS: Distributed Problem Solving",
    "Topics6": "SCS: Constraint Optimization",
    "Topics7": "SCS: Distributed CSP/Optimization",
    "Topics8": "",
    "Topics9": "",
    "Topics": "HSO: Heuristic Search;HSO: Optimization;HSO: Distributed Search;MAS: Coordination and Collaboration;MAS: Distributed Problem Solving;SCS: Constraint Optimization;SCS: Distributed CSP/Optimization"
  },
  {
    "Document Index (generated)": 316,
    "Number of Records": 1,
    "Abstract": "Many real-world planning problems are oversubscription problems where all\ngoals are not simultaneously achievable and the planner needs to find a\nfeasible subset. We present complexity results for the so-called partial satisfaction\nand net benefit problems under various restrictions; this extends previous work\nby van den Briel et al. Our results reveal strong connections between these\nproblems and with classical planning. We also present a method for efficiently\ncompiling oversubscription problems into the ordinary plan existence problem;\nthis generalizes previous work by Keyder & Geffner.",
    "Authors1": "Meysam Aghighi",
    "Authors2": "Peter Jonsson",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Meysam Aghighi , Peter Jonsson",
    "Groups1": "Planning and Scheduling (PS)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Planning and Scheduling (PS)",
    "Keywords10": "",
    "Keywords1": "oversubscription planning",
    "Keywords2": "computational complexity",
    "Keywords3": "compilability",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "oversubscription planning;computational complexity;compilability",
    "Title": "Oversubscription Planning: Complexity and Compilability",
    "Topics10": "",
    "Topics1": "PS: Deterministic Planning",
    "Topics2": "PS: Planning (General/Other)",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "PS: Deterministic Planning;PS: Planning (General/Other)"
  },
  {
    "Document Index (generated)": 317,
    "Number of Records": 1,
    "Abstract": "Recent advances of kernel methods have yielded the framework for representing probabilities using a reproducing kernel Hilbert space, called kernel embedding of distributions. In this paper, we propose a Monte Carlo filtering algorithm based on kernel embeddings. The proposed method is applied to state-space models where sampling from the transition model is possible, while the observation model is to be learned from training samples without assuming a parametric model. We derive convergence rates for the sampling method introduced to the kernel embedding approach. Experimental results on synthetic models and a real vision-based robot localization problem confirm the effectiveness of the proposed approach.",
    "Authors1": "Motonobu Kanagawa",
    "Authors2": "Yu Nishiyama",
    "Authors3": "Arthur Gretton",
    "Authors4": "Kenji Fukumizu",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Motonobu Kanagawa, Yu Nishiyama, Arthur Gretton , Kenji Fukumizu",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "kernel method",
    "Keywords2": "kernel embedding of distributions",
    "Keywords3": "Monte Carlo filtering",
    "Keywords4": "state-space model",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "kernel method;kernel embedding of distributions;Monte Carlo filtering;state-space model",
    "Title": "Monte Carlo Filtering using Kernel Embedding of Distributions",
    "Topics10": "",
    "Topics1": "NMLA: Kernel Methods",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Kernel Methods"
  },
  {
    "Document Index (generated)": 318,
    "Number of Records": 1,
    "Abstract": "In this paper, we introduce and examine two new and natural models for competitive contagion in networks, a game-theoretic generalization of the viral marketing problem. In our setting, firms compete to maximize their market share in a network of consumers whose adoption decisions are stochastically determined by the choices of their neighbors. \n\nBuilding on the switching-selecting framework introduced by Goyal and Kearns (2012), we first introduce a new model in which the payoff to firms comprises not only the number of vertices who adopt their (competing) technologies, but also the network connectivity among those nodes. For a general class of stochastic dynamics driving the local adoption process, we derive upper bounds for (1) the (pure strategy) Price of Anarchy (PoA), which measures the inefficiency of resource use at equilibrium, and (2) the Budget Multiplier, which captures the extent to which the network amplifies the imbalances in the firms' initial budgets. These bounds depend on the firm budgets and the maximum degree of the network, but no other structural properties. In addition, we give general conditions under which the PoA and the Budget Multiplier can be unbounded.\n\nWe also introduce a model in which budgeting decisions are endogenous, rather than externally given as is typical in the viral marketing problem. In this setting, the firms are allowed to choose the number of seeds to initially infect (at a fixed cost per seed), as well as which nodes to select as seeds. In sharp contrast to the results of Goyal and Kearns (2012), we show that for almost any local adoption dynamics, there exists a family of graphs for which the PoA and Budget Multiplier are unbounded.",
    "Authors1": "Moez Draief",
    "Authors2": "Hoda Heidari",
    "Authors3": "Michael Kearns",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Moez Draief, Hoda Heidari , Michael Kearns",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP)",
    "Keywords10": "",
    "Keywords1": "Competitive Contagion",
    "Keywords2": "Networks",
    "Keywords3": "Connectivity",
    "Keywords4": "Endogenous budgets",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Competitive Contagion;Networks;Connectivity;Endogenous budgets",
    "Title": "New Models for Competitive Contagion",
    "Topics10": "",
    "Topics1": "GTEP: Game Theory",
    "Topics2": "GTEP: Equilibrium",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Game Theory;GTEP: Equilibrium"
  },
  {
    "Document Index (generated)": 319,
    "Number of Records": 1,
    "Abstract": "Most previous  heterogeneous transfer learning methods learn a cross-domain feature mapping between heterogeneous feature spaces based on a few cross-domain instance-correspondences, and these corresponding instances are assumed to be representatives in the source and target domains respectively. However, in many real-world scenarios, this assumption may not hold. As a result, the feature mapping may not be constructed precisely or the mapped data from the source (or target) domain may suffer from a data or feature shift issue in the target (or source) domain. In this case, a classifier trained on the labeled transformed-source-domain  data may not be useful for the target domain. In this paper, we present a new transfer learning framework called {\\em Hybrid Heterogeneous Transfer Learning} (HHTL), which allows choosing the corresponding instances to be biased in either the source or target domain. Moreover,  we propose a deep learning approach to learn better feature representations of each domain data  to reduce the data shift issue, and a better feature mapping between cross-domain heterogeneous features  for the accurate transfer simultaneously. Extensive experiments on several multilingual sentiment classification tasks verify the effectiveness of our proposed approach compared with the baseline methods.",
    "Authors1": "Joey Tianyi Zhou",
    "Authors2": "Sinno Jialin Pan",
    "Authors3": "Ivor W. Tsang",
    "Authors4": "Yan Yan",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Joey Tianyi Zhou, Sinno Jialin Pan, Ivor W. Tsang , Yan Yan",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "transfer learning",
    "Keywords2": "domain adaptation",
    "Keywords3": "deep learning",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "transfer learning;domain adaptation;deep learning",
    "Title": "Hybrid Heterogeneous Transfer Learning through Deep Learning",
    "Topics10": "",
    "Topics1": "NMLA: Transfer, Adaptation, Multitask Learning",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Transfer, Adaptation, Multitask Learning"
  },
  {
    "Document Index (generated)": 320,
    "Number of Records": 1,
    "Abstract": "Researchers have introduced the Dynamic Distributed Constraint Optimization Problem (Dynamic DCOP) formulation to model dynamically changing multi-agent coordination problems, where a dynamic DCOP is a sequence of (static canonical) DCOPs, each partially different from the DCOP preceding it. Existing work typically assumes that the problem in each time step is decoupled from the problems in other time steps, which might not hold in some applications. Therefore, in this paper, we make the following contributions: (i) We introduce a new model, called Markovian Dynamic DCOPs (MD-DCOPs), where the DCOP in the next time step is a function of the value assignments in the current time step; (ii) We introduce two distributed reinforcement learning algorithms, the Distributed RVI Q-learning algorithm and the Distributed R-learning algorithm, that balance exploration and exploitation to solve MD-DCOPs in an online manner; and (iii) We empirically evaluate them against an existing multi-arm bandit DCOP algorithm on dynamic DCOPs.",
    "Authors1": "Nguyen Duc Thien",
    "Authors2": "William Yeoh",
    "Authors3": "Hoong Chuin Lau",
    "Authors4": "Shlomo Zilberstein",
    "Authors5": "Chongjie Zhang",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Nguyen Duc Thien, William Yeoh, Hoong Chuin Lau, Shlomo Zilberstein , Chongjie Zhang",
    "Groups1": "Multiagent Systems (MAS)",
    "Groups2": "Search and Constraint Satisfaction (SCS)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Multiagent Systems (MAS);Search and Constraint Satisfaction (SCS)",
    "Keywords10": "",
    "Keywords1": "Distributed Constraint Optimization Problems",
    "Keywords2": "DCOPs",
    "Keywords3": "Reinforcement Learning",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Distributed Constraint Optimization Problems;DCOPs;Reinforcement Learning",
    "Title": "Decentralized Multi-Agent Reinforcement Learning in Average-Reward Dynamic DCOPs",
    "Topics10": "",
    "Topics1": "MAS: Coordination and Collaboration",
    "Topics2": "MAS: Distributed Problem Solving",
    "Topics3": "MAS: Multiagent Learning",
    "Topics4": "SCS: Distributed CSP/Optimization",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "MAS: Coordination and Collaboration;MAS: Distributed Problem Solving;MAS: Multiagent Learning;SCS: Distributed CSP/Optimization"
  },
  {
    "Document Index (generated)": 321,
    "Number of Records": 1,
    "Abstract": "We study techniques to incentivize self-interested agents to form socially desirable solutions in scenarios where they benefit from mutual coordination. Towards this end, we consider coordination games where agents have different intrinsic preferences but they stand to gain if others choose the same strategy as them. For non-trivial versions of our game, stable solutions like Nash Equilibrium may not exist, or may be socially inefficient even when they do exist. This motivates us to focus on designing efficient algorithms to compute (almost) stable solutions like Approximate Equilibrium that can be be realized if agents are provided some additional incentives. Alternatively, approximate stability corresponds to the addition of a switching cost that agents have to pay in order to deviate. Our results apply in many settings like adoption of new products, project selection, and group formation, where a central authority can direct agents towards a strategy but agents may defect if they have better alternatives. We show that for any given instance, we can either compute a high quality approximate equilibrium or a near-optimal solution that can be stabilized by providing a small fraction of the social welfare to all players. Our results imply that little influence is necessary in order to ensure that selfish players coordinate and form socially efficient solutions.",
    "Authors1": "Elliot Anshelevich",
    "Authors2": "Shreyas Sekar",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Elliot Anshelevich , Shreyas Sekar",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP)",
    "Keywords10": "",
    "Keywords1": "Approximate Nash Equilibrium",
    "Keywords2": "Coordination Games",
    "Keywords3": "Price of Stability",
    "Keywords4": "Price of Anarchy",
    "Keywords5": "Network Games",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Approximate Nash Equilibrium;Coordination Games;Price of Stability;Price of Anarchy;Network Games",
    "Title": "Approximate Equilibrium and Incentivizing Social Coordination",
    "Topics10": "",
    "Topics1": "GTEP: Game Theory",
    "Topics2": "GTEP: Coordination and Collaboration",
    "Topics3": "GTEP: Equilibrium",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Game Theory;GTEP: Coordination and Collaboration;GTEP: Equilibrium"
  },
  {
    "Document Index (generated)": 322,
    "Number of Records": 1,
    "Abstract": "Applications of qualitative reasoning to engineering design face a knowledge acquisition challenge.  Designers are not fluent in qualitative modeling languages and techniques.  To overcome this barrier, we perform qualitative simulation using models solely written in Modelica, a popular language among designers for modeling hybrid systems.  This paper has two contributions: (1) a formalization of the relationship between the results of the Modelica and qualitative simulations for the same model along with a novel algorithm for computing the consequences of events in qualitative simulation, and (2) three classes of additional constraints that reduce the number of unrealizable trajectories when performing qualitative simulation with Modelica models.  We support these contributions with  examples and a case study that shows a reduction by a factor of six the size of the qualitative simulation.",
    "Authors1": "Matthew Klenk",
    "Authors2": "Daniel Bobrow",
    "Authors3": "Johan De Kleer",
    "Authors4": "Bill Janssen",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Matthew Klenk, Daniel Bobrow, Johan De Kleer , Bill Janssen",
    "Groups1": "Applications (APP)",
    "Groups2": "Knowledge Representation and Reasoning (KRR)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Applications (APP);Knowledge Representation and Reasoning (KRR)",
    "Keywords10": "",
    "Keywords1": "qualitative reasoning",
    "Keywords2": "design",
    "Keywords3": "Modelica",
    "Keywords4": "model-based reasoning",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "qualitative reasoning;design;Modelica;model-based reasoning",
    "Title": "Qualitative Reasoning with Modelica Models",
    "Topics10": "",
    "Topics1": "APP: Other Applications",
    "Topics2": "KRR: Knowledge Representation Languages",
    "Topics3": "KRR: Qualitative Reasoning",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "APP: Other Applications;KRR: Knowledge Representation Languages;KRR: Qualitative Reasoning"
  },
  {
    "Document Index (generated)": 323,
    "Number of Records": 1,
    "Abstract": "Missing values are a common problem when applying classification algorithms to real-world medical data. This is especially true for trauma patients, where clinical variables frequently go uncollected due to the severity and urgency of their condition. Standard approaches to handling missingness first learn a model to estimate missing data values, and subsequently train and evaluate a classifier using data imputed with this model. Recently, several works have demonstrated the benefits of jointly estimating the imputation model and classifier parameters. However existing approaches make assumptions that limit their utility with many real-world medical datasets, particularly that data elements are missing at random, which is often invalid. We present a novel approach to jointly learning the imputation model and classifier. Unlike existing methods, the proposed approach makes no assumptions about the missingness of the data, can be used with arbitrary probabilistic data models and classification loss functions, and can be used when both training and testing data have missing values. We investigate the approach's utility in the prediction of several patient outcomes in a large national registry of trauma patients, and find that it significantly outperforms standard sequential methods.",
    "Authors1": "Alex Van Esbroeck",
    "Authors2": "Satinder Singh",
    "Authors3": "Ilan Rubinfeld",
    "Authors4": "Zeeshan Syed",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Alex Van Esbroeck, Satinder Singh, Ilan Rubinfeld , Zeeshan Syed",
    "Groups1": "Machine Learning Applications (MLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Machine Learning Applications (MLA)",
    "Keywords10": "",
    "Keywords1": "missing values",
    "Keywords2": "classification",
    "Keywords3": "trauma",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "missing values;classification;trauma",
    "Title": "Evaluating Trauma Patients: Addressing Missing Covariates Using Joint Optimization",
    "Topics10": "",
    "Topics1": "MLA: Bio/Medicine",
    "Topics2": "MLA: Applications of Supervised Learning",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "MLA: Bio/Medicine;MLA: Applications of Supervised Learning"
  },
  {
    "Document Index (generated)": 324,
    "Number of Records": 1,
    "Abstract": "A recent breadth-first branch and bound algorithm (BFBnB) for learning Bayesian network structures (Malone et al. 2011) uses two bounds to prune the search space for better efficiency; one is a lower bound calculated from pattern database heuristics, and the other is an upper bound obtained by a hill climbing search. Whenever the lower bound of a search path exceeds its upper bound, the path is guaranteed to lead to suboptimal solutions and is discarded immediately. This paper introduces methods for tightening the bounds. The lower bound is tightened by using more informed variable groupings in creating the pattern databases, and the upper bound is tightened using an anytime learning algorithm. Empirical results show that these bounds improve the efficiency of Bayesian network learning by two to three orders of magnitude.",
    "Authors1": "Xiannian Fan",
    "Authors2": "Changhe Yuan",
    "Authors3": "Br",
    "Authors4": "on Malone",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Xiannian Fan, Changhe Yuan , Br,on Malone",
    "Groups1": "Reasoning under Uncertainty (RU)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Reasoning under Uncertainty (RU)",
    "Keywords10": "",
    "Keywords1": "Bayesian network",
    "Keywords2": "structure learning",
    "Keywords3": "lower and upper bounds",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Bayesian network;structure learning;lower and upper bounds",
    "Title": "Tightening Bounds for Bayesian Network Structure Learning",
    "Topics10": "",
    "Topics1": "NMLA: Graphical Model Learning",
    "Topics2": "RU: Bayesian Networks",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Graphical Model Learning;RU: Bayesian Networks"
  },
  {
    "Document Index (generated)": 325,
    "Number of Records": 1,
    "Abstract": "Understanding biological pathways is an important activity in the biological domain for drug development. Due to the parallelism and complexity inherent in pathways, computer models that can answer queries about pathways are needed. A researcher may ask ``what-if'' questions comparing alternate scenarios, that require deeper understanding of the underlying model. In this paper, we present overview of such a system we developed and an English-like high level language to expressed pathways and queries. Our language is inspired by high level action and query languages and it uses Petri Net execution semantics.",
    "Authors1": "Saadat Anwar",
    "Authors2": "Chitta Baral",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Saadat Anwar , Chitta Baral",
    "Groups1": "Knowledge Representation and Reasoning (KRR)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Knowledge Representation and Reasoning (KRR)",
    "Keywords10": "",
    "Keywords1": "Biological pathways",
    "Keywords2": "Comparative queries",
    "Keywords3": "Question answering",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Biological pathways;Comparative queries;Question answering",
    "Title": "Pathway Specification and Comparative Queries: A High Level Language with Petri Net Semantics",
    "Topics10": "",
    "Topics1": "APP: Biomedical / Bioinformatics",
    "Topics2": "KRR: Knowledge Representation Languages",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "APP: Biomedical / Bioinformatics;KRR: Knowledge Representation Languages"
  },
  {
    "Document Index (generated)": 326,
    "Number of Records": 1,
    "Abstract": "The Game Description Language GDL is the standard input language for general game-playing systems. While players can gain a lot of traction by an efficient inference algorithm for GDL, state-of-the-art reasoners suffer from a variant of a classical KR problem, the inferential frame problem. We present a method by which general game players can transform any given game description into a representation that solves this problem. Our experimental results demonstrate that with the help of automatically generated domain knowledge, a significant speedup can thus be obtained for the majority of the game descriptions from the AAAI competition.",
    "Authors1": "Javier Romero",
    "Authors2": "Abdallah Saffidine",
    "Authors3": "Michael Thielscher",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Javier Romero, Abdallah Saffidine , Michael Thielscher",
    "Groups1": "Game Playing and Interactive Entertainment (GPIE)",
    "Groups2": "Knowledge Representation and Reasoning (KRR)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Playing and Interactive Entertainment (GPIE);Knowledge Representation and Reasoning (KRR)",
    "Keywords10": "",
    "Keywords1": "General game playing",
    "Keywords2": "Inferential frame problem",
    "Keywords3": "Game description language",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "General game playing;Inferential frame problem;Game description language",
    "Title": "Solving the Inferential Frame Problem in the General Game Description Language",
    "Topics10": "",
    "Topics1": "GPIE: General Game Playing",
    "Topics2": "KRR: Action, Change, and Causality",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GPIE: General Game Playing;KRR: Action, Change, and Causality"
  },
  {
    "Document Index (generated)": 327,
    "Number of Records": 1,
    "Abstract": "In causal inference, all methods of model learning rely on testable implications, namely, properties of the joint distribution that are dictated by the model structure.  These constraints, if not satisfied in the data, allow us to reject or modify the model. Most common methods of testing a linear structural equation model (SEM) rely on the likelihood ratio or chi-square test which simultaneously tests all of the restrictions implied by the model.  Local constraints, on the other hand, offer increased power (Bollen and Pearl, 2013; McDonald, 2002) and, in the case of failure, provide the modeler with insight for revising the model specification. One strategy of uncovering local constraints in linear SEMs is to search for overidentified path coefficients. While these overidentifying constraints are well known, no method has been given for systematically discovering them. In this paper, we extend the half-trek criterion of (Foygel et al., 2012) to identify a larger set of structural coefficients and use it to systematically discover overidentifying constraints. Still open is the question of whether our algorithm is complete.",
    "Authors1": "Bryant Chen",
    "Authors2": "Judea Pearl",
    "Authors3": "Jin Tian",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Bryant Chen, Judea Pearl , Jin Tian",
    "Groups1": "Knowledge Representation and Reasoning (KRR)",
    "Groups2": "Reasoning under Uncertainty (RU)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Knowledge Representation and Reasoning (KRR);Reasoning under Uncertainty (RU)",
    "Keywords10": "graphical models",
    "Keywords1": "structural equation models",
    "Keywords2": "causality",
    "Keywords3": "causal models",
    "Keywords4": "linear",
    "Keywords5": "testable implications",
    "Keywords6": "constraints",
    "Keywords7": "verma constraints",
    "Keywords8": "overidentifying constraints",
    "Keywords9": "overidentifying restrictions",
    "Keywords": "structural equation models;causality;causal models;linear;testable implications;constraints;verma constraints;overidentifying constraints;overidentifying restrictions;graphical models",
    "Title": "Testable Implications of Linear Structural Equation Models",
    "Topics10": "",
    "Topics1": "KRR: Action, Change, and Causality",
    "Topics2": "RU: Graphical Models (Other)",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "KRR: Action, Change, and Causality;RU: Graphical Models (Other)"
  },
  {
    "Document Index (generated)": 328,
    "Number of Records": 1,
    "Abstract": "Graph construction is the essential first step for nearly all manifold learning algorithms. While many applications assume that a simple k-nearest or epsilon-close neighbors graph will accurately model the topology of the underlying manifold, these methods often require expert tuning and may not produce high quality graphs. In this paper, the hyperparameter sensitivity of existing graph construction methods is demonstrated. We then present a new algorithm for unsupervised graph construction, based on minimal assumptions about the input data and its manifold structure. Notably, this method requires no hyperparameter tuning.",
    "Authors1": "Cj Carey",
    "Authors2": "Sridhar Mahadevan",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Cj Carey , Sridhar Mahadevan",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "graph construction",
    "Keywords2": "manifold learning",
    "Keywords3": "topology",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "graph construction;manifold learning;topology",
    "Title": "Manifold Spanning Graphs",
    "Topics10": "",
    "Topics1": "NMLA: Dimension Reduction/Feature Selection",
    "Topics2": "NMLA: Unsupervised Learning (Other)",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Dimension Reduction/Feature Selection;NMLA: Unsupervised Learning (Other)"
  },
  {
    "Document Index (generated)": 329,
    "Number of Records": 1,
    "Abstract": "Learning relative similarity from pairwise instances is an important problem in machine learning and potentially very useful for many applications, such as image and text retrieval. Despite being studied for years, some existing methods solved by Stochastic Gradient Descent (SGD) techniques generally suffer from slow convergence. In this paper, we investigate the application of Stochastic Dual Coordinate Ascent (SDCA) technique to tackle the optimization task of relative similarity learning by extending from vector to matrix parameters. Theoretically, we prove the optimal linear convergence rate for the proposed SDCA algorithm, beating the well-known sublinear convergence rate by the previous best metric learning algorithms. Empirically, we conduct extensive experiments on both standard and large-scale data sets to validate the effectiveness of the proposed algorithm for retrieval tasks.",
    "Authors1": "Pengcheng Wu",
    "Authors2": "Yi Ding",
    "Authors3": "Peilin Zhao",
    "Authors4": "Steven C.H. Hoi",
    "Authors5": "Chunyan Miao",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Pengcheng Wu, Yi Ding, Peilin Zhao, Steven C.H. Hoi , Chunyan Miao",
    "Groups1": "Machine Learning Applications (MLA)",
    "Groups2": "Novel Machine Learning Algorithms (NMLA)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Machine Learning Applications (MLA);Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "distance metric learning",
    "Keywords2": "similarity learning",
    "Keywords3": "online learning",
    "Keywords4": "retrieval",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "distance metric learning;similarity learning;online learning;retrieval",
    "Title": "Learning Relative Similarity by Stochastic Dual Coordinate Ascent",
    "Topics10": "",
    "Topics1": "MLA: Applications of Supervised Learning",
    "Topics2": "MLA: Machine Learning Applications (General/other)",
    "Topics3": "NMLA: Online Learning",
    "Topics4": "NMLA: Supervised Learning (Other)",
    "Topics5": "VIS: Image and Video Retrieval",
    "Topics6": "VIS: Statistical Methods and Learning",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "MLA: Applications of Supervised Learning;MLA: Machine Learning Applications (General/other);NMLA: Online Learning;NMLA: Supervised Learning (Other);VIS: Image and Video Retrieval;VIS: Statistical Methods and Learning"
  },
  {
    "Document Index (generated)": 330,
    "Number of Records": 1,
    "Abstract": "In many practical cases, we need to generalize a model trained in a source domain to a new target domain.However, the distribution of these two domains may differ very significantly, especially sometimes some crucial target features may not have support in the source domain. This paper propose a novel locality preserving projection methods for domain adaptation task,which can find a linear mapping preserving the 'intrinsic structure' for both the source and the target domain. In this work, we first construct two graphs encoding the neighborhood information for the source domain and target domain separately. We then try to find linear projection coefficients which have the property of locality preserving for each graph.Instead of combing the two objective function under compatibility assumption and requiring the user to decide the importance of each objective function. We propose a multi-objective formulation for this problem and solve it simultaneously using pareto optimization.The pareto frontier captures all possible good linear projection vectors that are prefered by one or more objectives.The effectiveness of our approach is justified by both theoretical analysis and empirical results on real world data sets. The new feature representation  shows better prediction accuracy as our experiment clearly demonstrated.",
    "Authors1": "Le Shu",
    "Authors2": "Tianyang Ma",
    "Authors3": "Longin Latecki",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Le Shu, Tianyang Ma , Longin Latecki",
    "Groups1": "Knowledge Representation and Reasoning (KRR)",
    "Groups2": "Machine Learning Applications (MLA)",
    "Groups3": "Novel Machine Learning Algorithms (NMLA)",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Knowledge Representation and Reasoning (KRR);Machine Learning Applications (MLA);Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "locality preserving projection",
    "Keywords2": "multi-objective learning",
    "Keywords3": "domain adaptation",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "locality preserving projection;multi-objective learning;domain adaptation",
    "Title": "locality preserving projection via multi-objective learning for domain adaptation",
    "Topics10": "",
    "Topics1": "KRR: Knowledge Representation (General/Other)",
    "Topics2": "NMLA: Transfer, Adaptation, Multitask Learning",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "KRR: Knowledge Representation (General/Other);NMLA: Transfer, Adaptation, Multitask Learning"
  },
  {
    "Document Index (generated)": 331,
    "Number of Records": 1,
    "Abstract": "Stability is a central concept in matching-based mechanism design. It imposes a fundamental requirement that no subset of agents could beneficially deviate from the prescribed outcome. However, deployment of stability in the current design of kidney exchange mechanisms presents at least two challenges. First, it reduces social welfare of the mechanism and sometimes prevent the mechanism from producing any outcome at all. Second, it sometimes incurs computation cost to clear the mechanism.\n\nIn this paper, we propose an alternative notion of stability. Our theoretical and experimental studies demonstrate that the new notion of stability addresses both challenges above and could be deployed in the current kidney exchange design.",
    "Authors1": "Yicheng Liu",
    "Authors2": "Pingzhong Tang",
    "Authors3": "Wenyi Fang",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Yicheng Liu, Pingzhong Tang , Wenyi Fang",
    "Groups1": "Multiagent Systems (MAS)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Multiagent Systems (MAS)",
    "Keywords10": "",
    "Keywords1": "Kidney exchange",
    "Keywords2": "Stable matching",
    "Keywords3": "Maximum weighted matching",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Kidney exchange;Stable matching;Maximum weighted matching",
    "Title": "Internally Stable Kidney Exchange",
    "Topics10": "",
    "Topics1": "GTEP: Auctions and Market-Based Systems",
    "Topics2": "MAS: Mechanism Design",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Auctions and Market-Based Systems;MAS: Mechanism Design"
  },
  {
    "Document Index (generated)": 332,
    "Number of Records": 1,
    "Abstract": "The object always can be observed at multiple views, and multi-view feature learning is an attractive research topic with great practical success. Canonical correlation analysis (CCA) has become an important technique in multi-view learning, since it can fully utilize the inter-view correlation. In this paper, we mainly study the CCA based multi-view supervised feature learning technique where the labels of training samples are known. Several supervised CCA based multi-view methods have been presented, which focus on investigating the supervised correlation across different views. However, they take no account of the intra-view correlation between samples. Researchers have also introduced the discriminant analysis technique into multi-view feature learning, such as multi-view discriminant analysis (MvDA). But they ignore the canonical correlation within each view and between all views. In this paper, we propose a novel multi-view feature learning approach based on intra-view and inter-view supervised correlation analysis (I2SCA), which can explore the useful correlation information of samples within each view and between all views. The objective function of I2SCA is designed to simultaneously extract the discriminatingly correlated features from both inter-view and intra-view. It can obtain an analytical solution without iterative calculation. And we provide a kernelized extension of I2SCA to tackle the linearly inseparable problem in the original feature space. Three widely-used datasets are employed as test data. Experimental results demonstrate that our proposed approaches outperform several representative multi-view supervised feature learning methods.",
    "Authors1": "Xiao-Yuan Jing",
    "Authors2": "Rui-Min Hu",
    "Authors3": "Yang-Ping Zhu",
    "Authors4": "Shan-Shan Wu",
    "Authors5": "Chao Liang",
    "Authors6": "Jing-Yu Yang",
    "Authors7": "",
    "Authors": "Xiao-Yuan Jing, Rui-Min Hu, Yang-Ping Zhu, Shan-Shan Wu, Chao Liang , Jing-Yu Yang",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "Canonical correlation analysis (CCA)",
    "Keywords2": "Multi-view supervised feature learning",
    "Keywords3": "Inter-view and intra-view supervised correlation analysis (I2SCA)",
    "Keywords4": "Analytical solution",
    "Keywords5": "Kernelized extension",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Canonical correlation analysis (CCA);Multi-view supervised feature learning;Inter-view and intra-view supervised correlation analysis (I2SCA);Analytical solution;Kernelized extension",
    "Title": "Intra-view and Inter-view Supervised Correlation Analysis for Multi-view Feature Learning",
    "Topics10": "",
    "Topics1": "NMLA: Dimension Reduction/Feature Selection",
    "Topics2": "NMLA: Supervised Learning (Other)",
    "Topics3": "VIS: Statistical Methods and Learning",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Dimension Reduction/Feature Selection;NMLA: Supervised Learning (Other);VIS: Statistical Methods and Learning"
  },
  {
    "Document Index (generated)": 333,
    "Number of Records": 1,
    "Abstract": "In this paper, we study a prototype learning problem, called {\\em Median Point-Set}, whose objective is to construct a prototype for a set of given point-sets so as to minimize the total earth mover's distances (EMD) between the prototype and the point-sets, where EMD between two point-sets is measured under affine transformation. For this problem, we present the first purely geometric approach. Comparing to existing graph-based approaches ({\\em e.g.,} median graph, shock graph), our approach has several unique advantages: (1) No encoding and decoding procedures are needed to map between objects and graphs, and therefore avoid errors caused by information losing during the mappings; (2) Staying only in the geometric domain makes our approach computationally more efficient and robust to noise. As a key ingredient of our approach, we present  the first quality guaranteed algorithm for minimizing EMD between two point-sets under affine transformation. We evaluate the performance of our technique for prototype reconstruction on a random dataset and a benchmark dataset, handwriting Chinese characters.  Experiments suggest  that our technique considerably outperforms  the existing graph-based methods.",
    "Authors1": "Hu Ding",
    "Authors2": "Jinhui Xu",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Hu Ding , Jinhui Xu",
    "Groups1": "Heuristic Search and Optimization (HSO)",
    "Groups2": "Machine Learning Applications (MLA)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Heuristic Search and Optimization (HSO);Machine Learning Applications (MLA)",
    "Keywords10": "",
    "Keywords1": "Prototype learning",
    "Keywords2": "Earth mover's distance",
    "Keywords3": "Optimization",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Prototype learning;Earth mover's distance;Optimization",
    "Title": "Finding Median Point-Set Using Earth Mover's Distance",
    "Topics10": "",
    "Topics1": "HSO: Heuristic Search",
    "Topics2": "HSO: Optimization",
    "Topics3": "HSO: Evaluation and Analysis (Search and Optimization)",
    "Topics4": "MLA: Applications of Unsupervised Learning",
    "Topics5": "MLA: Machine Learning Applications (General/other)",
    "Topics6": "NMLA: Evaluation and Analysis (Machine Learning)",
    "Topics7": "NMLA: Unsupervised Learning (Other)",
    "Topics8": "NMLA: Machine Learning (General/other)",
    "Topics9": "",
    "Topics": "HSO: Heuristic Search;HSO: Optimization;HSO: Evaluation and Analysis (Search and Optimization);MLA: Applications of Unsupervised Learning;MLA: Machine Learning Applications (General/other);NMLA: Evaluation and Analysis (Machine Learning);NMLA: Unsupervised Learning (Other);NMLA: Machine Learning (General/other)"
  },
  {
    "Document Index (generated)": 334,
    "Number of Records": 1,
    "Abstract": "This paper is concerned with preprocessing techniques for propositional model counting. We have implemented a preprocessor which includes many elementary preprocessing techniques, including occurrence reduction, vivification, backbone identification, as well as equivalence, AND and XOR gate identification and replacement. We performed intensive experiments, using a huge number of benchmarks coming from a large number of families. Two approaches to model counting have been considered downstream: ”direct” model counting using Cachet and compilation-based model counting, based on the C2D compiler. The experimental results we have obtained show that our preprocessor is both efficient and robust.",
    "Authors1": "Jean Marie Lagniez",
    "Authors2": "Pierre Marquis",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Jean Marie Lagniez , Pierre Marquis",
    "Groups1": "Search and Constraint Satisfaction (SCS)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Search and Constraint Satisfaction (SCS)",
    "Keywords10": "",
    "Keywords1": "model counting",
    "Keywords2": "preprocessing",
    "Keywords3": "propositional",
    "Keywords4": "compilation",
    "Keywords5": "direct model counting",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "model counting;preprocessing;propositional;compilation;direct model counting",
    "Title": "Preprocessing for Propositional Model Counting",
    "Topics10": "",
    "Topics1": "SCS: SAT and CSP: Solvers and Tools",
    "Topics2": "SCS: Constraint Satisfaction (General/other)",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "SCS: SAT and CSP: Solvers and Tools;SCS: Constraint Satisfaction (General/other)"
  },
  {
    "Document Index (generated)": 335,
    "Number of Records": 1,
    "Abstract": "Constraints over finite sequences of variables are ubiquitous in sequencing and timetabling. This led to general modeling techniques and generic propagators, often based on deterministic finite automata (DFA) and their extensions. We consider counter-DFAs (cDFA), which provide concise models for regular counting constraints, that is constraints over the number of times a regular-language pattern occurs in a sequence. We show how to enforce domain consistency in polynomial time for atmost and atleast regular counting constraints based on the frequent case of a cDFA with only accepting states and a single counter that can be increased by transitions. We also show that the satisfaction of exact regular counting constraints is NP-hard and that an incomplete propagator for exact regular counting constraints is faster and provides more pruning than the existing propagator from (Beldiceanu, Carlsson, and Petit 2004). Finally, by avoiding the unrolling of the cDFA used by COSTREGULAR, the space complexity reduces from O(n|\\Sigma||Q|) to O(n(|\\Sigma|+|Q|)), where \\Sigma is the alphabet and Q the state set of the cDFA.",
    "Authors1": "Nicolas Beldiceanu",
    "Authors2": "Pierre Flener",
    "Authors3": "Justin Pearson",
    "Authors4": "Pascal Van Hentenryck",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Nicolas Beldiceanu, Pierre Flener, Justin Pearson , Pascal Van Hentenryck",
    "Groups1": "Search and Constraint Satisfaction (SCS)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Search and Constraint Satisfaction (SCS)",
    "Keywords10": "",
    "Keywords1": "constraints over a sequence",
    "Keywords2": "finite automata",
    "Keywords3": "counting",
    "Keywords4": "propagators",
    "Keywords5": "domain consistency",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "constraints over a sequence;finite automata;counting;propagators;domain consistency",
    "Title": "Propagating Regular Counting Constraints",
    "Topics10": "",
    "Topics1": "SCS: Constraint Satisfaction",
    "Topics2": "SCS: Global Constraints",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "SCS: Constraint Satisfaction;SCS: Global Constraints"
  },
  {
    "Document Index (generated)": 336,
    "Number of Records": 1,
    "Abstract": "Image similarity search plays a key role in many multimedia\napplications, where multimedia data (such as images and videos) are\nusually represented in high-dimensional feature space. In this\npaper, we propose a novel Sparse Online Metric Learning (SOML)\nscheme for learning sparse distance functions from large-scale\nhigh-dimensional data and explore its application to image\nretrieval. In contrast to many existing distance metric learning\nalgorithms that are often designed for low-dimensional data, the\nproposed algorithms are able to learn sparse distance metrics from\nhigh-dimensional data in an efficient and scalable manner. Our\nexperimental results show that the proposed method achieves better\nor at least comparable accuracy performance than the\nstate-of-the-art non-sparse distance metric learning approaches, but\nenjoys a significant advantage in computational efficiency and\nsparsity, making it more practical for real-world applications.",
    "Authors1": "Xingyu Gao",
    "Authors2": "Steven C.H. Hoi",
    "Authors3": "Yongdong Zhang",
    "Authors4": "Ji Wan",
    "Authors5": "Jintao Li",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Xingyu Gao, Steven C.H. Hoi, Yongdong Zhang, Ji Wan , Jintao Li",
    "Groups1": "Machine Learning Applications (MLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Machine Learning Applications (MLA)",
    "Keywords10": "",
    "Keywords1": "Sparse Online Learning",
    "Keywords2": "Distance Metric Learning",
    "Keywords3": "Image Retrieval",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Sparse Online Learning;Distance Metric Learning;Image Retrieval",
    "Title": "SOML: Sparse Online Metric Learning with Application to Image Retrieval",
    "Topics10": "",
    "Topics1": "MLA: Applications of Supervised Learning",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "MLA: Applications of Supervised Learning"
  },
  {
    "Document Index (generated)": 337,
    "Number of Records": 1,
    "Abstract": "We study a mechanism design problem for exchange economies where each agent is initially endowed with a set of indivisible goods and side payments are not allowed. We assume each agent can withhold some endowments, as well as misreport her preference. Under this assumption, strategyproofness requires that for each agent, reporting her true preference with revealing all her endowments is a dominant strategy, and thus implies individual rationality. \nOur objective in this paper is to analyze the effect of such private ownership in exchange economies with multiple endowments.  As fundamental results, we first show that the revelation principle holds under a natural assumption and that strategyproofness and Pareto efficiency are incompatible even under the lexicographic preference domain. We then propose a class of exchange rules, each of which has a corresponding directed graph to prescribe possible trades, and provide a necessary and sufficient condition on the graph structure so that the rule satisfies strategy-proofness.",
    "Authors1": "Taiki Todo",
    "Authors2": "Haixin Sun",
    "Authors3": "Makoto Yokoo",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Taiki Todo, Haixin Sun , Makoto Yokoo",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP)",
    "Keywords10": "",
    "Keywords1": "Mechanism design",
    "Keywords2": "Exchange",
    "Keywords3": "Manipulation",
    "Keywords4": "Strategyproofness",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Mechanism design;Exchange;Manipulation;Strategyproofness",
    "Title": "Strategyproof exchange with multiple private endowments",
    "Topics10": "",
    "Topics1": "GTEP: Auctions and Market-Based Systems",
    "Topics2": "GTEP: Game Theory",
    "Topics3": "MAS: E-Commerce",
    "Topics4": "MAS: Mechanism Design",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Auctions and Market-Based Systems;GTEP: Game Theory;MAS: E-Commerce;MAS: Mechanism Design"
  },
  {
    "Document Index (generated)": 338,
    "Number of Records": 1,
    "Abstract": "Mobile geo-location advertising, where mobile ads are targeted based on a user's location, has been identified as a key growth factor for the mobile market. As with online advertising, a crucial ingredient for their success is the development of effective economic mechanisms. An important difference is that mobile ads are shown sequentially over time and information about the user can be learned based on their movements. Furthermore, ads need to be shown selectively to prevent ad fatigue. To this end, we introduce, for the first time, a user model and suitable economic mechanisms which take these factors into account. Specifically, we design two truthful mechanisms which produce an advertisement plan based on the user's movements. One mechanism is allocatively efficient, but requires exponential compute time in the worst case. The other requires polynomial time, but  is not allocatively efficient. Finally, we experimentally evaluate the trade-off between compute time and efficiency of our mechanisms.",
    "Authors1": "Nicola Gatti",
    "Authors2": "Marco Rocco",
    "Authors3": "Sofia Ceppi",
    "Authors4": "Enrico H. Gerding",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Nicola Gatti, Marco Rocco, Sofia Ceppi , Enrico H. Gerding",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "Multiagent Systems (MAS)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP);Multiagent Systems (MAS)",
    "Keywords10": "",
    "Keywords1": "Mechanism Design",
    "Keywords2": "Auctions",
    "Keywords3": "Computational Advertising",
    "Keywords4": "Mobile Advertising",
    "Keywords5": "Game Theory (cooperative and non–cooperative)",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Mechanism Design;Auctions;Computational Advertising;Mobile Advertising;Game Theory (cooperative and non–cooperative)",
    "Title": "Mechanism design for mobile geo-location advertising",
    "Topics10": "",
    "Topics1": "GTEP: Auctions and Market-Based Systems",
    "Topics2": "GTEP: Game Theory",
    "Topics3": "MAS: Mechanism Design",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Auctions and Market-Based Systems;GTEP: Game Theory;MAS: Mechanism Design"
  },
  {
    "Document Index (generated)": 339,
    "Number of Records": 1,
    "Abstract": "Constraints over variable sequences are ubiquitous and many of their propagators have been inspired by dynamic programming (DP).  We propose a conceptual framework for designing such propagators: pruning rules are refined upon the application of transformation operators to a DP-style formulation of a constraint; a representation of the variable domains is picked; and a coordination of the pruning rules is picked.",
    "Authors1": "Jean-Noël Monette",
    "Authors2": "Pierre Flener",
    "Authors3": "Justin Pearson",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Jean-Noël Monette, Pierre Flener , Justin Pearson",
    "Groups1": "Search and Constraint Satisfaction (SCS)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Search and Constraint Satisfaction (SCS)",
    "Keywords10": "",
    "Keywords1": "Constraint Programming",
    "Keywords2": "Global Constraints",
    "Keywords3": "Stepwise Refinement",
    "Keywords4": "Tuple Variables",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Constraint Programming;Global Constraints;Stepwise Refinement;Tuple Variables",
    "Title": "A Propagator Design Framework for Constraints over Sequences",
    "Topics10": "",
    "Topics1": "SCS: Constraint Satisfaction",
    "Topics2": "SCS: Global Constraints",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "SCS: Constraint Satisfaction;SCS: Global Constraints"
  },
  {
    "Document Index (generated)": 340,
    "Number of Records": 1,
    "Abstract": "Sensitive data such as medical records and business reports usually contains valuable information that can be used to build prediction models. However, designing learning models by directly using sensitive data might result in severe privacy and copyright issues. In this paper, we propose a novel matrix completion based framework that is able to handle two challenging issues simultaneously: i) recovering missing and noisy sensitive data, and ii) preserving the privacy of the sensitive data during the learning process. In particular, the proposed framework is able to mask the sensitive data while ensuring that the transformed data are still usable for training regression models. We show that two key properties, namely \\emph{model preserving} and \\emph{privacy preserving}, are satisfied by the transformed data obtained from the proposed framework. In \\emph{model preserving}, we guarantee that the linear regression model built from the masked data approximates the regression model learned from the original data in a perfect way. In \\emph{privacy preserving}, we ensure that the original sensitive data cannot be recovered since the transformation procedure is irreversible. Given these two characteristics, the transformed data can be safely released to any learners for designing prediction models without revealing any private content. Our empirical studies with a synthesized dataset and multiple sensitive benchmark datasets verify our theoretical claim as well as the effectiveness of the proposed framework.",
    "Authors1": "Jinfeng Yi",
    "Authors2": "Jun Wang",
    "Authors3": "Rong Jin",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Jinfeng Yi, Jun Wang , Rong Jin",
    "Groups1": "Applications (APP)",
    "Groups2": "Machine Learning Applications (MLA)",
    "Groups3": "Novel Machine Learning Algorithms (NMLA)",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Applications (APP);Machine Learning Applications (MLA);Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "Regression analysis",
    "Keywords2": "Privacy",
    "Keywords3": "Matrix completion",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Regression analysis;Privacy;Matrix completion",
    "Title": "Regression Model and Privacy Preserved Learning by Matrix Completion",
    "Topics10": "NMLA: Machine Learning (General/other)",
    "Topics1": "APP: Biomedical / Bioinformatics",
    "Topics2": "APP: Computational Social Science",
    "Topics3": "APP: Security and Privacy",
    "Topics4": "MLA: Bio/Medicine",
    "Topics5": "MLA: Applications of Supervised Learning",
    "Topics6": "MLA: Machine Learning Applications (General/other)",
    "Topics7": "MAS: Mechanism Design",
    "Topics8": "NMLA: Data Mining and Knowledge Discovery",
    "Topics9": "NMLA: Feature Construction/Reformulation",
    "Topics": "APP: Biomedical / Bioinformatics;APP: Computational Social Science;APP: Security and Privacy;MLA: Bio/Medicine;MLA: Applications of Supervised Learning;MLA: Machine Learning Applications (General/other);MAS: Mechanism Design;NMLA: Data Mining and Knowledge Discovery;NMLA: Feature Construction/Reformulation;NMLA: Machine Learning (General/other);RU: Uncertainty in AI (General/Other)"
  },
  {
    "Document Index (generated)": 341,
    "Number of Records": 1,
    "Abstract": "Dung’s argumentation framework is an abstract framework based on a set of arguments and a binary attack relation defined over the set. One instantiation, among many others, of Dung’s framework consists in constructing the arguments from a set of propositional logic formulas. Thus an argument is seen as a reason for or against the truth of a particular statement. Despite its advantages, the argumentation approach for inconsistency handling also has important shortcomings. More precisely, in some applications what one is interested in are not so much only the conclusions supported by the arguments but also to the precise explications of such conclusions. We show that argumentation framework applied to classical logic formulas is not suitable to deal with this problem. On the other hand, intuitionistic logic appears to be a natural alternative candidate logic (instead of classical logic) to instantiate Dung’s framework. We develop constructive argumentation framework. We show that intuitionistic logic offers nice and desirable properties of the arguments. We also provide a characterization of the arguments in this setting in terms of minimal inconsistent subsets when intuitionistic logic is embedded in the modal logic S4.",
    "Authors1": "Souhila Kaci",
    "Authors2": "Yakoub Salhi",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Souhila Kaci , Yakoub Salhi",
    "Groups1": "",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "",
    "Keywords10": "",
    "Keywords1": "Logic-based Argumentation",
    "Keywords2": "Constructive Arguments",
    "Keywords3": "Intuitionistic Logic",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Logic-based Argumentation;Constructive Arguments;Intuitionistic Logic",
    "Title": "A Constructive Argumentation Framework",
    "Topics10": "",
    "Topics1": "KRR: Argumentation",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "KRR: Argumentation"
  },
  {
    "Document Index (generated)": 342,
    "Number of Records": 1,
    "Abstract": "Partially observable Markov decision processes (POMDPs) provide a principled mathematical framework for modeling autonomous decision-making problems. POMDP solutions are often represented by a value function comprised of a set of vectors. In the case of factored models, the size of these vectors grows exponentially with the number of state factors, leading to scalability issues. We consider an approximate value function representation based on a linear combination of basis functions. In particular, we present a backup operator that can be used in any point-based POMDP solvers. Furthermore, we show how independence between observation factors can be exploited for large computational gains. We experimentally verify our contributions and show that they can improve point-based methods in policy quality and solution size.",
    "Authors1": "Tiago Veiga",
    "Authors2": "Matthijs Spaan",
    "Authors3": "Pedro Lima",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Tiago Veiga, Matthijs Spaan , Pedro Lima",
    "Groups1": "Planning and Scheduling (PS)",
    "Groups2": "Reasoning under Uncertainty (RU)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Planning and Scheduling (PS);Reasoning under Uncertainty (RU)",
    "Keywords10": "",
    "Keywords1": "POMDP",
    "Keywords2": "Value function approximation",
    "Keywords3": "Point-based methods",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "POMDP;Value function approximation;Point-based methods",
    "Title": "Point-based POMDP solving with factored value function approximation",
    "Topics10": "",
    "Topics1": "PS: Probabilistic Planning",
    "Topics2": "PS: Planning (General/Other)",
    "Topics3": "RU: Sequential Decision Making",
    "Topics4": "RU: Uncertainty in AI (General/Other)",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "PS: Probabilistic Planning;PS: Planning (General/Other);RU: Sequential Decision Making;RU: Uncertainty in AI (General/Other)"
  },
  {
    "Document Index (generated)": 343,
    "Number of Records": 1,
    "Abstract": "Demand response is a critical part of renewable integration and energy cost reduction goals across the world. Motivated by the need to reduce costs arising from electricity shortage and renewable energy fluctuations, we propose a novel  multiarmed bandit mechanism for demand response (MAB-MDR) which makes monetary offers  to strategic consumers who have unknown response characteristics. Our work is inspired by  connection to and intuition from crowdsourcing mechanisms.  The proposed mechanism incorporates realistic features such as a time varying and quadratic cost function. The mechanism marries auctions, that allow users to report their preferences, with online algorithms, that allow distribution companies to learn user-specific parameters. We show that MAB-MDR is dominant strategy incentive compatible, individually rational, and achieves sublinear regret. \nSuch mechanisms can be effectively deployed in smart grids using new information and control architecture innovations \nand lead to welcome savings in energy costs.",
    "Authors1": "Shweta Jain",
    "Authors2": "Balakrishnan Narayanaswamy",
    "Authors3": "Yadati Narahari",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Shweta Jain, Balakrishnan Narayanaswamy , Yadati Narahari",
    "Groups1": "Computational Sustainability and AI (CSAI)",
    "Groups2": "Game Theory and Economic Paradigms (GTEP)",
    "Groups3": "Human-Computation and Crowd Sourcing (HCC)",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Computational Sustainability and AI (CSAI);Game Theory and Economic Paradigms (GTEP);Human-Computation and Crowd Sourcing (HCC)",
    "Keywords10": "",
    "Keywords1": "CSAI: Modeling the interactions of agents with different and often conflicting interests",
    "Keywords2": "GTEP: Auctions and Market-Based Systems",
    "Keywords3": "HCC: Game-theoretic mechanism design of incentives for motivation and honest reporting",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "CSAI: Modeling the interactions of agents with different and often conflicting interests;GTEP: Auctions and Market-Based Systems;HCC: Game-theoretic mechanism design of incentives for motivation and honest reporting",
    "Title": "A Multiarmed Bandit Incentive Mechanism for Crowdsourcing Demand Response in Smart Grids",
    "Topics10": "",
    "Topics1": "CSAI: Modeling the interactions of agents with different and often conflicting interests",
    "Topics2": "GTEP: Auctions and Market-Based Systems",
    "Topics3": "HCC: Game-theoretic mechanism design of incentives for motivation and honest reporting",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "CSAI: Modeling the interactions of agents with different and often conflicting interests;GTEP: Auctions and Market-Based Systems;HCC: Game-theoretic mechanism design of incentives for motivation and honest reporting"
  },
  {
    "Document Index (generated)": 344,
    "Number of Records": 1,
    "Abstract": "In binary aggregation, a group of voters each express yes/no choices\nregarding a number of possibly correlated issues and we are asked to\ndecide on a collective choice that accurately reflects the views of this\ngroup. A good collective choice will minimise the distance to each of\nthe individual choices, but using such a distance-based aggregation rule\nis computationally intractable. Instead, we explore a class of\nlow-complexity aggregation rules that select the most representative\nvoter in any given situation and return that voter's choice as the\ncollective outcome.",
    "Authors1": "Ulle Endriss",
    "Authors2": "Umberto Gr",
    "Authors3": "i",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Ulle Endriss , Umberto Gr,i",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "Knowledge Representation and Reasoning (KRR)",
    "Groups3": "Multiagent Systems (MAS)",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP);Knowledge Representation and Reasoning (KRR);Multiagent Systems (MAS)",
    "Keywords10": "",
    "Keywords1": "Computational Social Choice",
    "Keywords2": "Approximation",
    "Keywords3": "Judgment Aggregation",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Computational Social Choice;Approximation;Judgment Aggregation",
    "Title": "Binary Aggregation by Selection of the Most Representative Voter",
    "Topics10": "",
    "Topics1": "GTEP: Social Choice / Voting",
    "Topics2": "KRR: Preferences",
    "Topics3": "MAS: Multiagent Systems (General/other)",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Social Choice / Voting;KRR: Preferences;MAS: Multiagent Systems (General/other)"
  },
  {
    "Document Index (generated)": 345,
    "Number of Records": 1,
    "Abstract": "In machine learning, linear discriminant analysis (LDA) is a\npopular dimension reduction method. In this paper, we first pro-\nvide a new perspective of LDA from information theory per-\nspective. From this new perspective, we propose a new formula-\ntion of LDA, which uses the pairwise averaged class covariance\ninstead of the globally averaged class covariance used in stan-\ndard LDA. This pairwise (averaged) covariance describes data\ndistribution more accurately. The new perspective also provides\na natural way to properly weight different pairwise distances,\nwhich emphasizes the pairs of class with small distances, and\nthis leads to the proposed pairwise covariance properly weight-\ned LDA (pcLDA). The kernel version of pcLDA is presented to\nhandle nonlinear projections. Efficient algorithms are presented\nto efficiently compute the proposed models.",
    "Authors1": "Deguang Kong",
    "Authors2": "Chris Ding",
    "Authors3": "Qihe Pan",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Deguang Kong, Chris Ding , Qihe Pan",
    "Groups1": "Applications (APP)",
    "Groups2": "Machine Learning Applications (MLA)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Applications (APP);Machine Learning Applications (MLA)",
    "Keywords10": "",
    "Keywords1": "linear discriminant analysis",
    "Keywords2": "gradient",
    "Keywords3": "pairwise",
    "Keywords4": "covariance",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "linear discriminant analysis;gradient;pairwise;covariance",
    "Title": "Pairwise-Covariance Linear Discriminant Analysis",
    "Topics10": "",
    "Topics1": "",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": ""
  },
  {
    "Document Index (generated)": 346,
    "Number of Records": 1,
    "Abstract": "Monte Carlo tree search (MCTS) is a popular class of algorithms for online decision making in large Markov decision processes (MDPs). The effectiveness of these algorithms, however, often deteriorates for MDPs with high stochastic branching factors. In this paper, we study state aggregation as a way of reducing stochastic branching in tree search. Prior work has studied formal properties of MDP state aggregation in the context of dynamic programming and reinforcement learning, but little attention has been paid to state aggregation in MCTS. Our main contribution is to establish basic results about the optimality-preserving properties of state aggregation for search trees. We then apply these results to show that popular MCTS algorithms such as UCT and sparse sampling can employ fairly coarse state aggregation schemes while retaining their theoretical properties. As a proof of concept, we experimentally confirm that state aggregation in MCTS improves finite-sample performance.",
    "Authors1": "Jesse Hostetler",
    "Authors2": "Alan Fern",
    "Authors3": "Tom Dietterich",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Jesse Hostetler, Alan Fern , Tom Dietterich",
    "Groups1": "Planning and Scheduling (PS)",
    "Groups2": "Reasoning under Uncertainty (RU)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Planning and Scheduling (PS);Reasoning under Uncertainty (RU)",
    "Keywords10": "",
    "Keywords1": "markov decision process",
    "Keywords2": "monte carlo tree search",
    "Keywords3": "state abstraction",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "markov decision process;monte carlo tree search;state abstraction",
    "Title": "State Aggregation in Monte Carlo Tree Search",
    "Topics10": "",
    "Topics1": "PS: Probabilistic Planning",
    "Topics2": "RU: Sequential Decision Making",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "PS: Probabilistic Planning;RU: Sequential Decision Making"
  },
  {
    "Document Index (generated)": 347,
    "Number of Records": 1,
    "Abstract": "In many probabilistic planning scenarios, a system's behavior needs to not only maximize the expected utility but also obey certain restrictions. This paper presents Saturated Path-Constrained Markov Decision Processes (SPC MDPs), a new MDP type for planning under uncertainty with deterministic model-checking constraints, e.g., \"state s must be visited before s'\", \"the system must end up in s\", or \"the system must never enter s\". We present a mathematical analysis of SPC MDPs, showing that although SPC MDPs generally have no optimal policies, every instance of this class has an epsilon-optimal randomized policy for any epsilon > 0. We propose a dynamic programming-based algorithm for finding such policies, and empirically demonstrate this algorithm to be orders of magnitude faster than its next-best alternative.",
    "Authors1": "Jonathan Sprauel",
    "Authors2": "Andrey Kolobov",
    "Authors3": "Florent Teichteil-Königsbuch",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Jonathan Sprauel, Andrey Kolobov , Florent Teichteil-Königsbuch",
    "Groups1": "Planning and Scheduling (PS)",
    "Groups2": "Reasoning under Uncertainty (RU)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Planning and Scheduling (PS);Reasoning under Uncertainty (RU)",
    "Keywords10": "",
    "Keywords1": "Safe and Optimal Controller Synthesis",
    "Keywords2": "Uncertainty and Stochasticity",
    "Keywords3": "Planning under Uncertainty",
    "Keywords4": "Model-Checking PCTL Constraints",
    "Keywords5": "Path-Constrained Markov Decision Processes",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Safe and Optimal Controller Synthesis;Uncertainty and Stochasticity;Planning under Uncertainty;Model-Checking PCTL Constraints;Path-Constrained Markov Decision Processes",
    "Title": "Saturated Path-Constrained MDP: Planning under Uncertainty and Deterministic Model-Checking Constraints",
    "Topics10": "",
    "Topics1": "PS: Markov Models of Environments",
    "Topics2": "PS: Probabilistic Planning",
    "Topics3": "PS: Planning (General/Other)",
    "Topics4": "RU: Sequential Decision Making",
    "Topics5": "SCS: Constraint Satisfaction (General/other)",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "PS: Markov Models of Environments;PS: Probabilistic Planning;PS: Planning (General/Other);RU: Sequential Decision Making;SCS: Constraint Satisfaction (General/other)"
  },
  {
    "Document Index (generated)": 348,
    "Number of Records": 1,
    "Abstract": "It's a well known fact that in extensive form games with perfect information, there is a Nash equilibrium with support of size one. This doesn't hold for games with imperfect information, where the size of minimal support can be larger. We present a dependency between the level of uncertainty and the minimum support size. For many games, there is a big disproportion between the game uncertainty and the number of actions available. In Bayesian extensive games with perfect information, the only uncertainty is about the type of players. In card games, the uncertainty comes from dealing the deck. In these games, we can significantly reduce the support size. Our result applies to general-sum extensive form games with any finite number of players.",
    "Authors1": "Martin Schmid",
    "Authors2": "Matej Moravcik",
    "Authors3": "Milan Hladik",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Martin Schmid, Matej Moravcik , Milan Hladik",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP)",
    "Keywords10": "",
    "Keywords1": "Game theory",
    "Keywords2": "Nash equilibrium",
    "Keywords3": "Support",
    "Keywords4": "Extensive form games",
    "Keywords5": "Bayesian extensive games",
    "Keywords6": "Poker",
    "Keywords7": "Equilibrium preserving transformation",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Game theory;Nash equilibrium;Support;Extensive form games;Bayesian extensive games;Poker;Equilibrium preserving transformation",
    "Title": "Bounding the Support Size in Extensive Form Games with Imperfect Information",
    "Topics10": "",
    "Topics1": "GTEP: Game Theory",
    "Topics2": "GTEP: Equilibrium",
    "Topics3": "GTEP: Imperfect Information",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Game Theory;GTEP: Equilibrium;GTEP: Imperfect Information"
  },
  {
    "Document Index (generated)": 349,
    "Number of Records": 1,
    "Abstract": "Answer set programs (ASP) with external evaluations are a declarative means to capture advanced applications. However, their evaluation can be expensive due to external source accesses. In this paper we consider hex-programs that provide external atoms as a bidirectional interface to external sources and present a novel evaluation method based on support sets, which informally are portions of the input to an external atom that will determine its output for any completion of the partial input. Support sets allow one to shortcut the external source access, which can be completely eliminated. This is particularly attractive if a compact representation of suitable support sets is efficiently constructible. We discuss some applications with this property, among them description logic programs over DL-Lite ontologies, and present experimental results showing that support sets can significantly improve efficiency.",
    "Authors1": "Thomas Eiter",
    "Authors2": "Michael Fink",
    "Authors3": "Christoph Redl",
    "Authors4": "Daria Stepanova",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Thomas Eiter, Michael Fink, Christoph Redl , Daria Stepanova",
    "Groups1": "Knowledge Representation and Reasoning (KRR)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Knowledge Representation and Reasoning (KRR)",
    "Keywords10": "",
    "Keywords1": "Answer Set Programming",
    "Keywords2": "External Sources",
    "Keywords3": "Description Logic Programs",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Answer Set Programming;External Sources;Description Logic Programs",
    "Title": "Exploiting Support Sets for Answer Set Programs with External Evaluations",
    "Topics10": "",
    "Topics1": "KRR: Ontologies",
    "Topics2": "KRR: Description Logics",
    "Topics3": "KRR: Knowledge Representation Languages",
    "Topics4": "KRR: Logic Programming",
    "Topics5": "KRR: Nonmonotonic Reasoning",
    "Topics6": "KRR: Knowledge Representation (General/Other)",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "KRR: Ontologies;KRR: Description Logics;KRR: Knowledge Representation Languages;KRR: Logic Programming;KRR: Nonmonotonic Reasoning;KRR: Knowledge Representation (General/Other)"
  },
  {
    "Document Index (generated)": 350,
    "Number of Records": 1,
    "Abstract": "Non-rigid shape comparison based on manifold embedding using Generalized Multidimensional Scaling (GMDS) has attracted a lot of attention for its high accuracy. However, this method requires that shape surface is not elastic. In other words, it is sensitive to topological transformations such as stretching and compressing. To tackle this problem, we propose a new approach that constructs a high-dimensional space to embed the manifolds of shapes, which could completely withstand rigid transformations and considerably tolerate topological transformations. Experiments on TOSCA shapes validate the proposed approach.",
    "Authors1": "Longwen Gao",
    "Authors2": "Shuigeng Zhou",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Longwen Gao , Shuigeng Zhou",
    "Groups1": "Vision (VIS)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Vision (VIS)",
    "Keywords10": "",
    "Keywords1": "Shape Comparison",
    "Keywords2": "Manifold Embedding",
    "Keywords3": "Sparse Representation",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Shape Comparison;Manifold Embedding;Sparse Representation",
    "Title": "Towards Topological-transformation Robust Shape Comparison:  A Sparse Representation Based Manifold Embedding Approach",
    "Topics10": "",
    "Topics1": "VIS: Object Recognition",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "VIS: Object Recognition"
  },
  {
    "Document Index (generated)": 351,
    "Number of Records": 1,
    "Abstract": "Dictionary learning (DL) has now become an important feature learning technique that owns state-of-the-art recog-nition performance. Due to sparse characteristic of data in real-world applications, dictionary learning uses a set of learned dictionary bases to represent the linear decomposi-tion of a data point. Fisher discrimination DL (FDDL) is a representative supervised DL method, which constructs a structured dictionary whose atoms correspond to the class labels. Recent years have witnessed a growing interest in multi-view (more than two views) feature learning tech-niques. Although some multi-view (or multi-modal) DL methods have been presented, there still exists much room for improvement. How to enhance the total discriminability of dictionaries and reduce their redundancy is a crucial re-search topic. To boost the performance of multi-view dic-tionary learning technique, we propose an uncorrelated multi-view fisher discrimination DL (UMFDDL) approach for recognition. By making dictionary atoms correspond to the class labels such that the obtained reconstruction error is discriminative, UMFDDL aims to jointly learn multiple dic-tionaries with totally favorable discriminative power. Fur-thermore, we design the uncorrelated constraint for multi-view DL, so as to reduce the redundancy among dictionaries learned from different views. Experiments on several public datasets demonstrate the effectiveness of the proposed approach.",
    "Authors1": "Xiao-Yuan Jing",
    "Authors2": "Rui-Min Hu",
    "Authors3": "Fei Wu",
    "Authors4": "Xi-Lin Chen",
    "Authors5": "Qian Liu",
    "Authors6": "Yong-Fang Yao",
    "Authors7": "",
    "Authors": "Xiao-Yuan Jing, Rui-Min Hu, Fei Wu, Xi-Lin Chen, Qian Liu , Yong-Fang Yao",
    "Groups1": "Vision (VIS)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Vision (VIS)",
    "Keywords10": "",
    "Keywords1": "Fisher discrimination Dictionary learning (FDDL)",
    "Keywords2": "Multi-view FDDL (MFDDL)",
    "Keywords3": "Uncorrelated MFDDL (UMFDDL)",
    "Keywords4": "Uncorrelated constraint",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Fisher discrimination Dictionary learning (FDDL);Multi-view FDDL (MFDDL);Uncorrelated MFDDL (UMFDDL);Uncorrelated constraint",
    "Title": "Uncorrelated Multi-view Fisher Discrimination Dictionary Learning For Recognition",
    "Topics10": "",
    "Topics1": "NMLA: Supervised Learning (Other)",
    "Topics2": "VIS: Categorization",
    "Topics3": "VIS: Object Recognition",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Supervised Learning (Other);VIS: Categorization;VIS: Object Recognition"
  },
  {
    "Document Index (generated)": 352,
    "Number of Records": 1,
    "Abstract": "Predicting human activities is important for improving recommendation\n systems or analyzing social relationships among users. Those human\n activities are usually represented as multi-object relationships\n (e.g. user's tagging activity for items or user's tweeting activity at\n some location).  Since multi-object relationships are naturally\n represented as a tensor, tensor factorization is becoming more\n important for predicting users' possible activities.  However, the\n prediction accuracy of tensor factorization is weak for ambiguous\n and/or sparsely observed objects. Our solution, Semantic data\n Representation for Tensor Factorization (SRTF), tackles these problems\n by incorporating semantics into tensor factorization based on the\n following ideas: (1) it links objects to vocabularies/taxonomies and\n resolves the ambiguity caused by objects that can be used for multiple\n purposes. (2) it links objects to composite classes that merge classes\n in different kinds of vocabularies/taxonomies (e.g. classes in\n vocabularies for movie genres and those for directors) to avoid low\n prediction accuracy caused by rough-grained semantic space.  (3) it\n lifts sparsely observed objects into their classes to solve the\n sparsity problem for rarely observed objects.\n Experiments show that SRTF achieves 10\\% higher accuracy than current\n best methods.",
    "Authors1": "Makoto Nakatsuji",
    "Authors2": "Yasuhiro Fujiwara",
    "Authors3": "Hiroyuki Toda",
    "Authors4": "Hiroshi Sawada",
    "Authors5": "Jin Zheng",
    "Authors6": "James Hendler",
    "Authors7": "",
    "Authors": "Makoto Nakatsuji, Yasuhiro Fujiwara, Hiroyuki Toda, Hiroshi Sawada, Jin Zheng , James Hendler",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "Novel Machine Learning Algorithms (NMLA)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW);Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "Collaborative Filtering",
    "Keywords2": "Recommender System",
    "Keywords3": "Tensor Factorization",
    "Keywords4": "Rating prediction",
    "Keywords5": "Bayesian probabilistic tensor factorization",
    "Keywords6": "Linked Open Data",
    "Keywords7": "Taxonomy",
    "Keywords8": "Semantics on the web",
    "Keywords9": "",
    "Keywords": "Collaborative Filtering;Recommender System;Tensor Factorization;Rating prediction;Bayesian probabilistic tensor factorization;Linked Open Data;Taxonomy;Semantics on the web",
    "Title": "Semantic Data Representation for Improving Tensor Factorization",
    "Topics10": "",
    "Topics1": "AIW: Exploiting Linked Open Data",
    "Topics2": "AIW: Ontologies and the web: creation, extraction, evolution, mapping, merging, and alignment",
    "Topics3": "tags and folksonomies",
    "Topics4": "AIW: Web-based recommendation systems",
    "Topics5": "NMLA: Data Mining and Knowledge Discovery",
    "Topics6": "NMLA: Recommender Systems",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: Exploiting Linked Open Data;AIW: Ontologies and the web: creation, extraction, evolution, mapping, merging, and alignment; tags and folksonomies;AIW: Web-based recommendation systems;NMLA: Data Mining and Knowledge Discovery;NMLA: Recommender Systems"
  },
  {
    "Document Index (generated)": 353,
    "Number of Records": 1,
    "Abstract": "Abduction is a form of nonmonotonic reasoning that looks for an explanation, \nbuilt from a  given set of hypotheses, \nfor an observed manifestation according to some knowledge base.\nFollowing the concept behind the Schaefer's parametrization\nCSP(Gamma) of the Constraint Satisfaction Problem (CSP),\nwe study here the complexity of the abduction problem\nAbduction(Gamma, Hyp, M) parametrized by certain (omega-categorical) infinite \nrelational structures Gamma, Hyp, and M\nfrom which a knowledge base, hypotheses and a manifestation are built, respectively.\n\nWe say that Gamma  has local-to-global consistency if\nthere is k such that establishing strong k-consistency on an instance of CSP(Gamma) yields a globally consistent \n(whose every solution may be obtained straightforwardly from partial solutions) set of constraints.\nIn this case CSP(Gamma) is solvable in polynomial time.\nOur main contribution is an algorithm that under some natural conditions\ndecides  Abduction(Gamma, Hyp, M) in P when Gamma\nhas local-to-global consistency. \n\nAs we show in the number of examples, our approach offers\nan opportunity to consider abduction\nin the context of spatial and temporal reasoning (qualitative calculi such as Allen's\ninterval algebra or RCC-5) and that our procedure solves some related abduction problems in polynomial time.",
    "Authors1": "Michał Wrona",
    "Authors2": "",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Michał Wrona",
    "Groups1": "Knowledge Representation and Reasoning (KRR)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Knowledge Representation and Reasoning (KRR)",
    "Keywords10": "",
    "Keywords1": "Diagnosis and Abductive Reasoning",
    "Keywords2": "Spatial and Temporal Reasoning",
    "Keywords3": "Local Consistency",
    "Keywords4": "Computational Complexity",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Diagnosis and Abductive Reasoning;Spatial and Temporal Reasoning;Local Consistency;Computational Complexity",
    "Title": "Local-To-Global Consistency Implies Tractability of Abduction",
    "Topics10": "",
    "Topics1": "KRR: Computational Complexity of Reasoning",
    "Topics2": "KRR: Diagnosis and Abductive Reasoning",
    "Topics3": "KRR: Geometric, Spatial, and Temporal Reasoning",
    "Topics4": "KRR: Nonmonotonic Reasoning",
    "Topics5": "KRR: Qualitative Reasoning",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "KRR: Computational Complexity of Reasoning;KRR: Diagnosis and Abductive Reasoning;KRR: Geometric, Spatial, and Temporal Reasoning;KRR: Nonmonotonic Reasoning;KRR: Qualitative Reasoning"
  },
  {
    "Document Index (generated)": 354,
    "Number of Records": 1,
    "Abstract": "Higher-order tensors are becoming prevalent in many scientific areas such as computer vision, social network analysis, data mining and neuroscience. Traditional tensor decomposition approaches face three major challenges: model selecting, gross corruptions, and computational efficiency. To address these problems, we first propose a parallel trace norm regularized tensor decomposition method, and formulate it as a convex optimization problem. This method does not require the rank of each model to be specified beforehand, and can automatically determine the number of factors in each mode through our optimization scheme. By considering the low-rank structure of the observed tensor, we analyze the equivalent relationship of the trace norm between a low-rank tensor and its core tensor. Then, we cast a non-convex tensor decomposition model into a weighted combination of multiple much smaller-scale matrix trace norm minimization. Finally, we develop two parallel alternating direction methods of multipliers (ADMM) to solve the proposed problems. Experimental results verify that our regularized formulation is reasonable, and our methods are very robust to noise or outliers.",
    "Authors1": "Fanhua Shang",
    "Authors2": "Yuanyuan Liu",
    "Authors3": "James Cheng",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Fanhua Shang, Yuanyuan Liu , James Cheng",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "Tensor decomposition",
    "Keywords2": "Higher-order orthogonal iteration",
    "Keywords3": "Parallel Optimization",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Tensor decomposition;Higher-order orthogonal iteration;Parallel Optimization",
    "Title": "Generalized Higher-Order Tensor Decomposition via Parallel ADMM",
    "Topics10": "",
    "Topics1": "NMLA: Dimension Reduction/Feature Selection",
    "Topics2": "NMLA: Feature Construction/Reformulation",
    "Topics3": "NMLA: Unsupervised Learning (Other)",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Dimension Reduction/Feature Selection;NMLA: Feature Construction/Reformulation;NMLA: Unsupervised Learning (Other)"
  },
  {
    "Document Index (generated)": 355,
    "Number of Records": 1,
    "Abstract": "In this paper we consider the problem of repairing missing is-a relations in ontologies. We formalize the problem as a generalized TBox abduction problem (GTAP).\nBased on this abduction framework, we present complexity results for the existence, relevance and necessity decision problems for the GTAP with and without some\nspecific preference relations for ontologies that can be represented using a member of the EL family of description logics. Further, we present an algorithm for finding solutions, a system as well as experiments.",
    "Authors1": "Fang Wei-Kleiner",
    "Authors2": "Zlatan Dragisic",
    "Authors3": "Patrick Lambrix",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Fang Wei-Kleiner, Zlatan Dragisic , Patrick Lambrix",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "Knowledge Representation and Reasoning (KRR)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW);Knowledge Representation and Reasoning (KRR)",
    "Keywords10": "",
    "Keywords1": "ontology debugging",
    "Keywords2": "ontology engineering",
    "Keywords3": "description logics",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "ontology debugging;ontology engineering;description logics",
    "Title": "Abduction Framework for Repairing Incomplete  EL Ontologies:  Complexity Results and Algorithms",
    "Topics10": "",
    "Topics1": "AIW: Ontologies and the web: creation, extraction, evolution, mapping, merging, and alignment",
    "Topics2": "tags and folksonomies",
    "Topics3": "KRR: Ontologies",
    "Topics4": "KRR: Description Logics",
    "Topics5": "KRR: Diagnosis and Abductive Reasoning",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: Ontologies and the web: creation, extraction, evolution, mapping, merging, and alignment; tags and folksonomies;KRR: Ontologies;KRR: Description Logics;KRR: Diagnosis and Abductive Reasoning"
  },
  {
    "Document Index (generated)": 356,
    "Number of Records": 1,
    "Abstract": "Policy gradient reinforcement learning (PGRL) methods have received substantial attention as a mean for seeking stochastic policies that maximize a cumulative reward. However, PGRL methods can often take a huge number of learning steps before it finds a reasonable stochastic policy. This learning speed depends on the mixing time of the Markov chains that are given by the policies that PGRL explores. In this paper, we give a new PGRL approach that regularizes the rule of updating the policy with the hitting time that bounds the mixing time. In particular, hitting-time regressions based on temporal-difference learning are proposed. The proposed approach will keep the Markov chain compact and can improve the learning efficiency. Numerical experiments show the proposed method outperforms the conventional policy gradient methods.",
    "Authors1": "Tetsuro Morimura",
    "Authors2": "Takayuki Osogami",
    "Authors3": "Tomoyuki Shirai",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Tetsuro Morimura, Takayuki Osogami , Tomoyuki Shirai",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "Reinforcement learning",
    "Keywords2": "Policy gradient",
    "Keywords3": "Markov chain mixing time",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Reinforcement learning;Policy gradient;Markov chain mixing time",
    "Title": "Mixing-time Regularized Policy Gradient",
    "Topics10": "",
    "Topics1": "CS: Problem solving and decision making",
    "Topics2": "NMLA: Reinforcement Learning",
    "Topics3": "RU: Sequential Decision Making",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "CS: Problem solving and decision making;NMLA: Reinforcement Learning;RU: Sequential Decision Making"
  },
  {
    "Document Index (generated)": 357,
    "Number of Records": 1,
    "Abstract": "The action programming language \\Golog\\ has been found useful for the control of autonomous agents such as mobile robots. In scenarios like these, tasks are often open-ended so that the respective control programs are non-terminating. Before deploying such programs on a robot, it is often desirable to verify that they meet certain requirements. For this purpose, Claßen and Lakemeyer recently introduced algorithms for the verification of temporal properties of Golog programs. However, given the expressiveness of Golog, their verification procedures are not guaranteed to terminate. In this paper, we show how decidability can be obtained by suitably restricting the underlying base logic, the effect axioms for primitive actions, and the use of actions within Golog programs.  Moreover, we show that dropping any of these restrictions immediately leads to undecidability of the verification problem.",
    "Authors1": "Jens Classen",
    "Authors2": "Martin Liebenberg",
    "Authors3": "Gerhard Lakemeyer",
    "Authors4": "Benjamin Zarrieß",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Jens Classen, Martin Liebenberg, Gerhard Lakemeyer , Benjamin Zarrieß",
    "Groups1": "Knowledge Representation and Reasoning (KRR)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Knowledge Representation and Reasoning (KRR)",
    "Keywords10": "",
    "Keywords1": "Situation Calculus",
    "Keywords2": "Golog",
    "Keywords3": "Verification",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Situation Calculus;Golog;Verification",
    "Title": "Exploring the Boundaries of Decidable Verification of Non-Terminating Golog Programs",
    "Topics10": "",
    "Topics1": "KRR: Action, Change, and Causality",
    "Topics2": "KRR: Geometric, Spatial, and Temporal Reasoning",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "KRR: Action, Change, and Causality;KRR: Geometric, Spatial, and Temporal Reasoning"
  },
  {
    "Document Index (generated)": 358,
    "Number of Records": 1,
    "Abstract": "A Simple Temporal Network with Uncertainty (STNU) is a structure for\nrepresenting and reasoning about temporal constraints in domains where\nsome temporal durations are not controlled by the executor.  The most\nimportant property of an STNU is whether it is dynamically\ncontrollable (DC); that is, whether there exists a strategy for\nexecuting the controllable time-points that guarantees that all\nconstraints will be satisfied no matter how the uncontrollable\ndurations turn out.\n\nThis paper provides a novel mapping from STNUs to Timed Game Automata\n(TGAs) that: (1) explicates the deep theoretical relationships between\nSTNUs and TGAs; and (2) enables the memoryless strategies generated\nfrom the TGA to be transformed into equivalent STNU execution\nstrategies that reduce the real-time computational burden for the\nexecutor.  The paper formally proves that the STNU-to-TGA encoding\nproperly captures the execution semantics of STNUs.  It also provides\nexperimental evidence of the proposed approaches, generating offline\nexecution strategies for dynamically controllable STNUs encoded as\nTGAs.",
    "Authors1": "Aless",
    "Authors2": "ro Cimatti",
    "Authors3": "Luke Hunsberger",
    "Authors4": "Andrea Micheli",
    "Authors5": "Marco Roveri",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Aless,ro Cimatti, Luke Hunsberger, Andrea Micheli , Marco Roveri",
    "Groups1": "Planning and Scheduling (PS)",
    "Groups2": "Reasoning under Uncertainty (RU)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Planning and Scheduling (PS);Reasoning under Uncertainty (RU)",
    "Keywords10": "",
    "Keywords1": "Dynamic Controllability",
    "Keywords2": "Strategy Synthesis",
    "Keywords3": "Simple Temporal Networks with Uncertainty",
    "Keywords4": "Timed Game Automata",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Dynamic Controllability;Strategy Synthesis;Simple Temporal Networks with Uncertainty;Timed Game Automata",
    "Title": "Using Timed Game Automata to Synthesize Execution Strategies for Simple Temporal Networks with Uncertainty",
    "Topics10": "",
    "Topics1": "PS: Plan Execution and Monitoring",
    "Topics2": "PS: Scheduling",
    "Topics3": "RU: Uncertainty in AI (General/Other)",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "PS: Plan Execution and Monitoring;PS: Scheduling;RU: Uncertainty in AI (General/Other)"
  },
  {
    "Document Index (generated)": 359,
    "Number of Records": 1,
    "Abstract": "In case-based reasoning (CBR), problems are solved by retrieving prior cases and adapting their solutions to fit new problems. Controlling the growth of the case base in CBR is a fundamental problem. Much research on case-base maintenance has developed methods aimed at compacting case bases while maintaining system competence, by deleting cases whose absence is considered least likely to degrade the system's problem-solving, given static case adaptation knowledge. This paper proposes adaptation-guided case-base maintenance (AGCBM), a case-base maintenance approach exploiting the ability to dynamically generate new adaptation knowledge from cases. In AGCMB, case retention decisions are based both on their value as base cases for solving problems and on their value for generating new adaptation rules, in turn increasing the problem-solving value of other cases in the case base. The paper tests the method for numerical prediction tasks (case-based regression) in which rules are generated automatically using the case difference heuristic. Tests on four sample domains compare accuracy with a set of five candidate case-based maintenance methods, for varying case-base densities. AGCBM outperformed the alternatives all domains, with the benefit most substantial for the greatest amounts of compression.",
    "Authors1": "Vahid Jalali",
    "Authors2": "David Leake",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Vahid Jalali , David Leake",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "Adaptation-Guided Case-Based Maintenance",
    "Keywords2": "Case-Based Maintenance",
    "Keywords3": "Case-Based Reasoning",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Adaptation-Guided Case-Based Maintenance;Case-Based Maintenance;Case-Based Reasoning",
    "Title": "Adaptation Guided Case Base Maintenance",
    "Topics10": "",
    "Topics1": "NMLA: Case-Based Reasoning",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Case-Based Reasoning"
  },
  {
    "Document Index (generated)": 360,
    "Number of Records": 1,
    "Abstract": "The Fisher market model is one of the most fundamental resource allocation models in economics. In a Fisher market, the prices and allocations of goods are determined according to the preferences and budgets of buyers to clear the market.\n\nIn a Fisher market game, however, buyers are strategic and report their preferences over goods; the market-clearing prices and allocations are then determined based on their reported preferences rather than their real preferences.\nWe show that the Fisher market game always has a pure Nash equilibrium, for buyers with linear, Leontief, and Cobb-Douglas utility functions, which are three representative classes of utility functions in the important Constant Elasticity of Substitution (CES) family. Furthermore, to quantify the social efficiency, we prove Price of Anarchy bounds for the game when the utility functions of buyers fall into these three classes respectively.",
    "Authors1": "Simina Brânzei",
    "Authors2": "Yiling Chen",
    "Authors3": "Xiaotie Deng",
    "Authors4": "Aris Filos-Ratsikas",
    "Authors5": "Søren Kristoffer Stiil Frederiksen",
    "Authors6": "Jie Zhang",
    "Authors7": "",
    "Authors": "Simina Brânzei, Yiling Chen, Xiaotie Deng, Aris Filos-Ratsikas, Søren Kristoffer Stiil Frederiksen , Jie Zhang",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP)",
    "Keywords10": "",
    "Keywords1": "Fisher markets",
    "Keywords2": "Fisher market game",
    "Keywords3": "Equilibrium analysis",
    "Keywords4": "Price of anarchy",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Fisher markets;Fisher market game;Equilibrium analysis;Price of anarchy",
    "Title": "The Fisher Market Game: Equilibrium and Welfare",
    "Topics10": "",
    "Topics1": "GTEP: Auctions and Market-Based Systems",
    "Topics2": "GTEP: Game Theory",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Auctions and Market-Based Systems;GTEP: Game Theory"
  },
  {
    "Document Index (generated)": 361,
    "Number of Records": 1,
    "Abstract": "Associative memories are data structures that allow retrieval of previously stored messages given part of their content. They thus behave similarly to human brain's memory that is capable for instance of retrieving the end of a song given its beginning. Among different families of associative memories, sparse ones are known to provide the best efficiency (ratio of the number of bits stored to that of bits used). Nevertheless, it is well known that non-uniformity of the stored messages can lead to dramatic decrease in performance. Recently, a new family of sparse associative memories achieving almost-optimal efficiency has been proposed. Their structure induces a direct mapping between input messages and stored patterns. In this work, we show the impact of non-uniformity on the performance of this recent model and we exploit the structure of the model to introduce several strategies to allow for efficient storage of non-uniform messages. We show that a technique based on Huffman coding is the most efficient.",
    "Authors1": "Bartosz Boguslawski",
    "Authors2": "Vincent Gripon",
    "Authors3": "Fabrice Seguin",
    "Authors4": "Frédéric Heitzmann",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Bartosz Boguslawski, Vincent Gripon, Fabrice Seguin , Frédéric Heitzmann",
    "Groups1": "Applications (APP)",
    "Groups2": "Machine Learning Applications (MLA)",
    "Groups3": "Novel Machine Learning Algorithms (NMLA)",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Applications (APP);Machine Learning Applications (MLA);Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "neural clique",
    "Keywords2": "sparsity",
    "Keywords3": "associative memory",
    "Keywords4": "non-uniform distribution",
    "Keywords5": "compression code",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "neural clique;sparsity;associative memory;non-uniform distribution;compression code",
    "Title": "Huffman Coding for Storing Non-uniformly Distributed Messages in Networks of Neural Cliques",
    "Topics10": "",
    "Topics1": "APP: Security and Privacy",
    "Topics2": "APP: Other Applications",
    "Topics3": "MLA: Machine Learning Applications (General/other)",
    "Topics4": "NMLA: Neural Networks/Deep Learning",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "APP: Security and Privacy;APP: Other Applications;MLA: Machine Learning Applications (General/other);NMLA: Neural Networks/Deep Learning"
  },
  {
    "Document Index (generated)": 362,
    "Number of Records": 1,
    "Abstract": "This paper presents an agent-based model that studies the emergence\nand evolution of a language system of logical constructions, i.e. a\nvocabulary and a set of grammatical constructions that allow\nexpressing logical combinations of categories. The model assumes\nthe agents have a common vocabulary for basic categories, the ability\nto construct logical combinations of categories using Boolean\nfunctions, and some general purpose cognitive capacities for\ninvention, adoption, induction and adaptation. But it does not assume the agents\nhave a vocabulary for Boolean functions nor grammatical constructions\nfor expressing such logical combinations of categories through\nlanguage.  The results of the experiments we have performed show that\na language system of logical constructions emerges as a result of a\nprocess of self-organisation of the individual agents'\ninteractions when these agents adapt their preferences for vocabulary\nand grammatical constructions to those they observe are used more\noften by the rest of the population, and that such language system \nis transmitted from one generation to the next.",
    "Authors1": "Josefina Sierra-Santibanez",
    "Authors2": "",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Josefina Sierra-Santibanez",
    "Groups1": "Cognitive Modeling (CM)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Cognitive Modeling (CM)",
    "Keywords10": "",
    "Keywords1": "Cognitive Modeling",
    "Keywords2": "Symbolic AI",
    "Keywords3": "Simulating Humans",
    "Keywords4": "Adaptive Behavior",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Cognitive Modeling;Symbolic AI;Simulating Humans;Adaptive Behavior",
    "Title": "An Agent-Based Model Studying the Acquisition of a Language System of Logical Constructions",
    "Topics10": "",
    "Topics1": "CM: Adaptive Behavior",
    "Topics2": "CM: Simulating Humans",
    "Topics3": "CM: Symbolic AI",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "CM: Adaptive Behavior;CM: Simulating Humans;CM: Symbolic AI"
  },
  {
    "Document Index (generated)": 363,
    "Number of Records": 1,
    "Abstract": "Fitted Q-iteration (FQI) stands out among reinforcement-learning algorithms for its flexibility and easy of use. FQI can be combined with any regression method, and this choice determines the algorithm's theoretical and computational properties. The combination of FQI with an ensemble of regression trees gives rises to an algorithm, FQIT, that is computationally efficient, scalable to high dimensional spaces, and robust to irrelevant variables, outliers, and noise. Despite its nice properties and good performance in practice, FQIT also has some limitations: the fact that an ensemble of trees must be constructed (or updated) at each iteration confines the algorithm to the batch scenario. This paper aims to address this specific issue. Based on a strategy recently proposed in the literature, called the stochastic-factorization trick, we propose a modification of FQIT that makes it fully incremental, and thus suitable for on-line learning. We call the resulting method tree-based stochastic factorization (TBSF). We derive an upper bound for the difference between the value functions computed by FQIT and TBSF, and also show in which circumstances the approximations coincide. A series of computational experiments is presented to illustrate the properties of TBSF and to show its usefulness in practice.",
    "Authors1": "Andre Barreto",
    "Authors2": "",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Andre Barreto",
    "Groups1": "Reasoning under Uncertainty (RU)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Reasoning under Uncertainty (RU)",
    "Keywords10": "",
    "Keywords1": "Reinforcement Learning",
    "Keywords2": "Markov Decision Processes",
    "Keywords3": "Fitted Q-Iteration",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Reinforcement Learning;Markov Decision Processes;Fitted Q-Iteration",
    "Title": "Tree-Based On-line Reinforcement Learning",
    "Topics10": "",
    "Topics1": "RU: Sequential Decision Making",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "RU: Sequential Decision Making"
  },
  {
    "Document Index (generated)": 364,
    "Number of Records": 1,
    "Abstract": "Due to recent empirical success, machine learning algorithms have drawn sufficient attention and are becoming important analysis tools in financial industry. In particular, as the core engine of many financial services such as private wealth and pension fund management, portfolio management calls for the application of those novel algorithms. Most of portfolio allocation strategies do not account for costs from market frictions such as transaction costs and capital gain taxes, as the complexity of sensible cost models often causes the induced problem intractable. In this paper, we propose a doubly regularized sparse and consistent portfolio that provides a modest but effective solution to the above difficulty. Specifically, as all kinds of trading costs primarily root in large transaction volumes, to reduce volumes we synergistically combine two penalty terms with classic risk minimization models to ensure: (1) only a small set of assets are selected to invest in each period; (2) portfolios in subsequent trading periods are similar. To assess the new portfolio, we apply standard evaluation criteria and conduct extensive experiments on well-known benchmarks and market datasets. Compared to various state-of-the-art portfolios, the proposed portfolio demonstrates a superior performance of having both higher risk-adjusted returns and dramatically decreased transaction volumes.",
    "Authors1": "Weiwei Shen",
    "Authors2": "Jun Wang",
    "Authors3": "Shiqian Ma",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Weiwei Shen, Jun Wang , Shiqian Ma",
    "Groups1": "Applications (APP)",
    "Groups2": "Machine Learning Applications (MLA)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Applications (APP);Machine Learning Applications (MLA)",
    "Keywords10": "",
    "Keywords1": "Portfolion Management",
    "Keywords2": "Risk Minimization",
    "Keywords3": "Doubly Regularized Portfolio",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Portfolion Management;Risk Minimization;Doubly Regularized Portfolio",
    "Title": "Doubly Regularized Portfolio with Risk Minimization",
    "Topics10": "",
    "Topics1": "APP: Other Applications",
    "Topics2": "MLA: Machine Learning Applications (General/other)",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "APP: Other Applications;MLA: Machine Learning Applications (General/other)"
  },
  {
    "Document Index (generated)": 365,
    "Number of Records": 1,
    "Abstract": "We present a feature selection method for solving sparse regularization problem, which has a composite regularization of $\\ell_p$ norm and $\\ell_{\\infty}$ norm.\nWe use proximal gradient method to solve this \\L1inf operator problem, where a simple but efficient algorithm is designed to minimize a relative simple objective function, which contains a vector of $\\ell_2$ norm and $\\ell_\\infty$ norm. Proposed method brings some insight for solving sparsity-favoring norm, and\nextensive experiments are conducted to characterize the effect of varying $p$ and to compare with other approaches on real world multi-class and multi-label datasets.",
    "Authors1": "Deguang Kong",
    "Authors2": "Chris Ding",
    "Authors3": "Qihe Pan",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Deguang Kong, Chris Ding , Qihe Pan",
    "Groups1": "Machine Learning Applications (MLA)",
    "Groups2": "Novel Machine Learning Algorithms (NMLA)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Machine Learning Applications (MLA);Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "feature",
    "Keywords2": "sparse",
    "Keywords3": "learning",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "feature;sparse;learning",
    "Title": "Non-convex feature learning via $\\ell_{p,\\infty}$ operator",
    "Topics10": "",
    "Topics1": "",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": ""
  },
  {
    "Document Index (generated)": 366,
    "Number of Records": 1,
    "Abstract": "Dictionary learning plays an important role in machine learning, where data vectors are modeled as a sparse linear combinations of basis factors (i.e., dictionary). However, how to conduct dictionary learning in noisy environment has not been well studied. Moreover, in practice, the dictionary (i.e., the lower rank approximation of the data matrix) and the sparse representations are required to be nonnegative, such as applications for image annotation, document summarization, microarray analysis. In this paper, we propose a new formulation for non-negative dictionary learning in noisy environment, where structure sparsity is enforced on sparse representation. The proposed new formulation is also robust for data with noises and outliers, due to a robust loss function used.  We derive an efficient multiplicative updating algorithm to solve the optimization problem,  where dictionary and sparse representation are updated iteratively. We prove the convergence and correctness of proposed algorithm rigorously.\nWe show the differences of dictionary at different level of sparsity constraint.\nThe proposed algorithm can be adapted for data clustering and semi-supervised learning purpose. Promising results in extensive experiments validate the effectiveness of proposed approach.",
    "Authors1": "Deguang Kong",
    "Authors2": "Chris Ding",
    "Authors3": "Qihe Pan",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Deguang Kong, Chris Ding , Qihe Pan",
    "Groups1": "Machine Learning Applications (MLA)",
    "Groups2": "Novel Machine Learning Algorithms (NMLA)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Machine Learning Applications (MLA);Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "dictionary learning",
    "Keywords2": "non-negative",
    "Keywords3": "clustering",
    "Keywords4": "multiplicative",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "dictionary learning;non-negative;clustering;multiplicative",
    "Title": "Robust Non-negative Dictionary Learning",
    "Topics10": "",
    "Topics1": "",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": ""
  },
  {
    "Document Index (generated)": 367,
    "Number of Records": 1,
    "Abstract": "Runoff voting rules such as single transferable vote (STV) and Baldwin's rule are of particular interest in computational social choice due to their recursive nature and hardness of manipulation, as well as in (human) practice because they are relatively easy to understand. However, they are not known for their compliance with desirable axiomatic properties, which we attempt to rectify here. We characterize runoff rules that are based on scoring rules using two axioms: a weakening of local independence of irrelevant alternatives and a variant of population-consistency. We then show, as our main technical result, that STV is the only runoff scoring rule satisfying an independence-of-clones property. Furthermore, we provide axiomatizations of Baldwin's rule and Coombs' rule.",
    "Authors1": "Rupert Freeman",
    "Authors2": "Markus Brill",
    "Authors3": "Vincent Conitzer",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Rupert Freeman, Markus Brill , Vincent Conitzer",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP)",
    "Keywords10": "",
    "Keywords1": "computational social choice",
    "Keywords2": "runoff scoring rules",
    "Keywords3": "independence of clones",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "computational social choice;runoff scoring rules;independence of clones",
    "Title": "On the Axiomatic Characterization of Runoff Voting Rules",
    "Topics10": "",
    "Topics1": "GTEP: Social Choice / Voting",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Social Choice / Voting"
  },
  {
    "Document Index (generated)": 368,
    "Number of Records": 1,
    "Abstract": "Scoring involves the compression of a number of quantitative attributes into a single meaningful value. We consider the problem of how to generate scores in a setting where they should be weakly monotone (either non-increasing or non-decreasing) in their dimensions. Our approach allows an expert to score an arbitrary set of points to produce meaningful, continuous, monotone scores over the entire domain, while exactly interpolating through those inputs. In contrast, existing monotone interpolating methods only work in two dimensions and typically require exhaustive grid input. Our technique significantly lowers the bar to score creation, allowing domain experts to develop mathematically coherent scores. The method is used in practice to create the LEED Performance energy and water scores that gauge building sustainability.",
    "Authors1": "Abraham Othman",
    "Authors2": "",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Abraham Othman",
    "Groups1": "Computational Sustainability and AI (CSAI)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Computational Sustainability and AI (CSAI)",
    "Keywords10": "",
    "Keywords1": "Sustainability",
    "Keywords2": "Green Buildings",
    "Keywords3": "Interpolation",
    "Keywords4": "Scientific Computing",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Sustainability;Green Buildings;Interpolation;Scientific Computing",
    "Title": "Supervised Scoring with Monotone Multidimensional Splines",
    "Topics10": "",
    "Topics1": "CSAI: Modeling and control of complex high-dimensional systems",
    "Topics2": "CSAI: Support for public engagement and decision making by the public",
    "Topics3": "HCC: Optimality in the context of human computation",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "CSAI: Modeling and control of complex high-dimensional systems;CSAI: Support for public engagement and decision making by the public;HCC: Optimality in the context of human computation"
  },
  {
    "Document Index (generated)": 369,
    "Number of Records": 1,
    "Abstract": "Graph clustering or community detection constitutes an important\ntask for investigating the internal structure of graphs, with a\nplethora of applications in several diverse domains. Traditional\ntools for graph clustering, such as spectral methods, typically suffer\nfrom high time and space complexity. In this article, we present\nCoreCluster, an efficient graph clustering framework based on\nthe concept of graph degeneracy, that can be used along with any\nknown graph clustering algorithm. Our approach capitalizes on\nprocessing the graph in a hierarchical manner provided by its core\nexpansion sequence, an ordered partition of the graph into different\nlevels according to the k-core decomposition. Such a partition\nprovides a way to process the graph in an incremental manner that\npreserves its clustering structure, while making the execution of the\nchosen clustering algorithm much faster due to the smaller size of\nthe graph’s partitions onto which the algorithm operates.",
    "Authors1": "Christos Giatsidis",
    "Authors2": "Fragkiskos Malliaros",
    "Authors3": "Dimitrios Thilikos",
    "Authors4": "Michalis Vazirgiannis",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Christos Giatsidis, Fragkiskos Malliaros, Dimitrios Thilikos , Michalis Vazirgiannis",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "Applications (APP)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW);Applications (APP)",
    "Keywords10": "",
    "Keywords1": "Community detection",
    "Keywords2": "Graph clustering",
    "Keywords3": "Graph degeneracy",
    "Keywords4": "Graph mining",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Community detection;Graph clustering;Graph degeneracy;Graph mining",
    "Title": "CoreCluster: A Degeneracy Based Graph Clustering Framework",
    "Topics10": "",
    "Topics1": "AIW: Social networking and community identification",
    "Topics2": "APP: Social Networks",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: Social networking and community identification;APP: Social Networks"
  },
  {
    "Document Index (generated)": 370,
    "Number of Records": 1,
    "Abstract": "In this paper we introduce new types of square-piece jigsaw puzzles, where in addition to the unknown location and orientation of each piece, a piece might also need to be flipped. These puzzles, which are associated with a number of real world problems, are considerably harder, from a computational standpoint. Specifically, we present a novel generalized genetic algorithm (GA)-based solver that can handle puzzle pieces of unknown location and orientation (Type 2 puzzles), and puzzle pieces of unknown location, orientation and attitude (Type 4 puzzles). To the best of our knowledge, our solver provides a new state-of-the-art, solving previously attempted puzzles faster and far more accurately, solving puzzle sizes that have never been attempted before, and solving the newly introduced double-sided puzzle types automatically and effectively. This paper also presents, among other results, the most extensive set of experimental results compiled as of yet, on Type 2 puzzles.",
    "Authors1": "Dror Sholomon",
    "Authors2": "Omid E. David",
    "Authors3": "Nathan S. Netanyahu",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Dror Sholomon, Omid E. David , Nathan S. Netanyahu",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "Vision (VIS)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA);Vision (VIS)",
    "Keywords10": "",
    "Keywords1": "genetic algorithms",
    "Keywords2": "jigsaw puzzle",
    "Keywords3": "computer vision",
    "Keywords4": "recombination operators",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "genetic algorithms;jigsaw puzzle;computer vision;recombination operators",
    "Title": "A Generalized Genetic Algorithm-Based Solver for Very Large Jigsaw Puzzles of Complex Types",
    "Topics10": "",
    "Topics1": "NMLA: Evolutionary Computation",
    "Topics2": "VIS: Perception",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Evolutionary Computation;VIS: Perception"
  },
  {
    "Document Index (generated)": 371,
    "Number of Records": 1,
    "Abstract": "Security games model the problem of allocating multiple resources to defend multiple targets. In such settings, the defender's action space is usually exponential in the input size. Therefore, known general-purpose linear or mixed integer program formulations scale up exponentially. One method that has been widely deployed to address this computational issue is to instead compute the marginal probabilities, of which there are only polynomially many.\n\nIn this paper, we address a class of problems that cannot be handled by previous approaches based on marginal probabilities. We consider security games in discretized spatio-temporal domains, in which the schedule set is so large that even the marginal probability formulation has exponential size. We develop novel algorithms under an oracle-based algorithmic framework and show that\nthis framework allows us to efficiently compute Stackelberg mixed strategy \nwhen the problem allows a polynomial-time oracle. For the cases in which efficient oracles are difficult to find, we propose new direct algorithms or prove hardness results. All our algorithms are examined in experiments with realistic and artificial data.",
    "Authors1": "Haifeng Xu",
    "Authors2": "Fei Fang",
    "Authors3": "Albert Jiang",
    "Authors4": "Vincent Conitzer",
    "Authors5": "Shaddin Dughmi",
    "Authors6": "Milind Tambe",
    "Authors7": "",
    "Authors": "Haifeng Xu, Fei Fang, Albert Jiang, Vincent Conitzer, Shaddin Dughmi , Milind Tambe",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "Multiagent Systems (MAS)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP);Multiagent Systems (MAS)",
    "Keywords10": "",
    "Keywords1": "Security Games",
    "Keywords2": "Zero-Sum Games",
    "Keywords3": "Minimax Equilibrium",
    "Keywords4": "Oracle",
    "Keywords5": "Equilibria Computation",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Security Games;Zero-Sum Games;Minimax Equilibrium;Oracle;Equilibria Computation",
    "Title": "Solving Zero-Sum Security Games in Discretized Spatio-Temporal Domains",
    "Topics10": "",
    "Topics1": "GTEP: Game Theory",
    "Topics2": "GTEP: Equilibrium",
    "Topics3": "MAS: Multiagent Systems (General/other)",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Game Theory;GTEP: Equilibrium;MAS: Multiagent Systems (General/other)"
  },
  {
    "Document Index (generated)": 372,
    "Number of Records": 1,
    "Abstract": "Given a set of axis-parallel n-dimensional boxes, the q-intersection is defined as the smallest box encompassing all the points that belong to at least q boxes.  Computing the q-intersection is a combinatorial problem that allows us to handle robust parameter estimation with a numerical constraint programming approach. \nThe q-intersection can be viewed as a filtering operator for soft constraints that model measurements subject to outliers. This paper highlights the equivalence of this operator with the search of q-cliques in a graph whose boxicity is bounded by the number of variables in the constraint network. We present a computational study of the q-intersection. We also propose a fast incomplete algorithm and a sophisticated exact q-intersection algorithm. First experimental results show that our exact algorithm outperforms the existing one while our heuristic performs an efficient filtering on hard problems.",
    "Authors1": "Clement Carbonnel",
    "Authors2": "Gilles Trombettoni",
    "Authors3": "Philippe Vismara",
    "Authors4": "Gilles Chabert",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Clement Carbonnel, Gilles Trombettoni, Philippe Vismara , Gilles Chabert",
    "Groups1": "Search and Constraint Satisfaction (SCS)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Search and Constraint Satisfaction (SCS)",
    "Keywords10": "",
    "Keywords1": "intersection graph",
    "Keywords2": "computational complexity",
    "Keywords3": "parameter estimation",
    "Keywords4": "soft numerical constraints",
    "Keywords5": "q-intersection",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "intersection graph;computational complexity;parameter estimation;soft numerical constraints;q-intersection",
    "Title": "Q-intersection Algorithms for Constraint-Based Robust Parameter Estimation",
    "Topics10": "",
    "Topics1": "SCS: Constraint Satisfaction",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "SCS: Constraint Satisfaction"
  },
  {
    "Document Index (generated)": 373,
    "Number of Records": 1,
    "Abstract": "The automatic discovery of a significant low-dimensional feature representation from given data set is a fundamental problem in machine learning. This paper specifically focuses on to develop feature representation discovery methods appropriate for high-dimensional and sparse data, which are remain a frontier, but are now becoming a highly important tool. We formulate our feature representation discovery problem as a variant of semi-supervised learning problem, namely, an optimization problem over unsupervised data whose objective is evaluating the impact of each feature with respect to modeling a target task according to the initial model constructed by using supervised data. The most notable characteristic of our method is that it offers feasible processing speed even if the numbers of data and features both exceed the billions, and successfully provides significantly small feature sets, i.e., less than 10, that can also offer improved performance comparing with those obtained with using the original feature sets. We demonstrate the effectiveness of our method on experiments of two well-known natural language processing tasks.",
    "Authors1": "Jun Suzuki",
    "Authors2": "Masaaki Nagata",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Jun Suzuki , Masaaki Nagata",
    "Groups1": "NLP and Machine Learning (NLPML)",
    "Groups2": "Novel Machine Learning Algorithms (NMLA)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "NLP and Machine Learning (NLPML);Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "feature representation discovery",
    "Keywords2": "feature selection",
    "Keywords3": "dimensionality reduction",
    "Keywords4": "semi-supervised learning",
    "Keywords5": "feature grouping",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "feature representation discovery;feature selection;dimensionality reduction;semi-supervised learning;feature grouping",
    "Title": "Fused Feature Representation Discovery for High-dimensional and Sparse Data",
    "Topics10": "",
    "Topics1": "NLPML: Natural Language Processing (General/Other)",
    "Topics2": "NMLA: Feature Construction/Reformulation",
    "Topics3": "NMLA: Semisupervised Learning",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NLPML: Natural Language Processing (General/Other);NMLA: Feature Construction/Reformulation;NMLA: Semisupervised Learning"
  },
  {
    "Document Index (generated)": 374,
    "Number of Records": 1,
    "Abstract": "Estimating the remaining energy in high-capacity electric vehicle batteries is essential to safe and efficient operation. Accurate estimation remains a major challenge, however, because battery state cannot be observed directly.  In this paper, we demonstrate a method for estimating battery remaining energy using real data collected from the Charge Car electric vehicle.  This new method relies on energy integration as an initial estimation step, which is then corrected using a neural net that learns how error accumulates from recent charge/discharge cycles.  In this way, the algorithm is able to adapt to nonlinearities and variations that are difficult to model or characterize.  On the collected dataset, this method is demonstrated to be accurate to within 2.5% to 5% of battery remaining energy, which equates to approximately 1 to 2 miles of residual range for the Charge Car given its 10kWh battery pack.",
    "Authors1": "Michael Taylor",
    "Authors2": "",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Michael Taylor",
    "Groups1": "Applications (APP)",
    "Groups2": "Machine Learning Applications (MLA)",
    "Groups3": "Novel Machine Learning Algorithms (NMLA)",
    "Groups4": "Reasoning under Uncertainty (RU)",
    "Groups5": "Robotics (ROB)",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Applications (APP);Machine Learning Applications (MLA);Novel Machine Learning Algorithms (NMLA);Reasoning under Uncertainty (RU);Robotics (ROB)",
    "Keywords10": "",
    "Keywords1": "Electric Vehicles",
    "Keywords2": "Battery Estimation",
    "Keywords3": "State of Charge",
    "Keywords4": "Artificial Neural Nets",
    "Keywords5": "Lithium Iron Phosphate (LiFePo)",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Electric Vehicles;Battery Estimation;State of Charge;Artificial Neural Nets;Lithium Iron Phosphate (LiFePo)",
    "Title": "Joule Counting Correction for Electric Vehicles using Artificial Neural Nets",
    "Topics10": "ROB: State Estimation",
    "Topics1": "APP: Other Applications",
    "Topics2": "MLA: Applications of Unsupervised Learning",
    "Topics3": "MLA: Machine Learning Applications (General/other)",
    "Topics4": "NMLA: Active Learning",
    "Topics5": "NMLA: Time-Series/Data Streams",
    "Topics6": "NMLA: Unsupervised Learning (Other)",
    "Topics7": "NMLA: Machine Learning (General/other)",
    "Topics8": "RU: Uncertainty Representations",
    "Topics9": "ROB: Human-Robot Interaction",
    "Topics": "APP: Other Applications;MLA: Applications of Unsupervised Learning;MLA: Machine Learning Applications (General/other);NMLA: Active Learning;NMLA: Time-Series/Data Streams;NMLA: Unsupervised Learning (Other);NMLA: Machine Learning (General/other);RU: Uncertainty Representations;ROB: Human-Robot Interaction;ROB: State Estimation"
  },
  {
    "Document Index (generated)": 375,
    "Number of Records": 1,
    "Abstract": "In this paper we consider the setting of graph-structured data that evolves as a result of operations carried out by users or applications.  We study different reasoning problems, which range from ensuring the satisfaction of a given set of integrity constraints after a given sequence of updates, to deciding the (non-)existence of a sequence of actions that would take the data to an (un)desirable state, starting either from a specific data instance or from an incomplete description of it.  We consider a simple action language in which actions are finite sequences of insertions and deletions of nodes and labels, and use Description Logics for describing integrity constraints and (partial) states of the data.  We then formalize the data management problems mentioned above as a static verification problem and several planning problems.  We provide algorithms and tight complexity bounds for the formalized problems, both for an expressive DL and for a variant of DL-Lite.",
    "Authors1": "Shqiponja Ahmetaj",
    "Authors2": "Diego Calvanese",
    "Authors3": "Magdalena Ortiz",
    "Authors4": "Mantas Simkus",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Shqiponja Ahmetaj, Diego Calvanese, Magdalena Ortiz , Mantas Simkus",
    "Groups1": "Knowledge Representation and Reasoning (KRR)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Knowledge Representation and Reasoning (KRR)",
    "Keywords10": "",
    "Keywords1": "Graph structured data",
    "Keywords2": "Description Logics",
    "Keywords3": "Static analysis of transactions",
    "Keywords4": "Planning",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Graph structured data;Description Logics;Static analysis of transactions;Planning",
    "Title": "Managing Change in Graph-structured Data Using Description Logics",
    "Topics10": "",
    "Topics1": "KRR: Computational Complexity of Reasoning",
    "Topics2": "KRR: Description Logics",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "KRR: Computational Complexity of Reasoning;KRR: Description Logics"
  },
  {
    "Document Index (generated)": 376,
    "Number of Records": 1,
    "Abstract": "Recent work has shown that it is possible to extract feedback information from\nEEG measurements of brain activity, such as error potentials, and use it to solve\nsequential tasks. As most Brain-Computer Interfaces, a calibration phase is required\nto build a decoder that translates raw EEG signals to understandable feedback\nsignals. This paper proposes a method to solve sequential tasks based on\nfeedback extracted from the brain without any calibration. The proposed method\nuses optimal policies to hallucinate the meaning of the EEG signals and select the\ntarget with the lowest expected error. Also, we use the task and symbol uncertainty\nas an exploration bonus for an active strategy to speed up the learning. We\nreport online experiments where four users directly controlled an agent on a 2D\ngrid world to reach a target without any previous calibration process.",
    "Authors1": "Jonathan Grizou",
    "Authors2": "Iñaki Iturrate",
    "Authors3": "Luis Montesano",
    "Authors4": "Manuel Lopes",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Jonathan Grizou, Iñaki Iturrate, Luis Montesano , Manuel Lopes",
    "Groups1": "Cognitive Modeling (CM)",
    "Groups2": "Humans and AI (HAI)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Cognitive Modeling (CM);Humans and AI (HAI)",
    "Keywords10": "",
    "Keywords1": "Brain-Computer Interfaces",
    "Keywords2": "Calibration",
    "Keywords3": "Human-Robot Interaction",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Brain-Computer Interfaces;Calibration;Human-Robot Interaction",
    "Title": "BCI Based Control Without Explicit Calibration",
    "Topics10": "",
    "Topics1": "CM: Adaptive Behavior",
    "Topics2": "HAI: Brain-Sensing and Analysis",
    "Topics3": "HAI: Communication Protocols",
    "Topics4": "HAI: Human-Computer Interaction",
    "Topics5": "HAI: User Experience and Usability",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "CM: Adaptive Behavior;HAI: Brain-Sensing and Analysis;HAI: Communication Protocols;HAI: Human-Computer Interaction;HAI: User Experience and Usability"
  },
  {
    "Document Index (generated)": 377,
    "Number of Records": 1,
    "Abstract": "Diagnosis, or the process of identifying the nature and cause of an anomaly in an ontology, has been largely studied by the Semantic Web community. In the context of ontology stream, diagnosis results are not captured by a unique fixed ontology but numerous time-evolving ontologies. Thus any anomaly can be diagnosed by a large number of different explanations depending on the version and evolution of the ontology. We address the problems of identifying, representing, exploiting and exploring the evolution of diagnoses representations. Our approach consists in a graph-based representation, which aims at (i) efficiently organizing and linking time-evolving diagnoses and (ii) being used for scalable exploration. The experiments have shown scalable diagnoses exploration in the context of real and live data from Dublin City.",
    "Authors1": "Freddy Lecue",
    "Authors2": "",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Freddy Lecue",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW)",
    "Keywords10": "",
    "Keywords1": "Semantic Web",
    "Keywords2": "Ontology Stream",
    "Keywords3": "Semantic Reasoning",
    "Keywords4": "Knowledge Evolution",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Semantic Web;Ontology Stream;Semantic Reasoning;Knowledge Evolution",
    "Title": "Towards Scalable Exploration of Diagnoses in an Ontology Stream",
    "Topics10": "",
    "Topics1": "AIW: Languages, tools, and methodologies for representing, managing, and visualizing semantic web data",
    "Topics2": "AIW: Ontologies and the web: creation, extraction, evolution, mapping, merging, and alignment",
    "Topics3": "tags and folksonomies",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: Languages, tools, and methodologies for representing, managing, and visualizing semantic web data;AIW: Ontologies and the web: creation, extraction, evolution, mapping, merging, and alignment; tags and folksonomies"
  },
  {
    "Document Index (generated)": 378,
    "Number of Records": 1,
    "Abstract": "The problem of on-line planning in partially observable settings involves two problems: keeping track of beliefs about the environment, and selecting actions for achieving goals. While the two problems are computationally intractable in the worst case, significant progress has been achieved in recent years through the use of suitable reductions. In particular, the state-of-the-art CLG planner is based on a translation that maps deterministic partially observable problems into fully observable nondeterministic ones. The translation, which is quadratic in the number of problem fluents and gets rid of the belief tracking problem, is adequate for most benchmarks; it is in fact complete for problems that have width 1. The more recent K-replanner uses two translations that are linear, one for keeping track of beliefs and the other for selecting actions using off-the-shelf classical planners.\nAs a result, the K-replanner scales up better but is not as general as CLG. In this work, we combine the benefits of these two approaches, the scope of the CLG planner and the efficiency of the K-replanner, by introducing a new planner, called LW1, that is based on a translation that is linear but which is complete for width-1 problems. The scope and performance of the new planner is evaluated by considering the existing benchmarks and new problems.",
    "Authors1": "Blai Bonet",
    "Authors2": "Hector Geffner",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Blai Bonet , Hector Geffner",
    "Groups1": "Knowledge Representation and Reasoning (KRR)",
    "Groups2": "Planning and Scheduling (PS)",
    "Groups3": "Reasoning under Uncertainty (RU)",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Knowledge Representation and Reasoning (KRR);Planning and Scheduling (PS);Reasoning under Uncertainty (RU)",
    "Keywords10": "",
    "Keywords1": "Planning with sensing and partial information",
    "Keywords2": "Planning with beliefs",
    "Keywords3": "On-line planning",
    "Keywords4": "Replanning",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Planning with sensing and partial information;Planning with beliefs;On-line planning;Replanning",
    "Title": "Flexible and Scalable Partially Observable Planning with Linear Translations",
    "Topics10": "",
    "Topics1": "KRR: Reasoning with Beliefs",
    "Topics2": "PS: Deterministic Planning",
    "Topics3": "PS: Replanning and Plan Repair",
    "Topics4": "PS: Planning (General/Other)",
    "Topics5": "RU: Sequential Decision Making",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "KRR: Reasoning with Beliefs;PS: Deterministic Planning;PS: Replanning and Plan Repair;PS: Planning (General/Other);RU: Sequential Decision Making"
  },
  {
    "Document Index (generated)": 379,
    "Number of Records": 1,
    "Abstract": "In portfolio selection, it often might be preferable to focus on a few top\nperforming industries/sectors to beat the market. These top performing sectors\nhowever might change over time. In this paper, we propose an online portfolio\nselection algorithm that can take advantage of sector information through the use of a group sparsity inducing regularizer while making lazy updates to the portfolio. The lazy updates prevent changing ones portfolio too often which otherwise might incur huge transaction costs.\nThe proposed formulation is not straightforward to solve due to the presence of\nnon-smooth functions along with the constraint that the portfolios have to lie\nwithin a probability simplex. We propose an efficient primal-dual based alternating direction method of multipliers algorithm and demonstrate its effectiveness for the problem of online portfolio selection\nwith sector information. We show that our algorithm O-LUGS has sub-linear\nregret $w.r.t.$ the best \\textit{fixed} and best \\textit{shifting} solution in\nhindsight. We successfully establish the robustness and scalability of O-LUGS\nby performing extensive experiments on two real-world datasets.",
    "Authors1": "Puja Das",
    "Authors2": "Nicholas Johnson",
    "Authors3": "Arindam Banerjee",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Puja Das, Nicholas Johnson , Arindam Banerjee",
    "Groups1": "Applications (APP)",
    "Groups2": "Game Theory and Economic Paradigms (GTEP)",
    "Groups3": "Machine Learning Applications (MLA)",
    "Groups4": "Novel Machine Learning Algorithms (NMLA)",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Applications (APP);Game Theory and Economic Paradigms (GTEP);Machine Learning Applications (MLA);Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "online learning",
    "Keywords2": "portfolio selection",
    "Keywords3": "group lasso",
    "Keywords4": "non-smooth convex optimization",
    "Keywords5": "alternating direction method of multipliers",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "online learning;portfolio selection;group lasso;non-smooth convex optimization;alternating direction method of multipliers",
    "Title": "Online Portfolio Selection with Group Sparsity",
    "Topics10": "",
    "Topics1": "APP: Other Applications",
    "Topics2": "GTEP: Adversarial Learning",
    "Topics3": "MLA: Machine Learning Applications (General/other)",
    "Topics4": "NMLA: Big Data / Scalability",
    "Topics5": "NMLA: Data Mining and Knowledge Discovery",
    "Topics6": "NMLA: Online Learning",
    "Topics7": "NMLA: Time-Series/Data Streams",
    "Topics8": "NMLA: Machine Learning (General/other)",
    "Topics9": "",
    "Topics": "APP: Other Applications;GTEP: Adversarial Learning;MLA: Machine Learning Applications (General/other);NMLA: Big Data / Scalability;NMLA: Data Mining and Knowledge Discovery;NMLA: Online Learning;NMLA: Time-Series/Data Streams;NMLA: Machine Learning (General/other)"
  },
  {
    "Document Index (generated)": 380,
    "Number of Records": 1,
    "Abstract": "Reviews keep playing an increasingly important role in the decision process of buying products and booking hotels. However, the large amount of available information can be confusing to users. A more succinct interface, gathering only the most helpful reviews, can reduce information processing time and save effort. To create such an interface in real time, we need reliable prediction algorithms to classify and predict new reviews which have not been voted but are potentially helpful. So far such helpfulness prediction algorithms have benefited from structural aspects, such as the length and readability score. Since emotional words are at the heart of our written communication and are powerful to trigger listeners’ attention, we believe that emotional words can serve as important parameters for predicting helpfulness of review text. \n\nUsing GALC, a general lexicon of emotional words associated with a model representing 20 different categories, we extracted the emotionality from the review text and applied supervised classification method to derive the emotion-based helpful review prediction. As the second contribution, we propose an evaluation framework comparing three different real-world datasets extracted from the most well-known product review websites. This framework shows that emotion-based methods are outperforming the structure-based approach, by up to 9%.",
    "Authors1": "Lionel Martin",
    "Authors2": "Pearl Pu",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Lionel Martin , Pearl Pu",
    "Groups1": "Machine Learning Applications (MLA)",
    "Groups2": "NLP and Machine Learning (NLPML)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Machine Learning Applications (MLA);NLP and Machine Learning (NLPML)",
    "Keywords10": "",
    "Keywords1": "helpfulness prediction",
    "Keywords2": "product review analysis",
    "Keywords3": "emotions extraction",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "helpfulness prediction;product review analysis;emotions extraction",
    "Title": "Prediction of Helpful Reviews using Emotions Extraction",
    "Topics10": "",
    "Topics1": "MLA: Applications of Supervised Learning",
    "Topics2": "NLPML: Evaluation and Analysis",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "MLA: Applications of Supervised Learning;NLPML: Evaluation and Analysis"
  },
  {
    "Document Index (generated)": 381,
    "Number of Records": 1,
    "Abstract": "Recently, there has been a growing interest in modelling planning with information constraints. Accordingly, an agent maximizes a regularized expected utility known as the free energy, where the regularizer is given by the information divergence from a prior to a posterior policy. While this approach can be justified in various ways, most importantly from statistical mechanics and information theory, it is still unclear how it relates to game theory. This connection has been suggested previously in work relating the free energy to risk-sensitive control and to extensive form games. In this work, we present an adversarial interpretation that is equivalent to the free energy optimization problem. The adversary can, by paying an exponential\npenalty, generate costs that diminish the decision maker's payoffs. It turns out\nthat the optimal strategy of the adversary consists in choosing costs so as to\nrender the decision maker indifferent among its choices, which is a definining\nproperty of a Nash equilibrium, thus tightening the connection between free\nenergy optimization and game theory.",
    "Authors1": "Pedro A. Ortega",
    "Authors2": "Daniel D. Lee",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Pedro A. Ortega , Daniel D. Lee",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "Planning and Scheduling (PS)",
    "Groups3": "Reasoning under Uncertainty (RU)",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP);Planning and Scheduling (PS);Reasoning under Uncertainty (RU)",
    "Keywords10": "",
    "Keywords1": "bounded rationality",
    "Keywords2": "free energy",
    "Keywords3": "game theory",
    "Keywords4": "legendre transform",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "bounded rationality;free energy;game theory;legendre transform",
    "Title": "An Adversarial Interpretation of Information-Theoretic Bounded Rationality",
    "Topics10": "",
    "Topics1": "PS: Probabilistic Planning",
    "Topics2": "PS: Planning (General/Other)",
    "Topics3": "RU: Decision/Utility Theory",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "PS: Probabilistic Planning;PS: Planning (General/Other);RU: Decision/Utility Theory"
  },
  {
    "Document Index (generated)": 382,
    "Number of Records": 1,
    "Abstract": "Being able to quickly and naturally teach robots new knowledge is critical for many future open-world human-robot interaction scenarios.  In this paper we present a novel approach to using natural language context for one-shot learning of visual objects, where the robot is immediately able to recognize the described object. We describe the architectural components and demonstrate the proposed approach on a robotic platform in a proof-of-concept evaluation.",
    "Authors1": "Evan Krause",
    "Authors2": "Michael Zillich",
    "Authors3": "Thomas Williams",
    "Authors4": "Matthias Scheutz",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Evan Krause, Michael Zillich, Thomas Williams , Matthias Scheutz",
    "Groups1": "Cognitive Systems (CS)",
    "Groups2": "Robotics (ROB)",
    "Groups3": "Vision (VIS)",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Cognitive Systems (CS);Robotics (ROB);Vision (VIS)",
    "Keywords10": "",
    "Keywords1": "one-shot learning",
    "Keywords2": "object recognition",
    "Keywords3": "natural language dialogues",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "one-shot learning;object recognition;natural language dialogues",
    "Title": "Learning to Recognize Novel Objects in One Shot through Human-Robot Interactions in Natural Language Dialogues",
    "Topics10": "",
    "Topics1": "CS: Natural language understanding and dialogue",
    "Topics2": "ROB: Human-Robot Interaction",
    "Topics3": "VIS: Language and Vision",
    "Topics4": "VIS: Object Recognition",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "CS: Natural language understanding and dialogue;ROB: Human-Robot Interaction;VIS: Language and Vision;VIS: Object Recognition"
  },
  {
    "Document Index (generated)": 383,
    "Number of Records": 1,
    "Abstract": "Coactive learning is an online problem solving setting where the solutions\nprovided by a solver are interactively improved by a domain expert, which\nin turn drives learning. \nIn this paper we extend the\nstudy of coactive learning to problems where obtaining a\nglobal or near-optimal solution may be intractable or where an expert\ncan only be expected to make small, local improvements to a candidate solution.\nThe goal of learning in this new setting is to minimize the cost\nas measured by the expert effort\nover time. We first establish theoretical bounds\non the average cost of the existing coactive Perceptron\nalgorithm. In addition, we consider new online algorithms that use\ncost-sensitive and Passive-Aggressive (PA) updates, showing similar\nor improved theoretical bounds. We provide an empirical evaluation\nof the learners in 5 domains, which show that the Perceptron based\nalgorithms are quite effective and that unlike the case for online\nclassification, the PA algorithms do not yield significant performance\ngains.",
    "Authors1": "Robby Goetschalckx",
    "Authors2": "Alan Fern",
    "Authors3": "Prasad Tadepalli",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Robby Goetschalckx, Alan Fern , Prasad Tadepalli",
    "Groups1": "Humans and AI (HAI)",
    "Groups2": "Knowledge Representation and Reasoning (KRR)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Humans and AI (HAI);Knowledge Representation and Reasoning (KRR)",
    "Keywords10": "",
    "Keywords1": "Coactive Learning",
    "Keywords2": "Local Optimization",
    "Keywords3": "Preference Learning",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Coactive Learning;Local Optimization;Preference Learning",
    "Title": "Coactive Learning for Locally Optimal Problem Solving",
    "Topics10": "",
    "Topics1": "HCC: Active learning from imperfect human labelers",
    "Topics2": "HAI: Interaction Techniques and Devices",
    "Topics3": "KRR: Preferences",
    "Topics4": "NMLA: Preferences/Ranking Learning",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "HCC: Active learning from imperfect human labelers;HAI: Interaction Techniques and Devices;KRR: Preferences;NMLA: Preferences/Ranking Learning"
  },
  {
    "Document Index (generated)": 384,
    "Number of Records": 1,
    "Abstract": "It has been argued that one can use cognitive simulation of analogical\nprocessing to answer comparison questions.  In the context of a\nknowledge base (KB) system, a comparison question takes the form: What\nare the similarities and/or differences between A and B?, where\n\\concept{A} and \\concept{B} are concepts in the KB.  Previous attempts\nto use a general purpose analogical reasoner to answer this question\nrevealed three major problems: (a) the system presented too much\ninformation in the answer and the salient similarity or difference was\nnot highlighted (b) analogical inference found some incorrect\ndifferences (c) some expected similarities were not found. The primary\ncause of these problems was the lack of availability of a well-curated\nKB, and secondarily, there were also some algorithmic deficiencies.\nIn this paper, we present an of comparison questions that is inspired\nby the general model of analogical reasoning, but is specific to the\nquestions at hand. We also rely on a well-curated biology KB.  We\npresent numerous examples of answers produced by the system and\nempirical data on the quality of the answers to claim that we have\naddressed many of the problems faced in the previous system.",
    "Authors1": "Vinay Chaudhri",
    "Authors2": "Stijn Heymans",
    "Authors3": "Adam Overholtzer",
    "Authors4": "Aaron Spaulding",
    "Authors5": "Michael Wessel",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Vinay Chaudhri, Stijn Heymans, Adam Overholtzer, Aaron Spaulding , Michael Wessel",
    "Groups1": "Cognitive Systems (CS)",
    "Groups2": "Knowledge Representation and Reasoning (KRR)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Cognitive Systems (CS);Knowledge Representation and Reasoning (KRR)",
    "Keywords10": "",
    "Keywords1": "analogical reasoning",
    "Keywords2": "case-based reasoning",
    "Keywords3": "question answering",
    "Keywords4": "knowledge base systems",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "analogical reasoning;case-based reasoning;question answering;knowledge base systems",
    "Title": "Large Scale Analogical Reasoning",
    "Topics10": "",
    "Topics1": "CS: Conceptual inference and reasoning",
    "Topics2": "CS: Structural learning and knowledge capture",
    "Topics3": "KRR: Qualitative Reasoning",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "CS: Conceptual inference and reasoning;CS: Structural learning and knowledge capture;KRR: Qualitative Reasoning"
  },
  {
    "Document Index (generated)": 385,
    "Number of Records": 1,
    "Abstract": "Agents with incomplete models of their environment are likely to be surprised. For agents in immense environments that defy complete modeling, this represents an opportunity to learn. We investigate approaches for situated agents to detect surprises, discriminate among different forms of surprise, and hypothesize new models for the unknown events that surprised them. We instantiate these approaches in a new goal reasoning agent (named FOOLMETWICE), investigate its performance in simulation studies, and show that it produces plans with significantly reduced execution cost when compared to not learning models for surprising events.",
    "Authors1": "Matthew Molineaux",
    "Authors2": "David Aha",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Matthew Molineaux , David Aha",
    "Groups1": "Cognitive Systems (CS)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Cognitive Systems (CS)",
    "Keywords10": "",
    "Keywords1": "learning environment models",
    "Keywords2": "explanation generation",
    "Keywords3": "execution monitoring",
    "Keywords4": "goal-driven autonomy",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "learning environment models;explanation generation;execution monitoring;goal-driven autonomy",
    "Title": "Learning Models of Unknown Events",
    "Topics10": "",
    "Topics1": "CM: Symbolic AI",
    "Topics2": "CS: Problem solving and decision making",
    "Topics3": "CS: Introspection and meta-cognition",
    "Topics4": "CS: Structural learning and knowledge capture",
    "Topics5": "PS: Learning Models for Planning and Diagnosis",
    "Topics6": "PS: Plan Execution and Monitoring",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "CM: Symbolic AI;CS: Problem solving and decision making;CS: Introspection and meta-cognition;CS: Structural learning and knowledge capture;PS: Learning Models for Planning and Diagnosis;PS: Plan Execution and Monitoring"
  },
  {
    "Document Index (generated)": 386,
    "Number of Records": 1,
    "Abstract": "In web search, users queries are formulated using only few terms and term-matching retrieval functions could fail at retrieving relevant documents. Given a user query, the technique of query expansion (QE) consists in selecting related terms that could enhance the likelihood of retrieving relevant documents. Selecting such expansion terms is challenging and requires a computational framework capable of encoding complex semantic relationships. In this paper, we propose a novel method for learning, in a supervised way, semantic representations for words and phrases. By embedding queries and documents in special matrices, our model disposes of an increased representational power with respect to existing approaches adopting a vector representation. We show that our model produces high-quality query expansion terms. Our expansion increase IR mesures beyond expansion from current word-embeddings models and well-established traditional QE methods.",
    "Authors1": "Aless",
    "Authors2": "ro Sordoni",
    "Authors3": "Yoshua Bengio",
    "Authors4": "Jian-Yun Nie",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Aless,ro Sordoni, Yoshua Bengio , Jian-Yun Nie",
    "Groups1": "NLP and Knowledge Representation (NLPKR)",
    "Groups2": "NLP and Machine Learning (NLPML)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "NLP and Knowledge Representation (NLPKR);NLP and Machine Learning (NLPML)",
    "Keywords10": "",
    "Keywords1": "Embedding",
    "Keywords2": "Density Matrix",
    "Keywords3": "Query Expansion",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Embedding;Density Matrix;Query Expansion",
    "Title": "Learning Concept Embeddings for Query Expansion by Quantum Entropy Minimization",
    "Topics10": "",
    "Topics1": "NLPKR: Natural Language Processing (General/Other)",
    "Topics2": "NLPML: Natural Language Processing (General/Other)",
    "Topics3": "NMLA: Neural Networks/Deep Learning",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NLPKR: Natural Language Processing (General/Other);NLPML: Natural Language Processing (General/Other);NMLA: Neural Networks/Deep Learning"
  },
  {
    "Document Index (generated)": 387,
    "Number of Records": 1,
    "Abstract": "Propositional satisfiability (SAT) solvers based on conflict directed\nclause learning (CDCL) implicitly produce resolution refutations of\nunsatisfiable formulas. The precise class of formulas for which they\ncan produce polynomial size refutations has been the subject of\nseveral studies, with special focus on the clause learning aspect of\nthese solvers. The results, however, either assume the use of\nnon-standard and non-asserting learning schemes such as FirstNewCut,\nor rely on polynomially many restarts for simulating individual steps\nof a resolution refutation, or work with a theoretical model that\nsignificantly deviates from certain key aspects of all modern CDCL\nsolvers such as learning only one asserting clause from each conflict\nand other techniques such as conflict guided backjumping and clause\nminimization. We study non-restarting CDCL solvers that learn only one\nasserting clause per conflict and show that, with simple preprocessing\nthat depends only on the number of variables of the input formula,\nsuch solvers can polynomially simulate resolution.",
    "Authors1": "Paul Beame",
    "Authors2": "Ashish Sabharwal",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Paul Beame , Ashish Sabharwal",
    "Groups1": "Search and Constraint Satisfaction (SCS)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Search and Constraint Satisfaction (SCS)",
    "Keywords10": "",
    "Keywords1": "clause learning",
    "Keywords2": "satisfiability",
    "Keywords3": "proof complexity",
    "Keywords4": "p-simulation",
    "Keywords5": "1-UIP clauses",
    "Keywords6": "asserting clauses",
    "Keywords7": "resolution",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "clause learning;satisfiability;proof complexity;p-simulation;1-UIP clauses;asserting clauses;resolution",
    "Title": "Non-Restarting SAT Solvers With Simple Preprocessing Efficiently Simulate Resolution",
    "Topics10": "",
    "Topics1": "SCS: Constraint Satisfaction",
    "Topics2": "SCS: Constraint Learning and Acquisition",
    "Topics3": "SCS: SAT and CSP: Evaluation and Analysis",
    "Topics4": "SCS: Satisfiability (General/Other)",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "SCS: Constraint Satisfaction;SCS: Constraint Learning and Acquisition;SCS: SAT and CSP: Evaluation and Analysis;SCS: Satisfiability (General/Other)"
  },
  {
    "Document Index (generated)": 388,
    "Number of Records": 1,
    "Abstract": "The use of inconsistent heuristics with A* can result in increased runtime due to the need to re-expand nodes. Poor performance can also be seen with Weighted A* if nodes are re-expanded. While the negative impact of re-expansions can often be minimized by setting these algorithms to never expand nodes more than once, the result can be a lower solution quality. In this paper, we formally show that the loss in solution quality can be bounded based on the amount of inconsistency along optimal solution paths. This bound holds regardless of whether the heuristic is admissible or inadmissible, though if the heuristic is admissible the bound can be used to show that not re-expanding nodes can have at most a quadratic impact on the quality of solutions found when using A*. We then show that the bound is tight by describing a process for the construction of graphs for which a best-first search that does not re-expand nodes will find solutions whose quality is arbitrarily close to that given by the bound. Finally, we will use the bound to extend a known result regarding the solution quality of WA* when weighting a consistent heuristic, so that it applies to other types of heuristic weighting.",
    "Authors1": "Richard Valenzano",
    "Authors2": "Nathan Sturtevant",
    "Authors3": "Jonathan Schaeffer",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Richard Valenzano, Nathan Sturtevant , Jonathan Schaeffer",
    "Groups1": "Heuristic Search and Optimization (HSO)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Heuristic Search and Optimization (HSO)",
    "Keywords10": "",
    "Keywords1": "best-first search",
    "Keywords2": "re-expansions",
    "Keywords3": "heuristics",
    "Keywords4": "inconsistency",
    "Keywords5": "inadmissibility",
    "Keywords6": "solution quality",
    "Keywords7": "suboptimality",
    "Keywords8": "suboptimal heuristic search",
    "Keywords9": "worst-case analysis",
    "Keywords": "best-first search;re-expansions;heuristics;inconsistency;inadmissibility;solution quality;suboptimality;suboptimal heuristic search;worst-case analysis",
    "Title": "Worst-Case Solution Quality Analysis When Not Re-Expanding Nodes in Best-First Search",
    "Topics10": "",
    "Topics1": "HSO: Heuristic Search",
    "Topics2": "HSO: Evaluation and Analysis (Search and Optimization)",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "HSO: Heuristic Search;HSO: Evaluation and Analysis (Search and Optimization)"
  },
  {
    "Document Index (generated)": 389,
    "Number of Records": 1,
    "Abstract": "In this paper we investigate the application of natural gradient descent to Bellman error based reinforcement learning algorithms. This combination is interesting because natural gradient descent is invariant to the parameterization of the value function. This invariance property means that natural gradient descent adapts its update directions to correct for poorly conditioned representations. We present and analyze quadratic and linear time natural temporal difference learning algorithms, and prove that they are covariant. We conclude with experiments which suggest that the natural algorithms can match or outperform their non-natural counterparts using linear function approximation, and drastically improve upon their non-natural counterparts when using non-linear function approximation.",
    "Authors1": "William Dabney",
    "Authors2": "Philip Thomas",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "William Dabney , Philip Thomas",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "natural gradient",
    "Keywords2": "temporal difference learning",
    "Keywords3": "reinforcement learning",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "natural gradient;temporal difference learning;reinforcement learning",
    "Title": "Natural Temporal Difference Learning",
    "Topics10": "",
    "Topics1": "",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": ""
  },
  {
    "Document Index (generated)": 390,
    "Number of Records": 1,
    "Abstract": "A number of problems involve managing a set of optional clauses. For example, the soft clauses in a MaxSat formula are optional---they can be falsified for a cost. Similarly when computing a Minimum Correction Set for an unsatisfiable formula all clauses are optional---some can be falsified in order to make the\n  remaining satisfiable. In both of these cases the task is to find a subset of the optional clauses that achieves some optimization criteria and is satisfiable. Relaxation search is a simple method of using a standard SAT solver to solve this task. Relaxation search is very easy to implement, sometimes requiring only a simple   modification of the variable selection heuristic in the SAT solver. Furthermore, considerable flexibility and control can be achieved over the order in which subsets of optional clauses examined. We demonstrate how relaxation search can be used to solve MaxSat and to compute Minimum Correction Sets. In both cases  relaxation search is able to achieve state-of-the-art performance and solve some instances other solvers are not able to solve.",
    "Authors1": "Maria Tsimpoukelli",
    "Authors2": "Fahiem Bacchus",
    "Authors3": "Jessica Davies",
    "Authors4": "George Katsirelos",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Maria Tsimpoukelli, Fahiem Bacchus, Jessica Davies , George Katsirelos",
    "Groups1": "Search and Constraint Satisfaction (SCS)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Search and Constraint Satisfaction (SCS)",
    "Keywords10": "",
    "Keywords1": "Constraint Optimization",
    "Keywords2": "Satisfiability",
    "Keywords3": "Maximum Satisfiability",
    "Keywords4": "Minimal Correction Sets",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Constraint Optimization;Satisfiability;Maximum Satisfiability;Minimal Correction Sets",
    "Title": "Relaxation Search: a Simple Way of Managing Optional Clauses",
    "Topics10": "",
    "Topics1": "SCS: Constraint Optimization",
    "Topics2": "SCS: SAT and CSP: Solvers and Tools",
    "Topics3": "SCS: Satisfiability (General/Other)",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "SCS: Constraint Optimization;SCS: SAT and CSP: Solvers and Tools;SCS: Satisfiability (General/Other)"
  },
  {
    "Document Index (generated)": 391,
    "Number of Records": 1,
    "Abstract": "Extensive-form games are a powerful tool for representing complex multi-agent interactions. Nash equilibrium strategies are commonly used as a solution concept for extensive-form games, but many games are too large for the computation of Nash equilibria to be tractable. In these large games, exploitability has traditionally been used to measure deviation from Nash equilibrium, and thus strategies are aimed to achieve minimal exploitability. However, while exploitability measures a strategy's worst-case performance, it fails to capture how likely that worst-case is to be observed in practice. In fact, empirical evidence has shown that a less exploitable strategy can perform worse than a more exploitable strategy in one-on-one play against a variety of opponents. In this work, we propose a class of response functions that can be used to measure the strength of a strategy. We prove that standard no-regret algorithms can be used to learn optimal strategies for a scenario where the opponent uses one of these response functions. We demonstrate the effectiveness of this technique in Leduc poker against opponents that use the UCT Monte Carlo tree search algorithm.",
    "Authors1": "Trevor Davis",
    "Authors2": "Neil Burch",
    "Authors3": "Michael Bowling",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Trevor Davis, Neil Burch , Michael Bowling",
    "Groups1": "Game Theory and Economic Paradigms (GTEP)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Game Theory and Economic Paradigms (GTEP)",
    "Keywords10": "",
    "Keywords1": "strategy evaluation",
    "Keywords2": "extensive-form games",
    "Keywords3": "adaptive opponents",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "strategy evaluation;extensive-form games;adaptive opponents",
    "Title": "Using Response Functions to Measure Strategy Strength",
    "Topics10": "",
    "Topics1": "GTEP: Game Theory",
    "Topics2": "GTEP: Equilibrium",
    "Topics3": "GTEP: Imperfect Information",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "GTEP: Game Theory;GTEP: Equilibrium;GTEP: Imperfect Information"
  },
  {
    "Document Index (generated)": 392,
    "Number of Records": 1,
    "Abstract": "A framework capable of computing optimal control policies for a continuous system in the presence of both action and environment uncertainty is presented in this work.  The framework decomposes the planning problem into two stages: an offline phase that reasons only over action uncertainty and an online phase that quickly reacts to the uncertain environment.  Offline, a bounded-parameter Markov decision process (BMDP) is employed to model the evolution of the stochastic system over a discretization of the environment.  Online, an optimal control policy over the BMDP is computed.  Upon the discovery of an unknown environment feature during policy execution, the BMDP is updated and the optimal control policy is efficiently recomputed.  Depending on the desired quality of the control policy, a suite of methods is presented to incorporate new information into the BMDP with varying degrees of detail online.  Experiments confirm that the framework recomputes high-quality policies in seconds and is orders of magnitude faster than existing methods.",
    "Authors1": "Ryan Luna",
    "Authors2": "Morteza Lahijanian",
    "Authors3": "Mark Moll",
    "Authors4": "Lydia Kavraki",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Ryan Luna, Morteza Lahijanian, Mark Moll , Lydia Kavraki",
    "Groups1": "Reasoning under Uncertainty (RU)",
    "Groups2": "Robotics (ROB)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Reasoning under Uncertainty (RU);Robotics (ROB)",
    "Keywords10": "",
    "Keywords1": "Planning under uncertainty",
    "Keywords2": "Motion planning with action and environment uncertainty",
    "Keywords3": "Optimal stochastic motion planning",
    "Keywords4": "Computing policies under uncertainty",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Planning under uncertainty;Motion planning with action and environment uncertainty;Optimal stochastic motion planning;Computing policies under uncertainty",
    "Title": "Optimal and Efficient Stochastic Motion Planning in Partially-Known Environments",
    "Topics10": "",
    "Topics1": "PS: Mixed Discrete/Continuous Planning",
    "Topics2": "RU: Uncertainty in AI (General/Other)",
    "Topics3": "ROB: Motion and Path Planning",
    "Topics4": "ROB: Robotics (General/Other)",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "PS: Mixed Discrete/Continuous Planning;RU: Uncertainty in AI (General/Other);ROB: Motion and Path Planning;ROB: Robotics (General/Other)"
  },
  {
    "Document Index (generated)": 393,
    "Number of Records": 1,
    "Abstract": "Scripts have been proposed to model the stereotypical event sequences found in narratives. They can be applied to make a variety of inferences including filling gaps in the narratives and resolving ambiguous references. This paper proposes the first formal framework for scripts based on Hidden Markov Models (HMMs). Our framework supports robust inference and learning algorithms, which are lacking in previous clustering models. We develop an algorithm for structure and parameter learning based on Expectation Maximization and evaluate it on a number of natural and synthetic datasets. The results show that our algorithm is superior to several informed baselines for predicting future events given some past history.",
    "Authors1": "Walker Orr",
    "Authors2": "Prasad Tadepalli",
    "Authors3": "Thomas Dietterich",
    "Authors4": "Xiaoli Fern",
    "Authors5": "Janardhan Rao Doppa",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Walker Orr, Prasad Tadepalli, Thomas Dietterich, Xiaoli Fern , Janardhan Rao Doppa",
    "Groups1": "NLP and Machine Learning (NLPML)",
    "Groups2": "Novel Machine Learning Algorithms (NMLA)",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "NLP and Machine Learning (NLPML);Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "HMM",
    "Keywords2": "Scripts",
    "Keywords3": "NLP",
    "Keywords4": "Structural EM",
    "Keywords5": "Structure Learning",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "HMM;Scripts;NLP;Structural EM;Structure Learning",
    "Title": "Learning Scripts as Hidden Markov Models",
    "Topics10": "",
    "Topics1": "NLPML: Natural Language Processing (General/Other)",
    "Topics2": "NMLA: Graphical Model Learning",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NLPML: Natural Language Processing (General/Other);NMLA: Graphical Model Learning"
  },
  {
    "Document Index (generated)": 394,
    "Number of Records": 1,
    "Abstract": "Nowadays many people are members of multiple online social networks simultaneously, such as Facebook, Twitter and some other instant messaging circles. But these networks are usually isolated from each other. Mapping common users cross these social networks will be beneficial for cross network recommendation or expanding one’s social circle. Methods based on username comparison perform well on parts of users, however they can not work in the following situations: (a) users choose completely different usernames in different networks; (b) a unique username corresponds to different individuals. In this paper, we propose to utilize social structures to improve the mapping performance. Specifically, a novel subspace learning algorithm, Manifold Alignment on Hypergraph (MAH), is proposed. Different from traditional semi-supervised manifold alignment methods, we use hypergraph to model high-order relations here. For a target user in one network, the proposed algorithm ranks all users in the other network by their probabilities of being the corresponding user. Moreover, methods based on username comparison can be incorporated with our algorithm easily to further boost the mapping accuracy. In experiments, we use both simulation data and real world data to test the proposed method. Experiment results have demonstrated the effectiveness of our proposed algorithm in mapping users cross networks.",
    "Authors1": "Shulong Tan",
    "Authors2": "Ziyu Guan",
    "Authors3": "Deng Cai",
    "Authors4": "Xuzhen Qin",
    "Authors5": "Jiajun Bu",
    "Authors6": "Chun Chen",
    "Authors7": "",
    "Authors": "Shulong Tan, Ziyu Guan, Deng Cai, Xuzhen Qin, Jiajun Bu , Chun Chen",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW)",
    "Keywords10": "",
    "Keywords1": "Social Networks",
    "Keywords2": "Manifold Alignment",
    "Keywords3": "Hypergraph",
    "Keywords4": "De-anonymization",
    "Keywords5": "User Mapping",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Social Networks;Manifold Alignment;Hypergraph;De-anonymization;User Mapping",
    "Title": "Mapping Users Across Networks by Manifold Alignment on Hypergraph",
    "Topics10": "",
    "Topics1": "AIW: Machine learning and the web",
    "Topics2": "AIW: Ontologies and the web: creation, extraction, evolution, mapping, merging, and alignment",
    "Topics3": "tags and folksonomies",
    "Topics4": "AIW: Social networking and community identification",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: Machine learning and the web;AIW: Ontologies and the web: creation, extraction, evolution, mapping, merging, and alignment; tags and folksonomies;AIW: Social networking and community identification"
  },
  {
    "Document Index (generated)": 395,
    "Number of Records": 1,
    "Abstract": "Diversified query expansion (DQE) based approaches aim to select a set of expansion terms with less redundancy among them while covering  as many query aspects as possible. Recently they have experimentally demonstrate their effectiveness for the task of search result diversification. One challenge faced by existing DQE approaches is how to  ensure the aspect coverage. In this paper, we propose a novel method for DQE, called compact aspect embedding, which exploits trace norm regularization to  learn a  low rank vector space  for the query, with each eigenvector of the learnt vector space representing an aspect, and the absolute value of its corresponding eigenvalue representing the association strength of that aspect to the query.  Meanwhile, each expansion term is mapped into the vector space as well. Based on this novel representation of the query aspects and expansion terms, we design a greedy selection strategy to choose a set of expansion terms to explicitly cover all possible aspects of the query. We test our method  on several TREC diversification data sets, and show our method significantly outperforms the state-of-the-art approaches.",
    "Authors1": "Xiaohua Liu",
    "Authors2": "Arbi Bouchoucha",
    "Authors3": "Jian-Yun Nie",
    "Authors4": "Aless",
    "Authors5": "ro Sordoni",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Xiaohua Liu, Arbi Bouchoucha, Jian-Yun Nie , Aless,ro Sordoni",
    "Groups1": "AI and the Web (AIW)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "AI and the Web (AIW)",
    "Keywords10": "",
    "Keywords1": "query expansion",
    "Keywords2": "search result diversification",
    "Keywords3": "Trace Norm Regularization",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "query expansion;search result diversification;Trace Norm Regularization",
    "Title": "Compact Aspect Embedding For Diversified Query Expansion",
    "Topics10": "",
    "Topics1": "AIW: Enhancing web search and information retrieval",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "AIW: Enhancing web search and information retrieval"
  },
  {
    "Document Index (generated)": 396,
    "Number of Records": 1,
    "Abstract": "An essential task in managing DL ontologies is to deal with changes over the ontologies. \nIn particular, outdated axioms have to be removed from the ontology \nand newly formed axioms have to be incorporated into the ontology.\nSuch changes are formalised as the operations of contraction and revision in the literatures. \nThe operations can be defined in various ways.\nTo investigate properties of a defined operation, it is best to identify some postulates that completely \ncharacterise the operation such that on the one hand the operation satisfies the postulates \nand on the other hand it is the only operation that satisfies all the postulates.\nSuch characterisation results have never been shown for contractions under DLs.\nIn this paper, we define model-based contraction and revision for DL-Lite$_{core}$ TBoxes\nand provide characterisation results for both operations.\nAs a first step for applying the operations in practice, \nwe also provide tractable algorithms for both operations.\nSince DL semantics incurs infinite numbers of models for DL-Lite TBoxes,\nit is not feasible to develop algorithms involving DL models.\nThe key to our operations and algorithms is the development of an alternative semantics called type semantics. Type semantics closely resembles the semantics underlays propositional logic,\nthus it is more succinct than DL semantics. Most importantly, given a finite signature, any DL-Lite$_{core}$ TBox has finite numbers of type models.",
    "Authors1": "Zhiqiang Zhuang",
    "Authors2": "Zhe Wang",
    "Authors3": "Kewen Wang",
    "Authors4": "Guilin Qi",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Zhiqiang Zhuang, Zhe Wang, Kewen Wang , Guilin Qi",
    "Groups1": "Knowledge Representation and Reasoning (KRR)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Knowledge Representation and Reasoning (KRR)",
    "Keywords10": "",
    "Keywords1": "Belief Change",
    "Keywords2": "Description Logic",
    "Keywords3": "Non-monotonic reasoning",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Belief Change;Description Logic;Non-monotonic reasoning",
    "Title": "Contraction and Revision over DL-Lite TBoxes",
    "Topics10": "",
    "Topics1": "KRR: Belief Change",
    "Topics2": "KRR: Description Logics",
    "Topics3": "KRR: Nonmonotonic Reasoning",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "KRR: Belief Change;KRR: Description Logics;KRR: Nonmonotonic Reasoning"
  },
  {
    "Document Index (generated)": 397,
    "Number of Records": 1,
    "Abstract": "Compared to overt pronoun resolution, there is less work on the more challenging task of zero pronoun resolution. State-of-the-art approaches to zero pronoun resolution are supervised, requiring the availability of documents containing manually resolved zero pronouns. In contrast, we propose in this paper an unsupervised approach to this task. Underlying our approach is the novel idea of employing a model trained on manually resolved overt pronouns to resolve zero pronouns. Experimental results on the OntoNotes corpus are encouraging: our unsupervised model rivals its supervised counterparts in performance.",
    "Authors1": "Chen Chen",
    "Authors2": "Vincent Ng",
    "Authors3": "",
    "Authors4": "",
    "Authors5": "",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Chen Chen , Vincent Ng",
    "Groups1": "NLP and Text Mining (NLPTM)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "NLP and Text Mining (NLPTM)",
    "Keywords10": "",
    "Keywords1": "Zero Pronouns",
    "Keywords2": "Text Mining",
    "Keywords3": "Natural Language Processing",
    "Keywords4": "",
    "Keywords5": "",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Zero Pronouns;Text Mining;Natural Language Processing",
    "Title": "Zero Pronoun Resolution as Ranking",
    "Topics10": "",
    "Topics1": "NLPTM: Evaluation and Analysis",
    "Topics2": "",
    "Topics3": "",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NLPTM: Evaluation and Analysis"
  },
  {
    "Document Index (generated)": 398,
    "Number of Records": 1,
    "Abstract": "A combination of sparse coding and transfer learning techniques was shown to be accurate and robust in classification tasks where training and testing objects have a shared feature space but are sampled from different underlying distributions, i.e., belong to different domains. The key assumption in such case is that in spite of the domain disparity, samples from different domains share some common hidden factors. Previous methods often assumed that all the objects in the target domain are not labeled, and thus the training set solely comprised objects from the source domain. However, in real world applications, the target domain often has some labeled objects, or one can always manually label a small number of them. In this paper, we explore such possibility and show how a little amount of labeled data in the target domain can significantly leverage classification accuracy of the state-of-the-art transfer sparse coding methods. We further propose a unified framework named Supervised Transfer Sparse Coding (STSC) which simultaneously optimizes sparse representation, domain transfer and supervised classification. Experimental results on three applications demonstrate that little manual labeling and then learning the model in a supervised fashion can significantly improve classification accuracy.",
    "Authors1": "Maruan Al-Shedivat",
    "Authors2": "Jim Jing-Yan Wang",
    "Authors3": "Majed Alzahrani",
    "Authors4": "Jianhua Z. Huang",
    "Authors5": "Xin Gao",
    "Authors6": "",
    "Authors7": "",
    "Authors": "Maruan Al-Shedivat, Jim Jing-Yan Wang, Majed Alzahrani, Jianhua Z. Huang , Xin Gao",
    "Groups1": "Novel Machine Learning Algorithms (NMLA)",
    "Groups2": "",
    "Groups3": "",
    "Groups4": "",
    "Groups5": "",
    "Groups6": "",
    "Groups7": "",
    "Groups8": "",
    "Groups": "Novel Machine Learning Algorithms (NMLA)",
    "Keywords10": "",
    "Keywords1": "Sparse coding",
    "Keywords2": "Transfer learning",
    "Keywords3": "Supervised learning",
    "Keywords4": "Classification",
    "Keywords5": "Support Vector Machine",
    "Keywords6": "",
    "Keywords7": "",
    "Keywords8": "",
    "Keywords9": "",
    "Keywords": "Sparse coding;Transfer learning;Supervised learning;Classification;Support Vector Machine",
    "Title": "Supervised Transfer Sparse Coding",
    "Topics10": "",
    "Topics1": "NMLA: Classification",
    "Topics2": "NMLA: Transfer, Adaptation, Multitask Learning",
    "Topics3": "NMLA: Supervised Learning (Other)",
    "Topics4": "",
    "Topics5": "",
    "Topics6": "",
    "Topics7": "",
    "Topics8": "",
    "Topics9": "",
    "Topics": "NMLA: Classification;NMLA: Transfer, Adaptation, Multitask Learning;NMLA: Supervised Learning (Other)"
  }
]